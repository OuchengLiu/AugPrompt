***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoCoOp/vit_b16_c16_ep10_batch1.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/0506/base2new/train_base/caltech101/shots_16/CoCoOp/vit_b16_c16_ep10_batch1/seed2
resume: 
root: ../DATA
seed: 2
source_domains: None
target_domains: None
trainer: CoCoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 1
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  ROOT: ../DATA
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_flip',)
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 10
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/0506/base2new/train_base/caltech101/shots_16/CoCoOp/vit_b16_c16_ep10_batch1/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoCoOp
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 2.2.2+cu118
Is debug build: False
CUDA used to build PyTorch: 11.8
ROCM used to build PyTorch: N/A

OS: Microsoft Windows 11 ¼ÒÍ¥ÖÐÎÄ°æ
GCC version: (x86_64-win32-seh-rev0, Built by MinGW-W64 project) 8.1.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: N/A

Python version: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)] (64-bit runtime)
Python platform: Windows-10-10.0.22631-SP0
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 2060
Nvidia driver version: 527.54
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture=9
CurrentClockSpeed=2592
DeviceID=CPU0
Family=198
L2CacheSize=1536
L2CacheSpeed=
Manufacturer=GenuineIntel
MaxClockSpeed=2592
Name=Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz
ProcessorType=3
Revision=

Versions of relevant libraries:
[pip3] flake8==3.7.9
[pip3] numpy==1.26.0
[pip3] torch==2.2.2+cu118
[pip3] torchaudio==2.2.2+cu118
[pip3] torchvision==0.17.2+cu118
[conda] blas                      1.0                         mkl  
[conda] mkl                       2023.1.0         h6b88ed4_46357  
[conda] mkl-service               2.4.0           py310h2bbff1b_1  
[conda] mkl_fft                   1.3.8           py310h2bbff1b_0  
[conda] mkl_random                1.2.4           py310h59b6b97_0  
[conda] numpy                     1.26.0          py310h055cbcc_0  
[conda] numpy-base                1.26.0          py310h65a83cf_0  
[conda] torch                     1.13.1+cu117             pypi_0    pypi
[conda] torchaudio                0.13.1+cu117             pypi_0    pypi
[conda] torchvision               0.14.1                   pypi_0    pypi
        Pillow (9.4.0)

Loading trainer: CoCoOp
Loading dataset: Caltech101
Reading split from C:\Jupyter\MyConda\Experiment\1_CoOp_\DATA\caltech-101\split_zhou_Caltech101.json
Loading preprocessed few-shot data from C:\Jupyter\MyConda\Experiment\1_CoOp_\DATA\caltech-101\split_fewshot\shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
Building transform_train
+ resize to 224x224
+ random flip
+ to torch tensor of range [0, 1]
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
---------  ----------
Dataset    Caltech101
# classes  50
# train_x  800
# val      200
# test     1,549
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Aid context: "X X X"
Number of aid context words (tokens): 3
Turning off gradients in both the image and the text encoder
Parameters to be updated: {'prompt_learner.ctx', 'prompt_learner.meta_net.linear1.weight', 'prompt_learner.meta_net.linear1.bias', 'prompt_learner.meta_net.linear2.bias', 'prompt_learner.meta_net.linear2.weight'}
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/0506/base2new/train_base/caltech101/shots_16/CoCoOp/vit_b16_c16_ep10_batch1/seed2\tensorboard)
epoch [1/10] batch [20/800] time 1.222 (4.345) data 0.000 (3.019) loss 0.0013 (1.9879) lr 1.0000e-05 eta 9:37:49
epoch [1/10] batch [40/800] time 1.236 (2.787) data 0.000 (1.510) loss 1.2861 (1.4661) lr 1.0000e-05 eta 6:09:47
epoch [1/10] batch [60/800] time 1.407 (2.312) data 0.016 (1.007) loss 0.0649 (1.2608) lr 1.0000e-05 eta 5:06:01
epoch [1/10] batch [80/800] time 1.361 (2.082) data 0.000 (0.755) loss 0.0000 (1.1209) lr 1.0000e-05 eta 4:34:50
epoch [1/10] batch [100/800] time 1.377 (1.944) data 0.000 (0.604) loss 1.2314 (0.9889) lr 1.0000e-05 eta 4:15:54
epoch [1/10] batch [120/800] time 1.460 (1.854) data 0.000 (0.504) loss 0.0027 (0.9128) lr 1.0000e-05 eta 4:03:27
epoch [1/10] batch [140/800] time 1.423 (1.791) data 0.000 (0.432) loss 0.0484 (0.8762) lr 1.0000e-05 eta 3:54:36
epoch [1/10] batch [160/800] time 1.392 (1.743) data 0.016 (0.378) loss 0.0001 (0.8783) lr 1.0000e-05 eta 3:47:46
epoch [1/10] batch [180/800] time 1.393 (1.706) data 0.000 (0.336) loss 3.9629 (0.8152) lr 1.0000e-05 eta 3:42:20
epoch [1/10] batch [200/800] time 1.377 (1.677) data 0.000 (0.302) loss 0.0010 (0.7453) lr 1.0000e-05 eta 3:37:59
epoch [1/10] batch [220/800] time 1.423 (1.653) data 0.000 (0.275) loss 1.4756 (0.7414) lr 1.0000e-05 eta 3:34:21
epoch [1/10] batch [240/800] time 1.909 (1.658) data 0.000 (0.252) loss 0.0000 (0.7006) lr 1.0000e-05 eta 3:34:27
epoch [1/10] batch [260/800] time 1.910 (1.674) data 0.000 (0.233) loss 0.0609 (0.7079) lr 1.0000e-05 eta 3:36:00
epoch [1/10] batch [280/800] time 1.895 (1.688) data 0.000 (0.216) loss 0.0013 (0.6744) lr 1.0000e-05 eta 3:37:14
epoch [1/10] batch [300/800] time 1.909 (1.703) data 0.000 (0.202) loss 0.0001 (0.6593) lr 1.0000e-05 eta 3:38:33
epoch [1/10] batch [320/800] time 1.906 (1.716) data 0.000 (0.189) loss 0.0011 (0.6191) lr 1.0000e-05 eta 3:39:38
epoch [1/10] batch [340/800] time 1.924 (1.728) data 0.000 (0.178) loss 0.0199 (0.5958) lr 1.0000e-05 eta 3:40:36
epoch [1/10] batch [360/800] time 1.927 (1.737) data 0.000 (0.168) loss 0.0118 (0.5801) lr 1.0000e-05 eta 3:41:07
epoch [1/10] batch [380/800] time 1.909 (1.746) data 0.000 (0.159) loss 0.1204 (0.5690) lr 1.0000e-05 eta 3:41:41
epoch [1/10] batch [400/800] time 1.910 (1.754) data 0.000 (0.152) loss 1.2695 (0.5478) lr 1.0000e-05 eta 3:42:07
epoch [1/10] batch [420/800] time 1.909 (1.761) data 0.000 (0.144) loss 0.0004 (0.5463) lr 1.0000e-05 eta 3:42:26
epoch [1/10] batch [440/800] time 1.909 (1.768) data 0.000 (0.138) loss 0.0102 (0.5352) lr 1.0000e-05 eta 3:42:42
epoch [1/10] batch [460/800] time 1.909 (1.772) data 0.000 (0.132) loss 4.3867 (0.5232) lr 1.0000e-05 eta 3:42:40
epoch [1/10] batch [480/800] time 1.909 (1.778) data 0.000 (0.126) loss 0.0011 (0.5062) lr 1.0000e-05 eta 3:42:47
epoch [1/10] batch [500/800] time 1.894 (1.782) data 0.000 (0.121) loss 0.2815 (0.4882) lr 1.0000e-05 eta 3:42:45
epoch [1/10] batch [520/800] time 1.910 (1.787) data 0.000 (0.117) loss 0.0000 (0.4822) lr 1.0000e-05 eta 3:42:45
epoch [1/10] batch [540/800] time 1.901 (1.791) data 0.000 (0.112) loss 0.2590 (0.4762) lr 1.0000e-05 eta 3:42:43
epoch [1/10] batch [560/800] time 1.894 (1.794) data 0.000 (0.108) loss 0.0001 (0.4648) lr 1.0000e-05 eta 3:42:28
epoch [1/10] batch [580/800] time 1.909 (1.797) data 0.000 (0.105) loss 8.5547 (0.4650) lr 1.0000e-05 eta 3:42:11
epoch [1/10] batch [600/800] time 1.895 (1.800) data 0.000 (0.101) loss 0.0018 (0.4783) lr 1.0000e-05 eta 3:42:02
epoch [1/10] batch [620/800] time 1.908 (1.803) data 0.000 (0.098) loss 0.0015 (0.4674) lr 1.0000e-05 eta 3:41:42
epoch [1/10] batch [640/800] time 1.908 (1.805) data 0.000 (0.095) loss 0.0161 (0.4554) lr 1.0000e-05 eta 3:41:27
epoch [1/10] batch [660/800] time 1.892 (1.808) data 0.000 (0.092) loss 0.0004 (0.4543) lr 1.0000e-05 eta 3:41:09
epoch [1/10] batch [680/800] time 1.893 (1.811) data 0.000 (0.089) loss 0.0000 (0.4422) lr 1.0000e-05 eta 3:40:54
epoch [1/10] batch [700/800] time 1.908 (1.814) data 0.000 (0.087) loss 0.0020 (0.4320) lr 1.0000e-05 eta 3:40:38
epoch [1/10] batch [720/800] time 1.282 (1.815) data 0.000 (0.084) loss 0.0000 (0.4259) lr 1.0000e-05 eta 3:40:15
epoch [1/10] batch [740/800] time 1.909 (1.816) data 0.000 (0.082) loss 0.0011 (0.4182) lr 1.0000e-05 eta 3:39:47
epoch [1/10] batch [760/800] time 1.910 (1.817) data 0.000 (0.080) loss 0.0011 (0.4134) lr 1.0000e-05 eta 3:39:12
epoch [1/10] batch [780/800] time 1.911 (1.819) data 0.000 (0.078) loss 0.0000 (0.4053) lr 1.0000e-05 eta 3:38:52
epoch [1/10] batch [800/800] time 1.895 (1.820) data 0.000 (0.076) loss 0.0001 (0.3959) lr 2.0000e-03 eta 3:38:24
epoch [2/10] batch [20/800] time 1.908 (4.774) data 0.000 (3.020) loss 0.0000 (0.4273) lr 2.0000e-03 eta 9:31:18
epoch [2/10] batch [40/800] time 1.893 (3.340) data 0.000 (1.510) loss 0.0143 (0.3153) lr 2.0000e-03 eta 6:38:36
epoch [2/10] batch [60/800] time 1.910 (2.849) data 0.000 (1.007) loss 0.0002 (0.3265) lr 2.0000e-03 eta 5:39:01
epoch [2/10] batch [80/800] time 1.909 (2.593) data 0.000 (0.755) loss 0.0000 (0.3718) lr 2.0000e-03 eta 5:07:41
epoch [2/10] batch [100/800] time 1.269 (2.441) data 0.000 (0.604) loss 0.0010 (0.3116) lr 2.0000e-03 eta 4:48:53
epoch [2/10] batch [120/800] time 1.908 (2.344) data 0.000 (0.504) loss 0.0030 (0.2717) lr 2.0000e-03 eta 4:36:37
epoch [2/10] batch [140/800] time 1.895 (2.273) data 0.000 (0.432) loss 0.0033 (0.2447) lr 2.0000e-03 eta 4:27:24
epoch [2/10] batch [160/800] time 1.892 (2.222) data 0.000 (0.378) loss 0.0431 (0.2203) lr 2.0000e-03 eta 4:20:41
epoch [2/10] batch [180/800] time 1.915 (2.178) data 0.000 (0.336) loss 0.0020 (0.2183) lr 2.0000e-03 eta 4:14:50
epoch [2/10] batch [200/800] time 1.907 (2.151) data 0.000 (0.302) loss 0.1560 (0.2135) lr 2.0000e-03 eta 4:10:56
epoch [2/10] batch [220/800] time 1.908 (2.125) data 0.000 (0.275) loss 0.0137 (0.2104) lr 2.0000e-03 eta 4:07:13
epoch [2/10] batch [240/800] time 1.725 (2.100) data 0.000 (0.252) loss 0.0102 (0.2019) lr 2.0000e-03 eta 4:03:36
epoch [2/10] batch [260/800] time 1.894 (2.082) data 0.000 (0.233) loss 4.4688 (0.2095) lr 2.0000e-03 eta 4:00:48
epoch [2/10] batch [280/800] time 1.721 (2.064) data 0.000 (0.216) loss 0.0002 (0.2000) lr 2.0000e-03 eta 3:58:00
epoch [2/10] batch [300/800] time 1.908 (2.051) data 0.000 (0.202) loss 0.0012 (0.1990) lr 2.0000e-03 eta 3:55:49
epoch [2/10] batch [320/800] time 1.914 (2.042) data 0.000 (0.189) loss 0.0001 (0.1962) lr 2.0000e-03 eta 3:54:07
epoch [2/10] batch [340/800] time 1.909 (2.029) data 0.000 (0.178) loss 0.0083 (0.2008) lr 2.0000e-03 eta 3:51:59
epoch [2/10] batch [360/800] time 1.909 (2.020) data 0.000 (0.168) loss 0.1016 (0.1920) lr 2.0000e-03 eta 3:50:17
epoch [2/10] batch [380/800] time 1.911 (2.013) data 0.000 (0.159) loss 0.0465 (0.1937) lr 2.0000e-03 eta 3:48:48
epoch [2/10] batch [400/800] time 1.909 (2.006) data 0.000 (0.151) loss 0.0175 (0.1855) lr 2.0000e-03 eta 3:47:18
epoch [2/10] batch [420/800] time 1.282 (1.998) data 0.000 (0.144) loss 0.2681 (0.1891) lr 2.0000e-03 eta 3:45:43
epoch [2/10] batch [440/800] time 1.913 (1.990) data 0.000 (0.138) loss 0.0008 (0.1895) lr 2.0000e-03 eta 3:44:13
epoch [2/10] batch [460/800] time 1.910 (1.985) data 0.000 (0.132) loss 0.0151 (0.1918) lr 2.0000e-03 eta 3:42:57
epoch [2/10] batch [480/800] time 1.909 (1.981) data 0.000 (0.126) loss 0.0143 (0.1939) lr 2.0000e-03 eta 3:41:55
epoch [2/10] batch [500/800] time 1.894 (1.978) data 0.000 (0.121) loss 0.0001 (0.1938) lr 2.0000e-03 eta 3:40:55
epoch [2/10] batch [520/800] time 1.910 (1.976) data 0.000 (0.117) loss 0.0256 (0.1925) lr 2.0000e-03 eta 3:39:57
epoch [2/10] batch [540/800] time 1.909 (1.972) data 0.000 (0.112) loss 0.0875 (0.1898) lr 2.0000e-03 eta 3:38:51
epoch [2/10] batch [560/800] time 1.737 (1.966) data 0.016 (0.108) loss 0.0095 (0.1971) lr 2.0000e-03 eta 3:37:36
epoch [2/10] batch [580/800] time 1.910 (1.963) data 0.000 (0.105) loss 0.1079 (0.1964) lr 2.0000e-03 eta 3:36:35
epoch [2/10] batch [600/800] time 1.925 (1.960) data 0.000 (0.101) loss 0.0008 (0.1908) lr 2.0000e-03 eta 3:35:34
epoch [2/10] batch [620/800] time 1.908 (1.958) data 0.000 (0.098) loss 0.0004 (0.1889) lr 2.0000e-03 eta 3:34:44
epoch [2/10] batch [640/800] time 1.893 (1.954) data 0.000 (0.095) loss 0.0003 (0.1876) lr 2.0000e-03 eta 3:33:37
epoch [2/10] batch [660/800] time 1.909 (1.951) data 0.000 (0.092) loss 0.0002 (0.1844) lr 2.0000e-03 eta 3:32:41
epoch [2/10] batch [680/800] time 1.910 (1.949) data 0.000 (0.089) loss 0.0024 (0.1843) lr 2.0000e-03 eta 3:31:45
epoch [2/10] batch [700/800] time 1.914 (1.946) data 0.000 (0.087) loss 0.0006 (0.1843) lr 2.0000e-03 eta 3:30:51
epoch [2/10] batch [720/800] time 1.910 (1.945) data 0.000 (0.084) loss 0.0061 (0.1831) lr 2.0000e-03 eta 3:30:05
epoch [2/10] batch [740/800] time 1.897 (1.944) data 0.000 (0.082) loss 0.0007 (0.1794) lr 2.0000e-03 eta 3:29:20
epoch [2/10] batch [760/800] time 1.908 (1.942) data 0.000 (0.080) loss 0.5366 (0.1782) lr 2.0000e-03 eta 3:28:27
epoch [2/10] batch [780/800] time 1.893 (1.940) data 0.000 (0.078) loss 0.0000 (0.1753) lr 2.0000e-03 eta 3:27:36
epoch [2/10] batch [800/800] time 1.909 (1.939) data 0.000 (0.076) loss 0.0240 (0.1722) lr 1.9511e-03 eta 3:26:51
epoch [3/10] batch [20/800] time 1.893 (4.843) data 0.000 (3.000) loss 0.4124 (0.1467) lr 1.9511e-03 eta 8:35:01
epoch [3/10] batch [40/800] time 1.910 (3.375) data 0.000 (1.500) loss 0.0091 (0.1100) lr 1.9511e-03 eta 5:57:47
epoch [3/10] batch [60/800] time 1.908 (2.839) data 0.000 (1.000) loss 0.0117 (0.1926) lr 1.9511e-03 eta 4:59:59
epoch [3/10] batch [80/800] time 1.910 (2.606) data 0.000 (0.751) loss 0.0003 (0.1689) lr 1.9511e-03 eta 4:34:30
epoch [3/10] batch [100/800] time 1.908 (2.467) data 0.000 (0.601) loss 0.0003 (0.1449) lr 1.9511e-03 eta 4:19:00
epoch [3/10] batch [120/800] time 1.908 (2.373) data 0.000 (0.500) loss 0.0163 (0.1508) lr 1.9511e-03 eta 4:08:25
epoch [3/10] batch [140/800] time 1.909 (2.289) data 0.000 (0.429) loss 0.0461 (0.1450) lr 1.9511e-03 eta 3:58:50
epoch [3/10] batch [160/800] time 1.905 (2.242) data 0.000 (0.375) loss 0.0002 (0.1290) lr 1.9511e-03 eta 3:53:07
epoch [3/10] batch [180/800] time 1.893 (2.200) data 0.000 (0.334) loss 0.2085 (0.1216) lr 1.9511e-03 eta 3:48:01
epoch [3/10] batch [200/800] time 1.899 (2.170) data 0.000 (0.300) loss 0.0006 (0.1176) lr 1.9511e-03 eta 3:44:16
epoch [3/10] batch [220/800] time 1.893 (2.142) data 0.000 (0.273) loss 0.0001 (0.1131) lr 1.9511e-03 eta 3:40:40
epoch [3/10] batch [240/800] time 1.910 (2.119) data 0.000 (0.250) loss 0.0010 (0.1043) lr 1.9511e-03 eta 3:37:34
epoch [3/10] batch [260/800] time 1.909 (2.103) data 0.000 (0.231) loss 0.0111 (0.1061) lr 1.9511e-03 eta 3:35:11
epoch [3/10] batch [280/800] time 1.909 (2.086) data 0.000 (0.215) loss 0.0032 (0.1007) lr 1.9511e-03 eta 3:32:45
epoch [3/10] batch [300/800] time 1.892 (2.069) data 0.000 (0.200) loss 0.0023 (0.0999) lr 1.9511e-03 eta 3:30:17
epoch [3/10] batch [320/800] time 1.903 (2.058) data 0.000 (0.188) loss 0.0001 (0.1014) lr 1.9511e-03 eta 3:28:34
epoch [3/10] batch [340/800] time 1.897 (2.044) data 0.000 (0.177) loss 0.0002 (0.1066) lr 1.9511e-03 eta 3:26:29
epoch [3/10] batch [360/800] time 1.898 (2.037) data 0.000 (0.167) loss 0.0028 (0.1064) lr 1.9511e-03 eta 3:25:01
epoch [3/10] batch [380/800] time 1.907 (2.028) data 0.000 (0.158) loss 0.0005 (0.1058) lr 1.9511e-03 eta 3:23:26
epoch [3/10] batch [400/800] time 1.912 (2.019) data 0.000 (0.150) loss 0.0002 (0.1132) lr 1.9511e-03 eta 3:21:56
epoch [3/10] batch [420/800] time 1.909 (2.014) data 0.000 (0.143) loss 0.0001 (0.1154) lr 1.9511e-03 eta 3:20:44
epoch [3/10] batch [440/800] time 1.924 (2.007) data 0.016 (0.137) loss 0.0173 (0.1218) lr 1.9511e-03 eta 3:19:23
epoch [3/10] batch [460/800] time 1.909 (2.000) data 0.000 (0.131) loss 0.0001 (0.1231) lr 1.9511e-03 eta 3:18:01
epoch [3/10] batch [480/800] time 1.910 (1.996) data 0.000 (0.125) loss 0.0001 (0.1226) lr 1.9511e-03 eta 3:16:57
epoch [3/10] batch [500/800] time 1.910 (1.991) data 0.000 (0.120) loss 0.0001 (0.1228) lr 1.9511e-03 eta 3:15:46
epoch [3/10] batch [520/800] time 1.721 (1.986) data 0.000 (0.116) loss 0.1501 (0.1283) lr 1.9511e-03 eta 3:14:38
epoch [3/10] batch [540/800] time 1.743 (1.980) data 0.000 (0.111) loss 0.0007 (0.1306) lr 1.9511e-03 eta 3:13:23
epoch [3/10] batch [560/800] time 1.908 (1.975) data 0.000 (0.107) loss 0.0002 (0.1269) lr 1.9511e-03 eta 3:12:11
epoch [3/10] batch [580/800] time 1.909 (1.972) data 0.000 (0.104) loss 0.0014 (0.1260) lr 1.9511e-03 eta 3:11:18
epoch [3/10] batch [600/800] time 1.909 (1.966) data 0.000 (0.100) loss 0.0058 (0.1245) lr 1.9511e-03 eta 3:10:02
epoch [3/10] batch [620/800] time 1.912 (1.961) data 0.000 (0.097) loss 0.0000 (0.1225) lr 1.9511e-03 eta 3:08:56
epoch [3/10] batch [640/800] time 1.910 (1.960) data 0.000 (0.094) loss 0.0671 (0.1198) lr 1.9511e-03 eta 3:08:07
epoch [3/10] batch [660/800] time 1.912 (1.958) data 0.000 (0.091) loss 0.0023 (0.1203) lr 1.9511e-03 eta 3:07:19
epoch [3/10] batch [680/800] time 1.909 (1.955) data 0.000 (0.089) loss 0.0006 (0.1193) lr 1.9511e-03 eta 3:06:24
epoch [3/10] batch [700/800] time 1.252 (1.952) data 0.000 (0.086) loss 0.7749 (0.1183) lr 1.9511e-03 eta 3:05:25
epoch [3/10] batch [720/800] time 1.893 (1.950) data 0.000 (0.084) loss 0.0075 (0.1165) lr 1.9511e-03 eta 3:04:37
epoch [3/10] batch [740/800] time 1.909 (1.949) data 0.000 (0.081) loss 0.0004 (0.1163) lr 1.9511e-03 eta 3:03:52
epoch [3/10] batch [760/800] time 1.282 (1.946) data 0.000 (0.079) loss 0.1198 (0.1163) lr 1.9511e-03 eta 3:02:53
epoch [3/10] batch [780/800] time 1.908 (1.944) data 0.000 (0.077) loss 0.0003 (0.1192) lr 1.9511e-03 eta 3:02:05
epoch [3/10] batch [800/800] time 1.893 (1.943) data 0.000 (0.075) loss 0.0001 (0.1186) lr 1.8090e-03 eta 3:01:21
epoch [4/10] batch [20/800] time 1.909 (4.754) data 0.000 (2.960) loss 0.0003 (0.0706) lr 1.8090e-03 eta 7:22:09
epoch [4/10] batch [40/800] time 1.267 (3.315) data 0.000 (1.480) loss 0.4971 (0.1016) lr 1.8090e-03 eta 5:07:10
epoch [4/10] batch [60/800] time 1.893 (2.800) data 0.000 (0.987) loss 0.0034 (0.0799) lr 1.8090e-03 eta 4:18:32
epoch [4/10] batch [80/800] time 1.910 (2.556) data 0.000 (0.740) loss 0.0001 (0.0782) lr 1.8090e-03 eta 3:55:10
epoch [4/10] batch [100/800] time 1.741 (2.418) data 0.000 (0.592) loss 0.2313 (0.0728) lr 1.8090e-03 eta 3:41:40
epoch [4/10] batch [120/800] time 1.706 (2.326) data 0.000 (0.494) loss 0.0017 (0.0638) lr 1.8090e-03 eta 3:32:24
epoch [4/10] batch [140/800] time 1.913 (2.265) data 0.000 (0.423) loss 0.1604 (0.0615) lr 1.8090e-03 eta 3:26:09
epoch [4/10] batch [160/800] time 1.909 (2.221) data 0.000 (0.370) loss 0.0106 (0.0725) lr 1.8090e-03 eta 3:21:20
epoch [4/10] batch [180/800] time 1.912 (2.186) data 0.000 (0.329) loss 0.0011 (0.0674) lr 1.8090e-03 eta 3:17:25
epoch [4/10] batch [200/800] time 1.893 (2.158) data 0.000 (0.296) loss 0.0002 (0.0732) lr 1.8090e-03 eta 3:14:11
epoch [4/10] batch [220/800] time 1.909 (2.135) data 0.000 (0.269) loss 0.0130 (0.0792) lr 1.8090e-03 eta 3:11:26
epoch [4/10] batch [240/800] time 1.877 (2.109) data 0.000 (0.247) loss 0.0002 (0.0753) lr 1.8090e-03 eta 3:08:23
epoch [4/10] batch [260/800] time 1.909 (2.087) data 0.000 (0.228) loss 0.0006 (0.0700) lr 1.8090e-03 eta 3:05:45
epoch [4/10] batch [280/800] time 1.267 (2.072) data 0.000 (0.212) loss 0.0003 (0.0663) lr 1.8090e-03 eta 3:03:43
epoch [4/10] batch [300/800] time 1.909 (2.060) data 0.000 (0.198) loss 0.0000 (0.0722) lr 1.8090e-03 eta 3:01:59
epoch [4/10] batch [320/800] time 1.898 (2.051) data 0.000 (0.185) loss 0.0003 (0.0682) lr 1.8090e-03 eta 3:00:27
epoch [4/10] batch [340/800] time 1.925 (2.040) data 0.000 (0.174) loss 0.0318 (0.0688) lr 1.8090e-03 eta 2:58:49
epoch [4/10] batch [360/800] time 1.909 (2.032) data 0.000 (0.165) loss 0.0020 (0.0683) lr 1.8090e-03 eta 2:57:30
epoch [4/10] batch [380/800] time 1.896 (2.021) data 0.000 (0.156) loss 0.0000 (0.0683) lr 1.8090e-03 eta 2:55:51
epoch [4/10] batch [400/800] time 1.908 (2.014) data 0.000 (0.148) loss 0.0000 (0.0703) lr 1.8090e-03 eta 2:54:31
epoch [4/10] batch [420/800] time 1.894 (2.009) data 0.000 (0.141) loss 0.0002 (0.0741) lr 1.8090e-03 eta 2:53:24
epoch [4/10] batch [440/800] time 1.736 (2.002) data 0.000 (0.135) loss 0.0012 (0.0739) lr 1.8090e-03 eta 2:52:10
epoch [4/10] batch [460/800] time 1.908 (1.996) data 0.000 (0.129) loss 0.0028 (0.0726) lr 1.8090e-03 eta 2:50:59
epoch [4/10] batch [480/800] time 1.914 (1.989) data 0.016 (0.124) loss 0.0937 (0.0740) lr 1.8090e-03 eta 2:49:43
epoch [4/10] batch [500/800] time 1.908 (1.986) data 0.000 (0.119) loss 0.0006 (0.0714) lr 1.8090e-03 eta 2:48:46
epoch [4/10] batch [520/800] time 1.908 (1.981) data 0.000 (0.114) loss 0.0001 (0.0715) lr 1.8090e-03 eta 2:47:43
epoch [4/10] batch [540/800] time 1.908 (1.977) data 0.000 (0.110) loss 0.0004 (0.0707) lr 1.8090e-03 eta 2:46:42
epoch [4/10] batch [560/800] time 1.926 (1.973) data 0.000 (0.106) loss 0.0000 (0.0729) lr 1.8090e-03 eta 2:45:42
epoch [4/10] batch [580/800] time 1.738 (1.968) data 0.000 (0.102) loss 0.0001 (0.0723) lr 1.8090e-03 eta 2:44:37
epoch [4/10] batch [600/800] time 1.923 (1.966) data 0.000 (0.099) loss 0.0006 (0.0734) lr 1.8090e-03 eta 2:43:48
epoch [4/10] batch [620/800] time 1.725 (1.960) data 0.000 (0.096) loss 0.0000 (0.0737) lr 1.8090e-03 eta 2:42:38
epoch [4/10] batch [640/800] time 1.892 (1.957) data 0.000 (0.093) loss 0.0006 (0.0730) lr 1.8090e-03 eta 2:41:44
epoch [4/10] batch [660/800] time 1.266 (1.950) data 0.000 (0.090) loss 0.6040 (0.0730) lr 1.8090e-03 eta 2:40:34
epoch [4/10] batch [680/800] time 1.893 (1.948) data 0.000 (0.087) loss 0.0072 (0.0803) lr 1.8090e-03 eta 2:39:42
epoch [4/10] batch [700/800] time 1.910 (1.946) data 0.000 (0.085) loss 0.0007 (0.0783) lr 1.8090e-03 eta 2:38:57
epoch [4/10] batch [720/800] time 1.910 (1.945) data 0.000 (0.082) loss 0.0001 (0.0805) lr 1.8090e-03 eta 2:38:12
epoch [4/10] batch [740/800] time 1.902 (1.944) data 0.000 (0.080) loss 1.6758 (0.0866) lr 1.8090e-03 eta 2:37:29
epoch [4/10] batch [760/800] time 1.909 (1.943) data 0.000 (0.078) loss 0.0003 (0.0871) lr 1.8090e-03 eta 2:36:45
epoch [4/10] batch [780/800] time 1.920 (1.940) data 0.000 (0.076) loss 0.0025 (0.0877) lr 1.8090e-03 eta 2:35:51
epoch [4/10] batch [800/800] time 1.910 (1.939) data 0.000 (0.074) loss 0.0004 (0.0888) lr 1.5878e-03 eta 2:35:08
epoch [5/10] batch [20/800] time 1.900 (4.627) data 0.000 (2.938) loss 0.0001 (0.0332) lr 1.5878e-03 eta 6:08:35
epoch [5/10] batch [40/800] time 1.919 (3.244) data 0.000 (1.470) loss 0.0007 (0.0404) lr 1.5878e-03 eta 4:17:22
epoch [5/10] batch [60/800] time 1.914 (2.784) data 0.000 (0.980) loss 0.0000 (0.0443) lr 1.5878e-03 eta 3:39:55
epoch [5/10] batch [80/800] time 1.909 (2.554) data 0.000 (0.735) loss 0.3591 (0.0511) lr 1.5878e-03 eta 3:20:52
epoch [5/10] batch [100/800] time 1.908 (2.416) data 0.000 (0.588) loss 0.0004 (0.0546) lr 1.5878e-03 eta 3:09:13
epoch [5/10] batch [120/800] time 1.267 (2.325) data 0.000 (0.490) loss 0.0000 (0.0508) lr 1.5878e-03 eta 3:01:23
epoch [5/10] batch [140/800] time 1.893 (2.264) data 0.000 (0.420) loss 0.6040 (0.0537) lr 1.5878e-03 eta 2:55:50
epoch [5/10] batch [160/800] time 1.737 (2.214) data 0.000 (0.368) loss 0.0128 (0.0653) lr 1.5878e-03 eta 2:51:14
epoch [5/10] batch [180/800] time 1.267 (2.167) data 0.000 (0.327) loss 0.0026 (0.0619) lr 1.5878e-03 eta 2:46:53
epoch [5/10] batch [200/800] time 1.893 (2.135) data 0.000 (0.294) loss 0.0290 (0.0575) lr 1.5878e-03 eta 2:43:39
epoch [5/10] batch [220/800] time 1.893 (2.110) data 0.000 (0.268) loss 0.0020 (0.0591) lr 1.5878e-03 eta 2:41:04
epoch [5/10] batch [240/800] time 1.910 (2.093) data 0.000 (0.245) loss 0.5762 (0.0778) lr 1.5878e-03 eta 2:39:04
epoch [5/10] batch [260/800] time 1.890 (2.075) data 0.000 (0.227) loss 0.0021 (0.0764) lr 1.5878e-03 eta 2:37:02
epoch [5/10] batch [280/800] time 1.892 (2.060) data 0.000 (0.210) loss 0.0003 (0.0714) lr 1.5878e-03 eta 2:35:13
epoch [5/10] batch [300/800] time 1.898 (2.050) data 0.000 (0.196) loss 0.0004 (0.0711) lr 1.5878e-03 eta 2:33:45
epoch [5/10] batch [320/800] time 1.267 (2.039) data 0.000 (0.184) loss 0.0001 (0.0701) lr 1.5878e-03 eta 2:32:16
epoch [5/10] batch [340/800] time 1.910 (2.031) data 0.000 (0.173) loss 0.0000 (0.0666) lr 1.5878e-03 eta 2:30:57
epoch [5/10] batch [360/800] time 1.896 (2.024) data 0.000 (0.164) loss 0.0000 (0.0648) lr 1.5878e-03 eta 2:29:46
epoch [5/10] batch [380/800] time 1.909 (2.018) data 0.000 (0.155) loss 0.0381 (0.0653) lr 1.5878e-03 eta 2:28:38
epoch [5/10] batch [400/800] time 1.909 (2.012) data 0.000 (0.147) loss 0.0088 (0.0634) lr 1.5878e-03 eta 2:27:33
epoch [5/10] batch [420/800] time 1.910 (2.007) data 0.000 (0.140) loss 0.0656 (0.0724) lr 1.5878e-03 eta 2:26:31
epoch [5/10] batch [440/800] time 1.924 (2.001) data 0.000 (0.134) loss 0.0019 (0.0771) lr 1.5878e-03 eta 2:25:23
epoch [5/10] batch [460/800] time 1.909 (1.995) data 0.000 (0.128) loss 0.1959 (0.0788) lr 1.5878e-03 eta 2:24:17
epoch [5/10] batch [480/800] time 1.899 (1.991) data 0.000 (0.123) loss 0.0033 (0.0790) lr 1.5878e-03 eta 2:23:21
epoch [5/10] batch [500/800] time 1.267 (1.984) data 0.000 (0.118) loss 0.0000 (0.0804) lr 1.5878e-03 eta 2:22:10
epoch [5/10] batch [520/800] time 1.892 (1.981) data 0.000 (0.113) loss 0.0973 (0.0793) lr 1.5878e-03 eta 2:21:17
epoch [5/10] batch [540/800] time 1.908 (1.978) data 0.000 (0.109) loss 0.0734 (0.0778) lr 1.5878e-03 eta 2:20:25
epoch [5/10] batch [560/800] time 1.910 (1.975) data 0.000 (0.105) loss 0.0001 (0.0766) lr 1.5878e-03 eta 2:19:35
epoch [5/10] batch [580/800] time 1.902 (1.971) data 0.000 (0.102) loss 0.0002 (0.0776) lr 1.5878e-03 eta 2:18:39
epoch [5/10] batch [600/800] time 1.910 (1.969) data 0.000 (0.098) loss 0.0002 (0.0767) lr 1.5878e-03 eta 2:17:51
epoch [5/10] batch [620/800] time 1.894 (1.967) data 0.000 (0.095) loss 0.0090 (0.0773) lr 1.5878e-03 eta 2:17:03
epoch [5/10] batch [640/800] time 1.909 (1.965) data 0.000 (0.092) loss 0.0130 (0.0766) lr 1.5878e-03 eta 2:16:15
epoch [5/10] batch [660/800] time 1.910 (1.961) data 0.000 (0.089) loss 0.0037 (0.0765) lr 1.5878e-03 eta 2:15:18
epoch [5/10] batch [680/800] time 1.913 (1.958) data 0.000 (0.087) loss 0.0000 (0.0820) lr 1.5878e-03 eta 2:14:27
epoch [5/10] batch [700/800] time 1.894 (1.955) data 0.000 (0.084) loss 0.0002 (0.0826) lr 1.5878e-03 eta 2:13:37
epoch [5/10] batch [720/800] time 1.928 (1.954) data 0.000 (0.082) loss 0.0004 (0.0817) lr 1.5878e-03 eta 2:12:52
epoch [5/10] batch [740/800] time 1.911 (1.951) data 0.000 (0.080) loss 0.0001 (0.0819) lr 1.5878e-03 eta 2:12:03
epoch [5/10] batch [760/800] time 1.917 (1.949) data 0.000 (0.078) loss 0.0006 (0.0801) lr 1.5878e-03 eta 2:11:14
epoch [5/10] batch [780/800] time 1.908 (1.948) data 0.000 (0.076) loss 0.0002 (0.0790) lr 1.5878e-03 eta 2:10:29
epoch [5/10] batch [800/800] time 1.898 (1.947) data 0.000 (0.074) loss 0.0005 (0.0790) lr 1.3090e-03 eta 2:09:46
epoch [6/10] batch [20/800] time 1.893 (4.674) data 0.000 (2.950) loss 0.0000 (0.0303) lr 1.3090e-03 eta 5:10:01
epoch [6/10] batch [40/800] time 1.908 (3.250) data 0.000 (1.475) loss 0.0028 (0.0211) lr 1.3090e-03 eta 3:34:28
epoch [6/10] batch [60/800] time 1.909 (2.802) data 0.000 (0.983) loss 0.0004 (0.0401) lr 1.3090e-03 eta 3:03:59
epoch [6/10] batch [80/800] time 1.910 (2.548) data 0.000 (0.738) loss 0.0008 (0.0696) lr 1.3090e-03 eta 2:46:27
epoch [6/10] batch [100/800] time 1.899 (2.411) data 0.000 (0.590) loss 0.0056 (0.0743) lr 1.3090e-03 eta 2:36:43
epoch [6/10] batch [120/800] time 1.908 (2.327) data 0.016 (0.492) loss 0.0051 (0.0648) lr 1.3090e-03 eta 2:30:27
epoch [6/10] batch [140/800] time 1.910 (2.267) data 0.000 (0.422) loss 0.0000 (0.0744) lr 1.3090e-03 eta 2:25:50
epoch [6/10] batch [160/800] time 1.892 (2.222) data 0.000 (0.369) loss 0.0013 (0.0692) lr 1.3090e-03 eta 2:22:11
epoch [6/10] batch [180/800] time 1.914 (2.182) data 0.000 (0.328) loss 0.0001 (0.0625) lr 1.3090e-03 eta 2:18:55
epoch [6/10] batch [200/800] time 1.909 (2.150) data 0.016 (0.295) loss 0.0153 (0.0664) lr 1.3090e-03 eta 2:16:11
epoch [6/10] batch [220/800] time 1.909 (2.124) data 0.000 (0.269) loss 0.0017 (0.0619) lr 1.3090e-03 eta 2:13:49
epoch [6/10] batch [240/800] time 1.909 (2.106) data 0.000 (0.246) loss 0.0000 (0.0631) lr 1.3090e-03 eta 2:11:59
epoch [6/10] batch [260/800] time 1.909 (2.088) data 0.000 (0.227) loss 0.0001 (0.0772) lr 1.3090e-03 eta 2:10:07
epoch [6/10] batch [280/800] time 1.909 (2.069) data 0.000 (0.211) loss 0.0004 (0.0778) lr 1.3090e-03 eta 2:08:15
epoch [6/10] batch [300/800] time 1.892 (2.055) data 0.000 (0.197) loss 0.0817 (0.0763) lr 1.3090e-03 eta 2:06:43
epoch [6/10] batch [320/800] time 1.893 (2.043) data 0.000 (0.185) loss 0.0003 (0.0755) lr 1.3090e-03 eta 2:05:17
epoch [6/10] batch [340/800] time 1.908 (2.035) data 0.000 (0.174) loss 0.0916 (0.0732) lr 1.3090e-03 eta 2:04:07
epoch [6/10] batch [360/800] time 1.903 (2.026) data 0.000 (0.164) loss 0.0000 (0.0697) lr 1.3090e-03 eta 2:02:53
epoch [6/10] batch [380/800] time 1.894 (2.015) data 0.000 (0.155) loss 0.0000 (0.0691) lr 1.3090e-03 eta 2:01:34
epoch [6/10] batch [400/800] time 1.724 (2.006) data 0.000 (0.148) loss 0.0002 (0.0669) lr 1.3090e-03 eta 2:00:20
epoch [6/10] batch [420/800] time 1.892 (1.999) data 0.000 (0.141) loss 0.0000 (0.0673) lr 1.3090e-03 eta 1:59:16
epoch [6/10] batch [440/800] time 1.892 (1.993) data 0.000 (0.134) loss 0.2590 (0.0651) lr 1.3090e-03 eta 1:58:14
epoch [6/10] batch [460/800] time 1.897 (1.987) data 0.000 (0.129) loss 0.0002 (0.0657) lr 1.3090e-03 eta 1:57:14
epoch [6/10] batch [480/800] time 1.922 (1.982) data 0.000 (0.123) loss 0.2461 (0.0660) lr 1.3090e-03 eta 1:56:17
epoch [6/10] batch [500/800] time 1.899 (1.978) data 0.000 (0.118) loss 0.0167 (0.0643) lr 1.3090e-03 eta 1:55:21
epoch [6/10] batch [520/800] time 1.892 (1.972) data 0.000 (0.114) loss 0.0000 (0.0724) lr 1.3090e-03 eta 1:54:21
epoch [6/10] batch [540/800] time 1.892 (1.969) data 0.000 (0.110) loss 0.8989 (0.0717) lr 1.3090e-03 eta 1:53:34
epoch [6/10] batch [560/800] time 1.910 (1.966) data 0.000 (0.106) loss 0.0002 (0.0707) lr 1.3090e-03 eta 1:52:42
epoch [6/10] batch [580/800] time 1.909 (1.962) data 0.000 (0.102) loss 0.0028 (0.0684) lr 1.3090e-03 eta 1:51:51
epoch [6/10] batch [600/800] time 1.895 (1.958) data 0.000 (0.099) loss 0.0000 (0.0687) lr 1.3090e-03 eta 1:50:55
epoch [6/10] batch [620/800] time 1.893 (1.953) data 0.000 (0.095) loss 0.0072 (0.0693) lr 1.3090e-03 eta 1:50:02
epoch [6/10] batch [640/800] time 1.909 (1.949) data 0.000 (0.092) loss 0.0032 (0.0710) lr 1.3090e-03 eta 1:49:09
epoch [6/10] batch [660/800] time 1.898 (1.947) data 0.000 (0.090) loss 0.1079 (0.0705) lr 1.3090e-03 eta 1:48:21
epoch [6/10] batch [680/800] time 1.897 (1.944) data 0.000 (0.087) loss 0.0001 (0.0711) lr 1.3090e-03 eta 1:47:34
epoch [6/10] batch [700/800] time 1.914 (1.941) data 0.000 (0.085) loss 0.0000 (0.0708) lr 1.3090e-03 eta 1:46:44
epoch [6/10] batch [720/800] time 1.916 (1.939) data 0.000 (0.082) loss 0.3396 (0.0703) lr 1.3090e-03 eta 1:45:58
epoch [6/10] batch [740/800] time 1.909 (1.937) data 0.000 (0.080) loss 0.2255 (0.0711) lr 1.3090e-03 eta 1:45:13
epoch [6/10] batch [760/800] time 1.901 (1.933) data 0.000 (0.078) loss 0.0004 (0.0714) lr 1.3090e-03 eta 1:44:21
epoch [6/10] batch [780/800] time 1.915 (1.932) data 0.000 (0.076) loss 0.0015 (0.0714) lr 1.3090e-03 eta 1:43:40
epoch [6/10] batch [800/800] time 1.896 (1.931) data 0.000 (0.074) loss 0.0171 (0.0724) lr 1.0000e-03 eta 1:42:59
epoch [7/10] batch [20/800] time 1.915 (4.642) data 0.000 (2.948) loss 0.0000 (0.0476) lr 1.0000e-03 eta 4:06:01
epoch [7/10] batch [40/800] time 1.927 (3.230) data 0.000 (1.474) loss 0.0504 (0.0565) lr 1.0000e-03 eta 2:50:06
epoch [7/10] batch [60/800] time 1.898 (2.789) data 0.000 (0.983) loss 0.7251 (0.0687) lr 1.0000e-03 eta 2:25:58
epoch [7/10] batch [80/800] time 1.892 (2.547) data 0.000 (0.737) loss 0.0725 (0.0740) lr 1.0000e-03 eta 2:12:25
epoch [7/10] batch [100/800] time 1.908 (2.410) data 0.000 (0.590) loss 0.0000 (0.0653) lr 1.0000e-03 eta 2:04:31
epoch [7/10] batch [120/800] time 1.912 (2.326) data 0.000 (0.491) loss 0.0004 (0.0785) lr 1.0000e-03 eta 1:59:24
epoch [7/10] batch [140/800] time 1.908 (2.266) data 0.000 (0.421) loss 0.0001 (0.0749) lr 1.0000e-03 eta 1:55:34
epoch [7/10] batch [160/800] time 1.907 (2.211) data 0.000 (0.369) loss 0.0000 (0.0764) lr 1.0000e-03 eta 1:52:00
epoch [7/10] batch [180/800] time 1.900 (2.168) data 0.000 (0.328) loss 0.2159 (0.0746) lr 1.0000e-03 eta 1:49:06
epoch [7/10] batch [200/800] time 1.909 (2.142) data 0.000 (0.295) loss 0.1425 (0.0709) lr 1.0000e-03 eta 1:47:04
epoch [7/10] batch [220/800] time 1.909 (2.113) data 0.000 (0.268) loss 0.0104 (0.0749) lr 1.0000e-03 eta 1:44:55
epoch [7/10] batch [240/800] time 1.909 (2.092) data 0.000 (0.246) loss 0.0018 (0.0738) lr 1.0000e-03 eta 1:43:12
epoch [7/10] batch [260/800] time 1.909 (2.078) data 0.000 (0.227) loss 0.0006 (0.0737) lr 1.0000e-03 eta 1:41:48
epoch [7/10] batch [280/800] time 1.900 (2.056) data 0.000 (0.211) loss 0.0001 (0.0755) lr 1.0000e-03 eta 1:40:04
epoch [7/10] batch [300/800] time 1.908 (2.046) data 0.000 (0.197) loss 0.0499 (0.0743) lr 1.0000e-03 eta 1:38:54
epoch [7/10] batch [320/800] time 1.898 (2.038) data 0.000 (0.184) loss 0.0003 (0.0701) lr 1.0000e-03 eta 1:37:48
epoch [7/10] batch [340/800] time 1.900 (2.025) data 0.000 (0.174) loss 0.0083 (0.0666) lr 1.0000e-03 eta 1:36:31
epoch [7/10] batch [360/800] time 1.910 (2.018) data 0.000 (0.164) loss 0.0002 (0.0647) lr 1.0000e-03 eta 1:35:31
epoch [7/10] batch [380/800] time 1.720 (2.008) data 0.000 (0.155) loss 0.0040 (0.0635) lr 1.0000e-03 eta 1:34:22
epoch [7/10] batch [400/800] time 1.909 (2.003) data 0.000 (0.148) loss 0.0002 (0.0633) lr 1.0000e-03 eta 1:33:28
epoch [7/10] batch [420/800] time 1.893 (1.998) data 0.000 (0.141) loss 0.0002 (0.0632) lr 1.0000e-03 eta 1:32:35
epoch [7/10] batch [440/800] time 1.912 (1.990) data 0.000 (0.134) loss 0.0002 (0.0613) lr 1.0000e-03 eta 1:31:32
epoch [7/10] batch [460/800] time 1.899 (1.986) data 0.000 (0.128) loss 0.0000 (0.0698) lr 1.0000e-03 eta 1:30:42
epoch [7/10] batch [480/800] time 1.895 (1.979) data 0.000 (0.123) loss 0.4180 (0.0682) lr 1.0000e-03 eta 1:29:44
epoch [7/10] batch [500/800] time 1.885 (1.973) data 0.000 (0.118) loss 0.0037 (0.0669) lr 1.0000e-03 eta 1:28:47
epoch [7/10] batch [520/800] time 1.894 (1.969) data 0.000 (0.114) loss 0.0000 (0.0644) lr 1.0000e-03 eta 1:27:57
epoch [7/10] batch [540/800] time 1.910 (1.962) data 0.000 (0.109) loss 1.1807 (0.0675) lr 1.0000e-03 eta 1:26:59
epoch [7/10] batch [560/800] time 1.674 (1.957) data 0.000 (0.105) loss 0.0327 (0.0663) lr 1.0000e-03 eta 1:26:06
epoch [7/10] batch [580/800] time 1.914 (1.952) data 0.000 (0.102) loss 0.0069 (0.0659) lr 1.0000e-03 eta 1:25:15
epoch [7/10] batch [600/800] time 1.694 (1.949) data 0.000 (0.098) loss 0.0128 (0.0639) lr 1.0000e-03 eta 1:24:28
epoch [7/10] batch [620/800] time 1.923 (1.948) data 0.000 (0.095) loss 0.0001 (0.0622) lr 1.0000e-03 eta 1:23:46
epoch [7/10] batch [640/800] time 1.890 (1.943) data 0.000 (0.092) loss 0.0000 (0.0618) lr 1.0000e-03 eta 1:22:53
epoch [7/10] batch [660/800] time 1.909 (1.942) data 0.000 (0.090) loss 0.4299 (0.0657) lr 1.0000e-03 eta 1:22:12
epoch [7/10] batch [680/800] time 1.912 (1.940) data 0.000 (0.087) loss 0.0075 (0.0640) lr 1.0000e-03 eta 1:21:28
epoch [7/10] batch [700/800] time 1.900 (1.938) data 0.000 (0.084) loss 0.0029 (0.0632) lr 1.0000e-03 eta 1:20:43
epoch [7/10] batch [720/800] time 1.894 (1.936) data 0.000 (0.082) loss 0.0242 (0.0619) lr 1.0000e-03 eta 1:20:00
epoch [7/10] batch [740/800] time 1.910 (1.935) data 0.000 (0.080) loss 0.0001 (0.0626) lr 1.0000e-03 eta 1:19:19
epoch [7/10] batch [760/800] time 1.893 (1.931) data 0.000 (0.078) loss 0.0041 (0.0615) lr 1.0000e-03 eta 1:18:30
epoch [7/10] batch [780/800] time 1.924 (1.930) data 0.000 (0.076) loss 0.0013 (0.0608) lr 1.0000e-03 eta 1:17:50
epoch [7/10] batch [800/800] time 1.895 (1.927) data 0.000 (0.074) loss 0.0003 (0.0609) lr 6.9098e-04 eta 1:17:05
epoch [8/10] batch [20/800] time 1.894 (4.561) data 0.000 (2.940) loss 0.0000 (0.0010) lr 6.9098e-04 eta 3:00:54
epoch [8/10] batch [40/800] time 1.899 (3.174) data 0.000 (1.470) loss 0.0014 (0.0266) lr 6.9098e-04 eta 2:04:50
epoch [8/10] batch [60/800] time 1.919 (2.737) data 0.000 (0.980) loss 0.0000 (0.0914) lr 6.9098e-04 eta 1:46:43
epoch [8/10] batch [80/800] time 1.899 (2.519) data 0.000 (0.735) loss 0.0000 (0.0747) lr 6.9098e-04 eta 1:37:23
epoch [8/10] batch [100/800] time 1.910 (2.371) data 0.000 (0.589) loss 0.0005 (0.0745) lr 6.9098e-04 eta 1:30:52
epoch [8/10] batch [120/800] time 1.910 (2.294) data 0.000 (0.491) loss 0.4983 (0.0697) lr 6.9098e-04 eta 1:27:09
epoch [8/10] batch [140/800] time 1.936 (2.232) data 0.000 (0.420) loss 0.0001 (0.0627) lr 6.9098e-04 eta 1:24:03
epoch [8/10] batch [160/800] time 1.908 (2.191) data 0.000 (0.368) loss 0.0001 (0.0571) lr 6.9098e-04 eta 1:21:47
epoch [8/10] batch [180/800] time 1.894 (2.159) data 0.000 (0.327) loss 0.0000 (0.0606) lr 6.9098e-04 eta 1:19:53
epoch [8/10] batch [200/800] time 1.926 (2.130) data 0.016 (0.294) loss 0.0003 (0.0583) lr 6.9098e-04 eta 1:18:05
epoch [8/10] batch [220/800] time 1.709 (2.102) data 0.000 (0.268) loss 0.0000 (0.0597) lr 6.9098e-04 eta 1:16:21
epoch [8/10] batch [240/800] time 1.271 (2.083) data 0.000 (0.245) loss 0.0000 (0.0572) lr 6.9098e-04 eta 1:14:59
epoch [8/10] batch [260/800] time 1.896 (2.062) data 0.000 (0.227) loss 0.0017 (0.0580) lr 6.9098e-04 eta 1:13:33
epoch [8/10] batch [280/800] time 1.903 (2.051) data 0.000 (0.210) loss 0.0000 (0.0580) lr 6.9098e-04 eta 1:12:28
epoch [8/10] batch [300/800] time 1.900 (2.037) data 0.000 (0.196) loss 0.0045 (0.0582) lr 6.9098e-04 eta 1:11:17
epoch [8/10] batch [320/800] time 1.909 (2.029) data 0.000 (0.184) loss 0.3049 (0.0588) lr 6.9098e-04 eta 1:10:19
epoch [8/10] batch [340/800] time 1.895 (2.017) data 0.000 (0.173) loss 0.0000 (0.0626) lr 6.9098e-04 eta 1:09:14
epoch [8/10] batch [360/800] time 1.912 (2.008) data 0.000 (0.164) loss 0.0002 (0.0628) lr 6.9098e-04 eta 1:08:16
epoch [8/10] batch [380/800] time 1.898 (1.998) data 0.000 (0.155) loss 0.0027 (0.0601) lr 6.9098e-04 eta 1:07:16
epoch [8/10] batch [400/800] time 1.897 (1.989) data 0.000 (0.147) loss 0.0051 (0.0606) lr 6.9098e-04 eta 1:06:17
epoch [8/10] batch [420/800] time 1.893 (1.985) data 0.000 (0.140) loss 0.0000 (0.0582) lr 6.9098e-04 eta 1:05:29
epoch [8/10] batch [440/800] time 1.889 (1.975) data 0.000 (0.134) loss 0.0000 (0.0580) lr 6.9098e-04 eta 1:04:31
epoch [8/10] batch [460/800] time 1.909 (1.971) data 0.000 (0.128) loss 0.0001 (0.0562) lr 6.9098e-04 eta 1:03:42
epoch [8/10] batch [480/800] time 1.919 (1.966) data 0.000 (0.123) loss 0.0004 (0.0546) lr 6.9098e-04 eta 1:02:55
epoch [8/10] batch [500/800] time 1.898 (1.964) data 0.000 (0.118) loss 0.0006 (0.0575) lr 6.9098e-04 eta 1:02:10
epoch [8/10] batch [520/800] time 1.895 (1.960) data 0.000 (0.113) loss 0.0011 (0.0565) lr 6.9098e-04 eta 1:01:24
epoch [8/10] batch [540/800] time 1.892 (1.955) data 0.000 (0.109) loss 0.7744 (0.0561) lr 6.9098e-04 eta 1:00:35
epoch [8/10] batch [560/800] time 1.924 (1.950) data 0.000 (0.105) loss 0.0077 (0.0549) lr 6.9098e-04 eta 0:59:47
epoch [8/10] batch [580/800] time 1.267 (1.943) data 0.000 (0.102) loss 0.1521 (0.0545) lr 6.9098e-04 eta 0:58:56
epoch [8/10] batch [600/800] time 1.901 (1.942) data 0.000 (0.098) loss 0.0000 (0.0544) lr 6.9098e-04 eta 0:58:14
epoch [8/10] batch [620/800] time 1.721 (1.939) data 0.000 (0.095) loss 0.0948 (0.0547) lr 6.9098e-04 eta 0:57:31
epoch [8/10] batch [640/800] time 1.911 (1.938) data 0.000 (0.092) loss 0.2385 (0.0546) lr 6.9098e-04 eta 0:56:50
epoch [8/10] batch [660/800] time 1.911 (1.937) data 0.000 (0.089) loss 0.9551 (0.0556) lr 6.9098e-04 eta 0:56:10
epoch [8/10] batch [680/800] time 1.721 (1.935) data 0.000 (0.087) loss 0.0535 (0.0563) lr 6.9098e-04 eta 0:55:28
epoch [8/10] batch [700/800] time 1.905 (1.933) data 0.000 (0.084) loss 0.0196 (0.0550) lr 6.9098e-04 eta 0:54:45
epoch [8/10] batch [720/800] time 1.705 (1.931) data 0.000 (0.082) loss 0.0004 (0.0545) lr 6.9098e-04 eta 0:54:03
epoch [8/10] batch [740/800] time 1.260 (1.929) data 0.000 (0.080) loss 0.0001 (0.0531) lr 6.9098e-04 eta 0:53:22
epoch [8/10] batch [760/800] time 1.904 (1.926) data 0.000 (0.078) loss 0.0006 (0.0539) lr 6.9098e-04 eta 0:52:39
epoch [8/10] batch [780/800] time 1.251 (1.925) data 0.000 (0.076) loss 0.0009 (0.0541) lr 6.9098e-04 eta 0:51:58
epoch [8/10] batch [800/800] time 1.896 (1.924) data 0.000 (0.074) loss 0.0108 (0.0586) lr 4.1221e-04 eta 0:51:18
epoch [9/10] batch [20/800] time 1.910 (4.717) data 0.000 (2.956) loss 0.0944 (0.0528) lr 4.1221e-04 eta 2:04:12
epoch [9/10] batch [40/800] time 1.910 (3.272) data 0.000 (1.479) loss 0.0000 (0.0385) lr 4.1221e-04 eta 1:25:04
epoch [9/10] batch [60/800] time 1.908 (2.817) data 0.000 (0.986) loss 0.0209 (0.0746) lr 4.1221e-04 eta 1:12:18
epoch [9/10] batch [80/800] time 1.892 (2.589) data 0.000 (0.740) loss 0.0020 (0.0582) lr 4.1221e-04 eta 1:05:35
epoch [9/10] batch [100/800] time 1.896 (2.427) data 0.000 (0.592) loss 0.0000 (0.0486) lr 4.1221e-04 eta 1:00:40
epoch [9/10] batch [120/800] time 1.719 (2.333) data 0.000 (0.493) loss 0.5903 (0.0613) lr 4.1221e-04 eta 0:57:33
epoch [9/10] batch [140/800] time 1.909 (2.266) data 0.000 (0.423) loss 0.0000 (0.0602) lr 4.1221e-04 eta 0:55:08
epoch [9/10] batch [160/800] time 1.901 (2.211) data 0.000 (0.370) loss 0.0001 (0.0593) lr 4.1221e-04 eta 0:53:03
epoch [9/10] batch [180/800] time 1.925 (2.177) data 0.000 (0.329) loss 0.0002 (0.0787) lr 4.1221e-04 eta 0:51:30
epoch [9/10] batch [200/800] time 1.910 (2.141) data 0.000 (0.296) loss 0.0000 (0.0730) lr 4.1221e-04 eta 0:49:57
epoch [9/10] batch [220/800] time 1.924 (2.116) data 0.016 (0.269) loss 0.0000 (0.0696) lr 4.1221e-04 eta 0:48:40
epoch [9/10] batch [240/800] time 1.908 (2.099) data 0.000 (0.247) loss 0.0001 (0.0662) lr 4.1221e-04 eta 0:47:34
epoch [9/10] batch [260/800] time 1.910 (2.077) data 0.000 (0.228) loss 0.0014 (0.0618) lr 4.1221e-04 eta 0:46:23
epoch [9/10] batch [280/800] time 1.912 (2.059) data 0.000 (0.212) loss 0.0001 (0.0625) lr 4.1221e-04 eta 0:45:18
epoch [9/10] batch [300/800] time 1.903 (2.046) data 0.000 (0.197) loss 0.0001 (0.0661) lr 4.1221e-04 eta 0:44:20
epoch [9/10] batch [320/800] time 1.905 (2.032) data 0.000 (0.185) loss 0.0003 (0.0684) lr 4.1221e-04 eta 0:43:21
epoch [9/10] batch [340/800] time 1.263 (2.018) data 0.000 (0.174) loss 0.0000 (0.0698) lr 4.1221e-04 eta 0:42:22
epoch [9/10] batch [360/800] time 1.909 (2.011) data 0.000 (0.165) loss 0.0001 (0.0663) lr 4.1221e-04 eta 0:41:33
epoch [9/10] batch [380/800] time 1.907 (2.002) data 0.000 (0.156) loss 0.0000 (0.0637) lr 4.1221e-04 eta 0:40:42
epoch [9/10] batch [400/800] time 1.254 (1.992) data 0.000 (0.148) loss 0.0006 (0.0636) lr 4.1221e-04 eta 0:39:50
epoch [9/10] batch [420/800] time 1.908 (1.987) data 0.016 (0.141) loss 0.0004 (0.0625) lr 4.1221e-04 eta 0:39:04
epoch [9/10] batch [440/800] time 1.911 (1.980) data 0.000 (0.135) loss 0.0001 (0.0604) lr 4.1221e-04 eta 0:38:16
epoch [9/10] batch [460/800] time 1.910 (1.975) data 0.000 (0.129) loss 0.0000 (0.0581) lr 4.1221e-04 eta 0:37:31
epoch [9/10] batch [480/800] time 1.928 (1.970) data 0.000 (0.123) loss 0.0001 (0.0579) lr 4.1221e-04 eta 0:36:46
epoch [9/10] batch [500/800] time 1.898 (1.968) data 0.000 (0.119) loss 0.0001 (0.0564) lr 4.1221e-04 eta 0:36:04
epoch [9/10] batch [520/800] time 1.911 (1.965) data 0.000 (0.114) loss 0.0000 (0.0555) lr 4.1221e-04 eta 0:35:22
epoch [9/10] batch [540/800] time 1.274 (1.959) data 0.000 (0.110) loss 0.0001 (0.0544) lr 4.1221e-04 eta 0:34:36
epoch [9/10] batch [560/800] time 1.913 (1.954) data 0.000 (0.106) loss 0.0003 (0.0561) lr 4.1221e-04 eta 0:33:52
epoch [9/10] batch [580/800] time 1.721 (1.951) data 0.000 (0.102) loss 0.0001 (0.0561) lr 4.1221e-04 eta 0:33:10
epoch [9/10] batch [600/800] time 1.909 (1.948) data 0.000 (0.099) loss 0.0145 (0.0546) lr 4.1221e-04 eta 0:32:28
epoch [9/10] batch [620/800] time 1.252 (1.946) data 0.000 (0.096) loss 0.0661 (0.0551) lr 4.1221e-04 eta 0:31:46
epoch [9/10] batch [640/800] time 1.910 (1.940) data 0.000 (0.093) loss 0.0002 (0.0546) lr 4.1221e-04 eta 0:31:02
epoch [9/10] batch [660/800] time 1.909 (1.939) data 0.000 (0.090) loss 0.0000 (0.0603) lr 4.1221e-04 eta 0:30:22
epoch [9/10] batch [680/800] time 1.896 (1.938) data 0.000 (0.087) loss 0.0043 (0.0606) lr 4.1221e-04 eta 0:29:43
epoch [9/10] batch [700/800] time 1.909 (1.938) data 0.000 (0.085) loss 0.0003 (0.0605) lr 4.1221e-04 eta 0:29:03
epoch [9/10] batch [720/800] time 1.901 (1.934) data 0.000 (0.082) loss 0.0012 (0.0589) lr 4.1221e-04 eta 0:28:22
epoch [9/10] batch [740/800] time 1.906 (1.932) data 0.000 (0.080) loss 0.2671 (0.0597) lr 4.1221e-04 eta 0:27:41
epoch [9/10] batch [760/800] time 1.897 (1.931) data 0.000 (0.078) loss 0.0004 (0.0595) lr 4.1221e-04 eta 0:27:01
epoch [9/10] batch [780/800] time 1.893 (1.926) data 0.000 (0.076) loss 0.0000 (0.0609) lr 4.1221e-04 eta 0:26:19
epoch [9/10] batch [800/800] time 1.909 (1.924) data 0.000 (0.074) loss 0.0018 (0.0597) lr 1.9098e-04 eta 0:25:39
epoch [10/10] batch [20/800] time 1.913 (4.820) data 0.000 (2.985) loss 0.0013 (0.0519) lr 1.9098e-04 eta 1:02:39
epoch [10/10] batch [40/800] time 1.894 (3.323) data 0.000 (1.493) loss 0.0000 (0.0743) lr 1.9098e-04 eta 0:42:05
epoch [10/10] batch [60/800] time 1.898 (2.799) data 0.000 (0.996) loss 0.0006 (0.0593) lr 1.9098e-04 eta 0:34:30
epoch [10/10] batch [80/800] time 1.898 (2.554) data 0.000 (0.747) loss 0.0342 (0.0531) lr 1.9098e-04 eta 0:30:39
epoch [10/10] batch [100/800] time 1.910 (2.408) data 0.000 (0.598) loss 0.0087 (0.0550) lr 1.9098e-04 eta 0:28:05
epoch [10/10] batch [120/800] time 1.904 (2.324) data 0.000 (0.498) loss 0.0000 (0.0557) lr 1.9098e-04 eta 0:26:20
epoch [10/10] batch [140/800] time 1.906 (2.265) data 0.016 (0.427) loss 0.0008 (0.0612) lr 1.9098e-04 eta 0:24:54
epoch [10/10] batch [160/800] time 1.895 (2.215) data 0.000 (0.374) loss 0.0064 (0.0627) lr 1.9098e-04 eta 0:23:37
epoch [10/10] batch [180/800] time 1.913 (2.181) data 0.000 (0.332) loss 0.0004 (0.0616) lr 1.9098e-04 eta 0:22:31
epoch [10/10] batch [200/800] time 1.896 (2.149) data 0.000 (0.299) loss 0.0012 (0.0679) lr 1.9098e-04 eta 0:21:29
epoch [10/10] batch [220/800] time 1.913 (2.116) data 0.000 (0.272) loss 0.0019 (0.0691) lr 1.9098e-04 eta 0:20:27
epoch [10/10] batch [240/800] time 1.916 (2.095) data 0.000 (0.249) loss 0.0017 (0.0662) lr 1.9098e-04 eta 0:19:33
epoch [10/10] batch [260/800] time 1.909 (2.077) data 0.000 (0.230) loss 0.0046 (0.0796) lr 1.9098e-04 eta 0:18:41
epoch [10/10] batch [280/800] time 1.897 (2.062) data 0.000 (0.214) loss 0.3049 (0.0789) lr 1.9098e-04 eta 0:17:52
epoch [10/10] batch [300/800] time 1.893 (2.052) data 0.000 (0.199) loss 0.1038 (0.0759) lr 1.9098e-04 eta 0:17:05
epoch [10/10] batch [320/800] time 1.920 (2.040) data 0.000 (0.187) loss 0.0021 (0.0733) lr 1.9098e-04 eta 0:16:19
epoch [10/10] batch [340/800] time 1.919 (2.025) data 0.000 (0.176) loss 0.0007 (0.0700) lr 1.9098e-04 eta 0:15:31
epoch [10/10] batch [360/800] time 1.922 (2.014) data 0.000 (0.166) loss 0.0001 (0.0676) lr 1.9098e-04 eta 0:14:46
epoch [10/10] batch [380/800] time 1.265 (2.005) data 0.000 (0.158) loss 0.0310 (0.0666) lr 1.9098e-04 eta 0:14:02
epoch [10/10] batch [400/800] time 1.896 (1.997) data 0.000 (0.150) loss 0.0000 (0.0652) lr 1.9098e-04 eta 0:13:18
epoch [10/10] batch [420/800] time 1.910 (1.991) data 0.000 (0.143) loss 0.0255 (0.0651) lr 1.9098e-04 eta 0:12:36
epoch [10/10] batch [440/800] time 1.898 (1.987) data 0.000 (0.136) loss 0.0000 (0.0636) lr 1.9098e-04 eta 0:11:55
epoch [10/10] batch [460/800] time 1.892 (1.984) data 0.000 (0.130) loss 0.0001 (0.0626) lr 1.9098e-04 eta 0:11:14
epoch [10/10] batch [480/800] time 1.932 (1.978) data 0.000 (0.125) loss 0.0002 (0.0603) lr 1.9098e-04 eta 0:10:32
epoch [10/10] batch [500/800] time 1.905 (1.975) data 0.000 (0.120) loss 0.1903 (0.0587) lr 1.9098e-04 eta 0:09:52
epoch [10/10] batch [520/800] time 1.910 (1.969) data 0.000 (0.115) loss 0.0000 (0.0570) lr 1.9098e-04 eta 0:09:11
epoch [10/10] batch [540/800] time 1.925 (1.965) data 0.000 (0.111) loss 0.0000 (0.0566) lr 1.9098e-04 eta 0:08:31
epoch [10/10] batch [560/800] time 1.901 (1.962) data 0.000 (0.107) loss 0.0017 (0.0549) lr 1.9098e-04 eta 0:07:50
epoch [10/10] batch [580/800] time 1.910 (1.960) data 0.000 (0.103) loss 0.0017 (0.0544) lr 1.9098e-04 eta 0:07:11
epoch [10/10] batch [600/800] time 1.896 (1.957) data 0.000 (0.100) loss 0.0026 (0.0527) lr 1.9098e-04 eta 0:06:31
epoch [10/10] batch [620/800] time 1.906 (1.952) data 0.000 (0.097) loss 0.0011 (0.0514) lr 1.9098e-04 eta 0:05:51
epoch [10/10] batch [640/800] time 1.896 (1.951) data 0.000 (0.094) loss 0.0001 (0.0519) lr 1.9098e-04 eta 0:05:12
epoch [10/10] batch [660/800] time 1.892 (1.948) data 0.000 (0.091) loss 0.2969 (0.0536) lr 1.9098e-04 eta 0:04:32
epoch [10/10] batch [680/800] time 1.913 (1.943) data 0.000 (0.088) loss 0.0002 (0.0529) lr 1.9098e-04 eta 0:03:53
epoch [10/10] batch [700/800] time 1.914 (1.940) data 0.000 (0.086) loss 0.1608 (0.0532) lr 1.9098e-04 eta 0:03:13
epoch [10/10] batch [720/800] time 1.915 (1.937) data 0.000 (0.083) loss 0.0009 (0.0521) lr 1.9098e-04 eta 0:02:34
epoch [10/10] batch [740/800] time 1.914 (1.935) data 0.000 (0.081) loss 0.0000 (0.0516) lr 1.9098e-04 eta 0:01:56
epoch [10/10] batch [760/800] time 1.898 (1.934) data 0.000 (0.079) loss 0.3577 (0.0513) lr 1.9098e-04 eta 0:01:17
epoch [10/10] batch [780/800] time 1.254 (1.930) data 0.000 (0.077) loss 0.0001 (0.0530) lr 1.9098e-04 eta 0:00:38
epoch [10/10] batch [800/800] time 1.907 (1.929) data 0.000 (0.075) loss 0.0003 (0.0554) lr 4.8943e-05 eta 0:00:00
Checkpoint saved to output/0506/base2new/train_base/caltech101/shots_16/CoCoOp/vit_b16_c16_ep10_batch1/seed2\prompt_learner\model.pth.tar-10
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 1,549
* correct: 1,522
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.6%
Elapsed: 4:37:00
