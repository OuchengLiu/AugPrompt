***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoCoOp/vit_b16_c16_ep10_batch1_ctxv1.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/base2new/train_base/ucf101/shots_16/CoCoOp/vit_b16_c16_ep10_batch1_ctxv1/seed2
resume: 
root: ../DATA
seed: 2
source_domains: None
target_domains: None
trainer: CoCoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 1
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  ROOT: ../DATA
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_flip',)
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 10
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/base2new/train_base/ucf101/shots_16/CoCoOp/vit_b16_c16_ep10_batch1_ctxv1/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoCoOp
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 2.2.2+cu118
Is debug build: False
CUDA used to build PyTorch: 11.8
ROCM used to build PyTorch: N/A

OS: Microsoft Windows 11 ¼ÒÍ¥ÖÐÎÄ°æ
GCC version: (x86_64-win32-seh-rev0, Built by MinGW-W64 project) 8.1.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: N/A

Python version: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)] (64-bit runtime)
Python platform: Windows-10-10.0.22631-SP0
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 2060
Nvidia driver version: 527.54
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture=9
CurrentClockSpeed=2592
DeviceID=CPU0
Family=198
L2CacheSize=1536
L2CacheSpeed=
Manufacturer=GenuineIntel
MaxClockSpeed=2592
Name=Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz
ProcessorType=3
Revision=

Versions of relevant libraries:
[pip3] flake8==3.7.9
[pip3] numpy==1.26.0
[pip3] torch==2.2.2+cu118
[pip3] torchaudio==2.2.2+cu118
[pip3] torchvision==0.17.2+cu118
[conda] blas                      1.0                         mkl  
[conda] mkl                       2023.1.0         h6b88ed4_46357  
[conda] mkl-service               2.4.0           py310h2bbff1b_1  
[conda] mkl_fft                   1.3.8           py310h2bbff1b_0  
[conda] mkl_random                1.2.4           py310h59b6b97_0  
[conda] numpy                     1.26.0          py310h055cbcc_0  
[conda] numpy-base                1.26.0          py310h65a83cf_0  
[conda] torch                     1.13.1+cu117             pypi_0    pypi
[conda] torchaudio                0.13.1+cu117             pypi_0    pypi
[conda] torchvision               0.14.1                   pypi_0    pypi
        Pillow (9.4.0)

Loading trainer: CoCoOp
Loading dataset: UCF101
Reading split from C:\Jupyter\MyConda\Experiment\1_CoOp_\DATA\ucf101\split_zhou_UCF101.json
Creating a 16-shot dataset
Creating a 4-shot dataset
Saving preprocessed few-shot data to C:\Jupyter\MyConda\Experiment\1_CoOp_\DATA\ucf101\split_fewshot\shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
Building transform_train
+ resize to 224x224
+ random flip
+ to torch tensor of range [0, 1]
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
---------  ------
Dataset    UCF101
# classes  51
# train_x  816
# val      204
# test     1,934
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Aid context: "X X"
Number of aid context words (tokens): 2
Turning off gradients in both the image and the text encoder
Parameters to be updated: {'prompt_learner.meta_net.linear2.weight', 'prompt_learner.meta_net.linear1.weight', 'prompt_learner.meta_net.linear2.bias', 'prompt_learner.meta_net.linear1.bias', 'prompt_learner.ctx'}
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/base2new/train_base/ucf101/shots_16/CoCoOp/vit_b16_c16_ep10_batch1_ctxv1/seed2\tensorboard)
epoch [1/10] batch [20/816] time 1.844 (6.563) data 0.001 (4.538) loss 0.8804 (1.3625) lr 1.0000e-05 eta 14:50:19
epoch [1/10] batch [40/816] time 1.633 (4.091) data 0.001 (2.269) loss 0.9810 (1.0299) lr 1.0000e-05 eta 9:13:37
epoch [1/10] batch [60/816] time 1.665 (3.275) data 0.000 (1.513) loss 0.6646 (1.0536) lr 1.0000e-05 eta 7:22:11
epoch [1/10] batch [80/816] time 1.838 (2.899) data 0.000 (1.135) loss 0.0068 (1.0773) lr 1.0000e-05 eta 6:30:23
epoch [1/10] batch [100/816] time 1.439 (2.646) data 0.001 (0.908) loss 1.0889 (1.0654) lr 1.0000e-05 eta 5:55:29
epoch [1/10] batch [120/816] time 1.472 (2.465) data 0.000 (0.757) loss 0.4578 (1.0513) lr 1.0000e-05 eta 5:30:17
epoch [1/10] batch [140/816] time 1.871 (2.357) data 0.000 (0.649) loss 0.0245 (1.0056) lr 1.0000e-05 eta 5:15:00
epoch [1/10] batch [160/816] time 1.456 (2.267) data 0.000 (0.567) loss 0.0032 (1.0357) lr 1.0000e-05 eta 5:02:17
epoch [1/10] batch [180/816] time 1.423 (2.203) data 0.001 (0.504) loss 0.0010 (0.9832) lr 1.0000e-05 eta 4:53:03
epoch [1/10] batch [200/816] time 1.726 (2.145) data 0.000 (0.454) loss 3.1387 (1.0099) lr 1.0000e-05 eta 4:44:34
epoch [1/10] batch [220/816] time 1.716 (2.101) data 0.000 (0.413) loss 0.0450 (0.9996) lr 1.0000e-05 eta 4:37:59
epoch [1/10] batch [240/816] time 1.830 (2.066) data 0.001 (0.378) loss 0.0196 (0.9702) lr 1.0000e-05 eta 4:32:43
epoch [1/10] batch [260/816] time 1.659 (2.033) data 0.000 (0.349) loss 3.4316 (0.9648) lr 1.0000e-05 eta 4:27:38
epoch [1/10] batch [280/816] time 1.658 (2.005) data 0.000 (0.324) loss 0.0542 (0.9967) lr 1.0000e-05 eta 4:23:20
epoch [1/10] batch [300/816] time 1.658 (1.983) data 0.000 (0.303) loss 0.3032 (0.9547) lr 1.0000e-05 eta 4:19:47
epoch [1/10] batch [320/816] time 1.634 (1.962) data 0.000 (0.284) loss 0.4177 (0.9512) lr 1.0000e-05 eta 4:16:20
epoch [1/10] batch [340/816] time 1.657 (1.943) data 0.000 (0.267) loss 1.7021 (0.9338) lr 1.0000e-05 eta 4:13:17
epoch [1/10] batch [360/816] time 1.654 (1.926) data 0.000 (0.252) loss 1.8311 (0.9205) lr 1.0000e-05 eta 4:10:26
epoch [1/10] batch [380/816] time 1.659 (1.912) data 0.000 (0.239) loss 0.8413 (0.9103) lr 1.0000e-05 eta 4:07:51
epoch [1/10] batch [400/816] time 1.652 (1.898) data 0.001 (0.227) loss 2.4590 (0.8938) lr 1.0000e-05 eta 4:05:29
epoch [1/10] batch [420/816] time 1.657 (1.886) data 0.000 (0.216) loss 0.0237 (0.8803) lr 1.0000e-05 eta 4:03:20
epoch [1/10] batch [440/816] time 1.885 (1.877) data 0.000 (0.207) loss 0.0102 (0.8740) lr 1.0000e-05 eta 4:01:30
epoch [1/10] batch [460/816] time 1.841 (1.868) data 0.001 (0.198) loss 0.0048 (0.8853) lr 1.0000e-05 eta 3:59:45
epoch [1/10] batch [480/816] time 1.497 (1.857) data 0.001 (0.189) loss 0.0761 (0.8762) lr 1.0000e-05 eta 3:57:40
epoch [1/10] batch [500/816] time 1.633 (1.850) data 0.001 (0.182) loss 0.1208 (0.8849) lr 1.0000e-05 eta 3:56:13
epoch [1/10] batch [520/816] time 1.423 (1.841) data 0.000 (0.175) loss 0.0003 (0.8879) lr 1.0000e-05 eta 3:54:21
epoch [1/10] batch [540/816] time 1.869 (1.835) data 0.000 (0.168) loss 0.0960 (0.8940) lr 1.0000e-05 eta 3:53:03
epoch [1/10] batch [560/816] time 1.438 (1.828) data 0.000 (0.162) loss 0.0871 (0.8892) lr 1.0000e-05 eta 3:51:31
epoch [1/10] batch [580/816] time 1.926 (1.823) data 0.000 (0.157) loss 1.1348 (0.8990) lr 1.0000e-05 eta 3:50:17
epoch [1/10] batch [600/816] time 1.466 (1.815) data 0.000 (0.152) loss 0.6719 (0.8953) lr 1.0000e-05 eta 3:48:38
epoch [1/10] batch [620/816] time 1.635 (1.809) data 0.000 (0.147) loss 0.1035 (0.8866) lr 1.0000e-05 eta 3:47:17
epoch [1/10] batch [640/816] time 1.756 (1.804) data 0.000 (0.142) loss 0.3025 (0.8805) lr 1.0000e-05 eta 3:46:03
epoch [1/10] batch [660/816] time 1.683 (1.801) data 0.000 (0.138) loss 0.4878 (0.8756) lr 1.0000e-05 eta 3:45:10
epoch [1/10] batch [680/816] time 1.471 (1.797) data 0.000 (0.134) loss 0.7310 (0.8745) lr 1.0000e-05 eta 3:44:04
epoch [1/10] batch [700/816] time 1.674 (1.789) data 0.001 (0.130) loss 0.3142 (0.8626) lr 1.0000e-05 eta 3:42:29
epoch [1/10] batch [720/816] time 1.735 (1.783) data 0.000 (0.126) loss 0.2788 (0.8655) lr 1.0000e-05 eta 3:41:02
epoch [1/10] batch [740/816] time 1.641 (1.779) data 0.000 (0.123) loss 0.1036 (0.8582) lr 1.0000e-05 eta 3:39:57
epoch [1/10] batch [760/816] time 1.642 (1.775) data 0.000 (0.120) loss 0.2673 (0.8585) lr 1.0000e-05 eta 3:38:55
epoch [1/10] batch [780/816] time 1.626 (1.788) data 0.000 (0.117) loss 4.8125 (0.8561) lr 1.0000e-05 eta 3:39:51
epoch [1/10] batch [800/816] time 1.640 (1.787) data 0.000 (0.114) loss 0.0079 (0.8462) lr 1.0000e-05 eta 3:39:12
epoch [2/10] batch [20/816] time 1.418 (5.824) data 0.000 (4.394) loss 0.1770 (1.6392) lr 2.0000e-03 eta 11:50:54
epoch [2/10] batch [40/816] time 1.417 (3.621) data 0.000 (2.198) loss 0.0003 (1.0989) lr 2.0000e-03 eta 7:20:47
epoch [2/10] batch [60/816] time 1.434 (2.889) data 0.000 (1.465) loss 2.5703 (1.1817) lr 2.0000e-03 eta 5:50:45
epoch [2/10] batch [80/816] time 1.402 (2.523) data 0.000 (1.099) loss 0.0228 (1.1032) lr 2.0000e-03 eta 5:05:29
epoch [2/10] batch [100/816] time 1.445 (2.305) data 0.000 (0.879) loss 0.3049 (1.0051) lr 2.0000e-03 eta 4:38:20
epoch [2/10] batch [120/816] time 1.434 (2.159) data 0.000 (0.733) loss 0.4651 (1.0693) lr 2.0000e-03 eta 4:19:54
epoch [2/10] batch [140/816] time 1.681 (2.085) data 0.000 (0.628) loss 4.6055 (1.0000) lr 2.0000e-03 eta 4:10:18
epoch [2/10] batch [160/816] time 1.455 (2.031) data 0.000 (0.550) loss 0.0002 (1.0082) lr 2.0000e-03 eta 4:03:13
epoch [2/10] batch [180/816] time 1.442 (1.971) data 0.000 (0.489) loss 0.2786 (0.9526) lr 2.0000e-03 eta 3:55:18
epoch [2/10] batch [200/816] time 1.621 (1.932) data 0.000 (0.440) loss 0.9468 (0.9108) lr 2.0000e-03 eta 3:50:05
epoch [2/10] batch [220/816] time 1.574 (1.903) data 0.000 (0.400) loss 0.1476 (0.8860) lr 2.0000e-03 eta 3:45:59
epoch [2/10] batch [240/816] time 1.637 (1.880) data 0.000 (0.366) loss 0.0006 (0.8481) lr 2.0000e-03 eta 3:42:32
epoch [2/10] batch [260/816] time 1.621 (1.859) data 0.000 (0.338) loss 1.7393 (0.8367) lr 2.0000e-03 eta 3:39:29
epoch [2/10] batch [280/816] time 1.944 (1.849) data 0.000 (0.314) loss 0.0010 (0.8112) lr 2.0000e-03 eta 3:37:42
epoch [2/10] batch [300/816] time 1.694 (1.845) data 0.000 (0.293) loss 0.0000 (0.7976) lr 2.0000e-03 eta 3:36:34
epoch [2/10] batch [320/816] time 1.739 (1.835) data 0.001 (0.275) loss 0.0004 (0.7718) lr 2.0000e-03 eta 3:34:48
epoch [2/10] batch [340/816] time 1.686 (1.828) data 0.000 (0.259) loss 0.0010 (0.7636) lr 2.0000e-03 eta 3:33:24
epoch [2/10] batch [360/816] time 1.435 (1.817) data 0.000 (0.244) loss 0.3381 (0.7575) lr 2.0000e-03 eta 3:31:30
epoch [2/10] batch [380/816] time 1.764 (1.798) data 0.000 (0.232) loss 1.3359 (0.7460) lr 2.0000e-03 eta 3:28:42
epoch [2/10] batch [400/816] time 1.497 (1.784) data 0.000 (0.220) loss 0.0018 (0.7385) lr 2.0000e-03 eta 3:26:27
epoch [2/10] batch [420/816] time 1.766 (1.774) data 0.000 (0.210) loss 0.0350 (0.7372) lr 2.0000e-03 eta 3:24:45
epoch [2/10] batch [440/816] time 1.468 (1.765) data 0.000 (0.200) loss 0.3911 (0.7349) lr 2.0000e-03 eta 3:23:02
epoch [2/10] batch [460/816] time 1.487 (1.758) data 0.016 (0.191) loss 0.0001 (0.7252) lr 2.0000e-03 eta 3:21:45
epoch [2/10] batch [480/816] time 1.450 (1.746) data 0.000 (0.183) loss 0.0001 (0.7309) lr 2.0000e-03 eta 3:19:46
epoch [2/10] batch [500/816] time 1.419 (1.739) data 0.000 (0.176) loss 0.1278 (0.7565) lr 2.0000e-03 eta 3:18:20
epoch [2/10] batch [520/816] time 1.604 (1.731) data 0.000 (0.169) loss 0.3220 (0.7769) lr 2.0000e-03 eta 3:16:52
epoch [2/10] batch [540/816] time 1.652 (1.728) data 0.000 (0.163) loss 2.3770 (0.7621) lr 2.0000e-03 eta 3:15:54
epoch [2/10] batch [560/816] time 1.621 (1.725) data 0.000 (0.157) loss 4.8125 (0.7581) lr 2.0000e-03 eta 3:14:59
epoch [2/10] batch [580/816] time 1.806 (1.722) data 0.000 (0.152) loss 0.0040 (0.7424) lr 2.0000e-03 eta 3:14:06
epoch [2/10] batch [600/816] time 1.465 (1.718) data 0.000 (0.147) loss 0.7896 (0.7383) lr 2.0000e-03 eta 3:13:03
epoch [2/10] batch [620/816] time 1.444 (1.709) data 0.000 (0.142) loss 0.0004 (0.7226) lr 2.0000e-03 eta 3:11:29
epoch [2/10] batch [640/816] time 1.650 (1.703) data 0.000 (0.138) loss 0.0307 (0.7188) lr 2.0000e-03 eta 3:10:16
epoch [2/10] batch [660/816] time 1.653 (1.700) data 0.000 (0.133) loss 0.0008 (0.7088) lr 2.0000e-03 eta 3:09:25
epoch [2/10] batch [680/816] time 1.615 (1.698) data 0.000 (0.130) loss 0.5513 (0.6956) lr 2.0000e-03 eta 3:08:37
epoch [2/10] batch [700/816] time 1.652 (1.696) data 0.000 (0.126) loss 0.0011 (0.6941) lr 2.0000e-03 eta 3:07:49
epoch [2/10] batch [720/816] time 1.621 (1.694) data 0.000 (0.122) loss 0.0000 (0.6944) lr 2.0000e-03 eta 3:07:03
epoch [2/10] batch [740/816] time 1.621 (1.693) data 0.000 (0.119) loss 0.0005 (0.6884) lr 2.0000e-03 eta 3:06:19
epoch [2/10] batch [760/816] time 1.629 (1.688) data 0.000 (0.116) loss 0.0083 (0.6821) lr 2.0000e-03 eta 3:05:15
epoch [2/10] batch [780/816] time 1.465 (1.683) data 0.000 (0.113) loss 0.6392 (0.6827) lr 2.0000e-03 eta 3:04:09
epoch [2/10] batch [800/816] time 1.430 (1.677) data 0.000 (0.110) loss 0.0066 (0.6810) lr 2.0000e-03 eta 3:02:55
epoch [3/10] batch [20/816] time 1.414 (5.707) data 0.000 (4.289) loss 0.3525 (0.4274) lr 1.9511e-03 eta 10:18:59
epoch [3/10] batch [40/816] time 1.417 (3.560) data 0.000 (2.144) loss 0.2198 (0.3379) lr 1.9511e-03 eta 6:24:56
epoch [3/10] batch [60/816] time 1.561 (2.865) data 0.001 (1.430) loss 0.0056 (0.3685) lr 1.9511e-03 eta 5:08:51
epoch [3/10] batch [80/816] time 1.590 (2.544) data 0.000 (1.073) loss 0.6055 (0.3980) lr 1.9511e-03 eta 4:33:21
epoch [3/10] batch [100/816] time 1.589 (2.351) data 0.000 (0.858) loss 0.7896 (0.3614) lr 1.9511e-03 eta 4:11:49
epoch [3/10] batch [120/816] time 1.618 (2.223) data 0.000 (0.715) loss 0.1725 (0.3591) lr 1.9511e-03 eta 3:57:26
epoch [3/10] batch [140/816] time 1.588 (2.133) data 0.000 (0.613) loss 0.0002 (0.3438) lr 1.9511e-03 eta 3:47:04
epoch [3/10] batch [160/816] time 1.621 (2.066) data 0.000 (0.536) loss 0.0000 (0.4485) lr 1.9511e-03 eta 3:39:17
epoch [3/10] batch [180/816] time 1.590 (2.015) data 0.000 (0.477) loss 0.4358 (0.4458) lr 1.9511e-03 eta 3:33:09
epoch [3/10] batch [200/816] time 1.604 (1.975) data 0.000 (0.429) loss 0.2112 (0.4892) lr 1.9511e-03 eta 3:28:17
epoch [3/10] batch [220/816] time 1.606 (1.943) data 0.000 (0.390) loss 2.2617 (0.5045) lr 1.9511e-03 eta 3:24:14
epoch [3/10] batch [240/816] time 1.621 (1.915) data 0.000 (0.358) loss 0.5820 (0.5200) lr 1.9511e-03 eta 3:20:41
epoch [3/10] batch [260/816] time 1.446 (1.888) data 0.000 (0.330) loss 1.0576 (0.5023) lr 1.9511e-03 eta 3:17:14
epoch [3/10] batch [280/816] time 1.434 (1.856) data 0.000 (0.307) loss 0.0099 (0.4902) lr 1.9511e-03 eta 3:13:16
epoch [3/10] batch [300/816] time 1.449 (1.828) data 0.000 (0.286) loss 2.0977 (0.4961) lr 1.9511e-03 eta 3:09:46
epoch [3/10] batch [320/816] time 1.446 (1.804) data 0.000 (0.268) loss 0.0009 (0.4956) lr 1.9511e-03 eta 3:06:38
epoch [3/10] batch [340/816] time 1.434 (1.783) data 0.000 (0.253) loss 2.0449 (0.4929) lr 1.9511e-03 eta 3:03:50
epoch [3/10] batch [360/816] time 1.414 (1.771) data 0.000 (0.239) loss 0.0506 (0.4836) lr 1.9511e-03 eta 3:02:05
epoch [3/10] batch [380/816] time 1.433 (1.754) data 0.000 (0.226) loss 0.0228 (0.4682) lr 1.9511e-03 eta 2:59:42
epoch [3/10] batch [400/816] time 1.449 (1.738) data 0.000 (0.215) loss 0.4468 (0.4853) lr 1.9511e-03 eta 2:57:30
epoch [3/10] batch [420/816] time 1.434 (1.723) data 0.000 (0.205) loss 0.4624 (0.4822) lr 1.9511e-03 eta 2:55:27
epoch [3/10] batch [440/816] time 1.621 (1.714) data 0.000 (0.195) loss 2.2070 (0.4961) lr 1.9511e-03 eta 2:53:56
epoch [3/10] batch [460/816] time 1.614 (1.710) data 0.000 (0.187) loss 0.1272 (0.4987) lr 1.9511e-03 eta 2:52:55
epoch [3/10] batch [480/816] time 1.619 (1.706) data 0.000 (0.179) loss 0.2250 (0.5017) lr 1.9511e-03 eta 2:51:57
epoch [3/10] batch [500/816] time 1.606 (1.702) data 0.000 (0.172) loss 0.9956 (0.5020) lr 1.9511e-03 eta 2:51:02
epoch [3/10] batch [520/816] time 1.499 (1.700) data 0.000 (0.165) loss 0.0073 (0.4941) lr 1.9511e-03 eta 2:50:14
epoch [3/10] batch [540/816] time 1.469 (1.692) data 0.000 (0.159) loss 0.0000 (0.4934) lr 1.9511e-03 eta 2:48:52
epoch [3/10] batch [560/816] time 1.868 (1.690) data 0.000 (0.153) loss 0.1864 (0.4919) lr 1.9511e-03 eta 2:48:03
epoch [3/10] batch [580/816] time 1.703 (1.692) data 0.000 (0.148) loss 0.2686 (0.4840) lr 1.9511e-03 eta 2:47:44
epoch [3/10] batch [600/816] time 1.695 (1.692) data 0.000 (0.143) loss 0.1862 (0.4786) lr 1.9511e-03 eta 2:47:11
epoch [3/10] batch [620/816] time 1.673 (1.692) data 0.000 (0.139) loss 0.3420 (0.4748) lr 1.9511e-03 eta 2:46:37
epoch [3/10] batch [640/816] time 1.667 (1.694) data 0.000 (0.134) loss 0.0000 (0.4813) lr 1.9511e-03 eta 2:46:12
epoch [3/10] batch [660/816] time 1.560 (1.692) data 0.000 (0.130) loss 0.2527 (0.4736) lr 1.9511e-03 eta 2:45:29
epoch [3/10] batch [680/816] time 1.885 (1.692) data 0.000 (0.126) loss 0.2205 (0.4880) lr 1.9511e-03 eta 2:44:55
epoch [3/10] batch [700/816] time 1.423 (1.691) data 0.000 (0.123) loss 0.2532 (0.4940) lr 1.9511e-03 eta 2:44:14
epoch [3/10] batch [720/816] time 1.418 (1.688) data 0.000 (0.119) loss 0.0522 (0.4919) lr 1.9511e-03 eta 2:43:26
epoch [3/10] batch [740/816] time 1.510 (1.687) data 0.000 (0.116) loss 0.0000 (0.4860) lr 1.9511e-03 eta 2:42:46
epoch [3/10] batch [760/816] time 1.503 (1.688) data 0.000 (0.113) loss 0.0001 (0.4885) lr 1.9511e-03 eta 2:42:13
epoch [3/10] batch [780/816] time 1.449 (1.683) data 0.000 (0.110) loss 1.0000 (0.4843) lr 1.9511e-03 eta 2:41:14
epoch [3/10] batch [800/816] time 1.874 (1.682) data 0.000 (0.108) loss 0.0000 (0.4811) lr 1.9511e-03 eta 2:40:34
epoch [4/10] batch [20/816] time 1.633 (6.139) data 0.000 (4.501) loss 0.0035 (0.4483) lr 1.8090e-03 eta 9:42:23
epoch [4/10] batch [40/816] time 1.438 (3.841) data 0.000 (2.251) loss 0.0000 (0.3011) lr 1.8090e-03 eta 6:03:03
epoch [4/10] batch [60/816] time 1.438 (3.052) data 0.000 (1.501) loss 1.1260 (0.3963) lr 1.8090e-03 eta 4:47:29
epoch [4/10] batch [80/816] time 1.638 (2.685) data 0.000 (1.125) loss 0.0067 (0.4342) lr 1.8090e-03 eta 4:12:01
epoch [4/10] batch [100/816] time 1.699 (2.484) data 0.000 (0.900) loss 1.5205 (0.4550) lr 1.8090e-03 eta 3:52:17
epoch [4/10] batch [120/816] time 1.687 (2.347) data 0.000 (0.750) loss 0.0267 (0.4556) lr 1.8090e-03 eta 3:38:45
epoch [4/10] batch [140/816] time 1.689 (2.250) data 0.000 (0.643) loss 0.0203 (0.4239) lr 1.8090e-03 eta 3:28:58
epoch [4/10] batch [160/816] time 1.641 (2.188) data 0.000 (0.563) loss 0.0038 (0.4306) lr 1.8090e-03 eta 3:22:29
epoch [4/10] batch [180/816] time 1.753 (2.120) data 0.000 (0.500) loss 0.8643 (0.4268) lr 1.8090e-03 eta 3:15:29
epoch [4/10] batch [200/816] time 2.011 (2.079) data 0.000 (0.450) loss 0.0001 (0.4406) lr 1.8090e-03 eta 3:11:00
epoch [4/10] batch [220/816] time 1.593 (2.040) data 0.000 (0.409) loss 0.0008 (0.4362) lr 1.8090e-03 eta 3:06:45
epoch [4/10] batch [240/816] time 1.863 (2.008) data 0.000 (0.375) loss 0.0024 (0.4323) lr 1.8090e-03 eta 3:03:06
epoch [4/10] batch [260/816] time 1.547 (1.975) data 0.000 (0.346) loss 0.9829 (0.4482) lr 1.8090e-03 eta 2:59:28
epoch [4/10] batch [280/816] time 1.768 (1.952) data 0.000 (0.322) loss 0.0041 (0.4559) lr 1.8090e-03 eta 2:56:44
epoch [4/10] batch [300/816] time 1.451 (1.931) data 0.000 (0.300) loss 0.0018 (0.4509) lr 1.8090e-03 eta 2:54:08
epoch [4/10] batch [320/816] time 1.478 (1.914) data 0.000 (0.282) loss 0.0019 (0.4414) lr 1.8090e-03 eta 2:51:58
epoch [4/10] batch [340/816] time 1.464 (1.900) data 0.000 (0.265) loss 1.0488 (0.4333) lr 1.8090e-03 eta 2:50:08
epoch [4/10] batch [360/816] time 1.662 (1.891) data 0.000 (0.250) loss 0.1144 (0.4323) lr 1.8090e-03 eta 2:48:39
epoch [4/10] batch [380/816] time 1.637 (1.877) data 0.000 (0.237) loss 0.0066 (0.4365) lr 1.8090e-03 eta 2:46:49
epoch [4/10] batch [400/816] time 1.653 (1.868) data 0.000 (0.225) loss 0.0145 (0.4434) lr 1.8090e-03 eta 2:45:21
epoch [4/10] batch [420/816] time 1.652 (1.861) data 0.000 (0.215) loss 0.2345 (0.4294) lr 1.8090e-03 eta 2:44:09
epoch [4/10] batch [440/816] time 1.484 (1.847) data 0.000 (0.205) loss 0.0006 (0.4317) lr 1.8090e-03 eta 2:42:16
epoch [4/10] batch [460/816] time 1.471 (1.830) data 0.000 (0.196) loss 0.0028 (0.4550) lr 1.8090e-03 eta 2:40:09
epoch [4/10] batch [480/816] time 1.658 (1.820) data 0.000 (0.188) loss 0.0157 (0.4506) lr 1.8090e-03 eta 2:38:39
epoch [4/10] batch [500/816] time 1.625 (1.812) data 0.000 (0.180) loss 0.0163 (0.4483) lr 1.8090e-03 eta 2:37:24
epoch [4/10] batch [520/816] time 1.641 (1.806) data 0.000 (0.173) loss 0.0065 (0.4373) lr 1.8090e-03 eta 2:36:17
epoch [4/10] batch [540/816] time 1.652 (1.801) data 0.000 (0.167) loss 0.1877 (0.4350) lr 1.8090e-03 eta 2:35:13
epoch [4/10] batch [560/816] time 1.859 (1.797) data 0.000 (0.161) loss 0.0799 (0.4287) lr 1.8090e-03 eta 2:34:16
epoch [4/10] batch [580/816] time 1.481 (1.793) data 0.000 (0.155) loss 0.0000 (0.4218) lr 1.8090e-03 eta 2:33:21
epoch [4/10] batch [600/816] time 1.969 (1.795) data 0.000 (0.150) loss 0.2296 (0.4177) lr 1.8090e-03 eta 2:32:54
epoch [4/10] batch [620/816] time 1.973 (1.791) data 0.000 (0.145) loss 0.0005 (0.4134) lr 1.8090e-03 eta 2:31:58
epoch [4/10] batch [640/816] time 2.003 (1.785) data 0.000 (0.141) loss 1.7920 (0.4122) lr 1.8090e-03 eta 2:30:54
epoch [4/10] batch [660/816] time 1.519 (1.780) data 0.000 (0.137) loss 0.1487 (0.4123) lr 1.8090e-03 eta 2:29:50
epoch [4/10] batch [680/816] time 1.466 (1.772) data 0.000 (0.133) loss 0.0145 (0.4092) lr 1.8090e-03 eta 2:28:35
epoch [4/10] batch [700/816] time 1.438 (1.767) data 0.000 (0.129) loss 0.0008 (0.4059) lr 1.8090e-03 eta 2:27:36
epoch [4/10] batch [720/816] time 1.481 (1.763) data 0.016 (0.125) loss 0.0004 (0.4005) lr 1.8090e-03 eta 2:26:40
epoch [4/10] batch [740/816] time 1.387 (1.759) data 0.000 (0.122) loss 0.0001 (0.3979) lr 1.8090e-03 eta 2:25:45
epoch [4/10] batch [760/816] time 1.675 (1.758) data 0.000 (0.119) loss 0.0048 (0.3989) lr 1.8090e-03 eta 2:25:04
epoch [4/10] batch [780/816] time 1.714 (1.757) data 0.000 (0.116) loss 0.0002 (0.4073) lr 1.8090e-03 eta 2:24:23
epoch [4/10] batch [800/816] time 1.677 (1.755) data 0.000 (0.113) loss 0.3767 (0.4071) lr 1.8090e-03 eta 2:23:39
epoch [5/10] batch [20/816] time 1.597 (5.842) data 0.000 (4.220) loss 0.0084 (0.4008) lr 1.5878e-03 eta 7:54:44
epoch [5/10] batch [40/816] time 1.611 (3.780) data 0.000 (2.110) loss 0.3577 (0.3368) lr 1.5878e-03 eta 5:05:57
epoch [5/10] batch [60/816] time 1.618 (3.099) data 0.000 (1.407) loss 0.9355 (0.3529) lr 1.5878e-03 eta 4:09:45
epoch [5/10] batch [80/816] time 1.723 (2.743) data 0.000 (1.055) loss 0.0005 (0.2932) lr 1.5878e-03 eta 3:40:08
epoch [5/10] batch [100/816] time 1.618 (2.527) data 0.000 (0.844) loss 0.4634 (0.3773) lr 1.5878e-03 eta 3:21:58
epoch [5/10] batch [120/816] time 1.672 (2.367) data 0.000 (0.704) loss 0.0010 (0.3428) lr 1.5878e-03 eta 3:08:25
epoch [5/10] batch [140/816] time 1.482 (2.245) data 0.000 (0.603) loss 1.2344 (0.3314) lr 1.5878e-03 eta 2:57:55
epoch [5/10] batch [160/816] time 1.809 (2.156) data 0.000 (0.528) loss 1.6846 (0.3669) lr 1.5878e-03 eta 2:50:10
epoch [5/10] batch [180/816] time 1.839 (2.096) data 0.000 (0.469) loss 0.0148 (0.3771) lr 1.5878e-03 eta 2:44:46
epoch [5/10] batch [200/816] time 1.862 (2.058) data 0.000 (0.422) loss 0.0079 (0.3752) lr 1.5878e-03 eta 2:41:03
epoch [5/10] batch [220/816] time 1.533 (2.025) data 0.000 (0.384) loss 0.0000 (0.3504) lr 1.5878e-03 eta 2:37:49
epoch [5/10] batch [240/816] time 1.994 (1.998) data 0.000 (0.352) loss 0.0241 (0.3267) lr 1.5878e-03 eta 2:35:01
epoch [5/10] batch [260/816] time 1.830 (1.972) data 0.000 (0.325) loss 0.0003 (0.3637) lr 1.5878e-03 eta 2:32:24
epoch [5/10] batch [280/816] time 1.638 (1.951) data 0.000 (0.302) loss 0.4568 (0.3957) lr 1.5878e-03 eta 2:30:03
epoch [5/10] batch [300/816] time 1.665 (1.932) data 0.000 (0.281) loss 0.1594 (0.3835) lr 1.5878e-03 eta 2:27:58
epoch [5/10] batch [320/816] time 1.665 (1.915) data 0.000 (0.264) loss 0.5947 (0.3839) lr 1.5878e-03 eta 2:26:02
epoch [5/10] batch [340/816] time 1.657 (1.900) data 0.000 (0.248) loss 0.0025 (0.3673) lr 1.5878e-03 eta 2:24:16
epoch [5/10] batch [360/816] time 1.655 (1.887) data 0.000 (0.235) loss 0.0176 (0.3686) lr 1.5878e-03 eta 2:22:41
epoch [5/10] batch [380/816] time 1.694 (1.877) data 0.000 (0.222) loss 0.1497 (0.3617) lr 1.5878e-03 eta 2:21:16
epoch [5/10] batch [400/816] time 2.080 (1.868) data 0.000 (0.211) loss 0.0797 (0.3568) lr 1.5878e-03 eta 2:19:59
epoch [5/10] batch [420/816] time 1.703 (1.861) data 0.000 (0.201) loss 3.9727 (0.3626) lr 1.5878e-03 eta 2:18:48
epoch [5/10] batch [440/816] time 1.727 (1.854) data 0.000 (0.192) loss 1.6826 (0.3533) lr 1.5878e-03 eta 2:17:40
epoch [5/10] batch [460/816] time 1.862 (1.851) data 0.000 (0.184) loss 0.3660 (0.3584) lr 1.5878e-03 eta 2:16:52
epoch [5/10] batch [480/816] time 1.503 (1.845) data 0.000 (0.176) loss 0.0001 (0.3587) lr 1.5878e-03 eta 2:15:48
epoch [5/10] batch [500/816] time 1.952 (1.838) data 0.000 (0.169) loss 0.2993 (0.3480) lr 1.5878e-03 eta 2:14:39
epoch [5/10] batch [520/816] time 1.724 (1.832) data 0.000 (0.162) loss 0.4985 (0.3404) lr 1.5878e-03 eta 2:13:37
epoch [5/10] batch [540/816] time 1.906 (1.824) data 0.000 (0.156) loss 0.2291 (0.3448) lr 1.5878e-03 eta 2:12:24
epoch [5/10] batch [560/816] time 1.458 (1.824) data 0.000 (0.151) loss 0.0701 (0.3361) lr 1.5878e-03 eta 2:11:47
epoch [5/10] batch [580/816] time 1.987 (1.821) data 0.000 (0.146) loss 1.0098 (0.3357) lr 1.5878e-03 eta 2:10:58
epoch [5/10] batch [600/816] time 1.920 (1.822) data 0.000 (0.141) loss 0.1409 (0.3286) lr 1.5878e-03 eta 2:10:27
epoch [5/10] batch [620/816] time 1.808 (1.819) data 0.001 (0.136) loss 0.0317 (0.3263) lr 1.5878e-03 eta 2:09:38
epoch [5/10] batch [640/816] time 1.729 (1.816) data 0.000 (0.132) loss 0.3684 (0.3240) lr 1.5878e-03 eta 2:08:49
epoch [5/10] batch [660/816] time 1.293 (1.810) data 0.000 (0.128) loss 0.0001 (0.3204) lr 1.5878e-03 eta 2:07:45
epoch [5/10] batch [680/816] time 1.675 (1.809) data 0.000 (0.124) loss 0.0008 (0.3181) lr 1.5878e-03 eta 2:07:08
epoch [5/10] batch [700/816] time 2.515 (1.814) data 0.000 (0.121) loss 1.7842 (0.3187) lr 1.5878e-03 eta 2:06:50
epoch [5/10] batch [720/816] time 1.597 (1.807) data 0.000 (0.117) loss 0.0296 (0.3236) lr 1.5878e-03 eta 2:05:46
epoch [5/10] batch [740/816] time 1.755 (1.802) data 0.000 (0.114) loss 0.0000 (0.3267) lr 1.5878e-03 eta 2:04:47
epoch [5/10] batch [760/816] time 2.036 (1.803) data 0.000 (0.111) loss 0.0389 (0.3224) lr 1.5878e-03 eta 2:04:15
epoch [5/10] batch [780/816] time 1.760 (1.805) data 0.000 (0.108) loss 0.0004 (0.3199) lr 1.5878e-03 eta 2:03:48
epoch [5/10] batch [800/816] time 1.679 (1.805) data 0.001 (0.106) loss 0.0041 (0.3217) lr 1.5878e-03 eta 2:03:14
epoch [6/10] batch [20/816] time 2.128 (5.929) data 0.001 (4.284) loss 0.0000 (0.0786) lr 1.3090e-03 eta 6:41:11
epoch [6/10] batch [40/816] time 1.958 (3.862) data 0.001 (2.142) loss 0.0493 (0.1372) lr 1.3090e-03 eta 4:20:03
epoch [6/10] batch [60/816] time 2.033 (3.207) data 0.000 (1.428) loss 0.0234 (0.1227) lr 1.3090e-03 eta 3:34:50
epoch [6/10] batch [80/816] time 2.080 (2.892) data 0.001 (1.071) loss 0.0001 (0.1178) lr 1.3090e-03 eta 3:12:47
epoch [6/10] batch [100/816] time 1.640 (2.676) data 0.000 (0.857) loss 0.0016 (0.1588) lr 1.3090e-03 eta 2:57:30
epoch [6/10] batch [120/816] time 1.791 (2.548) data 0.001 (0.714) loss 0.0000 (0.1625) lr 1.3090e-03 eta 2:48:08
epoch [6/10] batch [140/816] time 1.798 (2.445) data 0.001 (0.612) loss 0.0405 (0.1898) lr 1.3090e-03 eta 2:40:32
epoch [6/10] batch [160/816] time 1.322 (2.343) data 0.000 (0.536) loss 0.0005 (0.2040) lr 1.3090e-03 eta 2:33:03
epoch [6/10] batch [180/816] time 1.886 (2.273) data 0.001 (0.476) loss 0.0003 (0.2147) lr 1.3090e-03 eta 2:27:46
epoch [6/10] batch [200/816] time 1.785 (2.215) data 0.000 (0.429) loss 0.0384 (0.2245) lr 1.3090e-03 eta 2:23:13
epoch [6/10] batch [220/816] time 1.776 (2.153) data 0.000 (0.390) loss 0.0037 (0.2373) lr 1.3090e-03 eta 2:18:32
epoch [6/10] batch [240/816] time 1.886 (2.122) data 0.001 (0.357) loss 0.0000 (0.2348) lr 1.3090e-03 eta 2:15:49
epoch [6/10] batch [260/816] time 1.334 (2.097) data 0.000 (0.330) loss 0.0001 (0.2299) lr 1.3090e-03 eta 2:13:31
epoch [6/10] batch [280/816] time 1.298 (2.059) data 0.000 (0.306) loss 0.0228 (0.2336) lr 1.3090e-03 eta 2:10:25
epoch [6/10] batch [300/816] time 1.868 (2.046) data 0.001 (0.286) loss 0.3784 (0.2332) lr 1.3090e-03 eta 2:08:54
epoch [6/10] batch [320/816] time 1.935 (2.038) data 0.001 (0.268) loss 1.3037 (0.2562) lr 1.3090e-03 eta 2:07:44
epoch [6/10] batch [340/816] time 1.835 (2.029) data 0.000 (0.252) loss 0.4717 (0.2711) lr 1.3090e-03 eta 2:06:29
epoch [6/10] batch [360/816] time 2.027 (2.021) data 0.001 (0.238) loss 0.0006 (0.2720) lr 1.3090e-03 eta 2:05:19
epoch [6/10] batch [380/816] time 2.044 (2.017) data 0.000 (0.226) loss 2.1348 (0.2693) lr 1.3090e-03 eta 2:04:24
epoch [6/10] batch [400/816] time 2.013 (2.016) data 0.000 (0.215) loss 0.1163 (0.2637) lr 1.3090e-03 eta 2:03:38
epoch [6/10] batch [420/816] time 2.007 (2.007) data 0.000 (0.204) loss 0.0626 (0.2611) lr 1.3090e-03 eta 2:02:27
epoch [6/10] batch [440/816] time 1.930 (2.002) data 0.000 (0.195) loss 1.1162 (0.2626) lr 1.3090e-03 eta 2:01:27
epoch [6/10] batch [460/816] time 2.009 (1.999) data 0.000 (0.187) loss 0.0005 (0.2553) lr 1.3090e-03 eta 2:00:36
epoch [6/10] batch [480/816] time 2.053 (1.999) data 0.000 (0.179) loss 0.0396 (0.2483) lr 1.3090e-03 eta 1:59:54
epoch [6/10] batch [500/816] time 2.005 (1.997) data 0.000 (0.172) loss 0.0515 (0.2502) lr 1.3090e-03 eta 1:59:10
epoch [6/10] batch [520/816] time 1.740 (1.992) data 0.000 (0.165) loss 1.9521 (0.2565) lr 1.3090e-03 eta 1:58:09
epoch [6/10] batch [540/816] time 1.724 (1.986) data 0.001 (0.159) loss 0.4558 (0.2551) lr 1.3090e-03 eta 1:57:09
epoch [6/10] batch [560/816] time 1.887 (1.980) data 0.001 (0.153) loss 0.1615 (0.2539) lr 1.3090e-03 eta 1:56:10
epoch [6/10] batch [580/816] time 1.965 (1.978) data 0.000 (0.148) loss 0.0000 (0.2659) lr 1.3090e-03 eta 1:55:23
epoch [6/10] batch [600/816] time 1.829 (1.977) data 0.000 (0.143) loss 0.5283 (0.2723) lr 1.3090e-03 eta 1:54:38
epoch [6/10] batch [620/816] time 1.853 (1.970) data 0.000 (0.139) loss 0.0002 (0.2679) lr 1.3090e-03 eta 1:53:36
epoch [6/10] batch [640/816] time 2.090 (1.969) data 0.000 (0.134) loss 0.3035 (0.2655) lr 1.3090e-03 eta 1:52:52
epoch [6/10] batch [660/816] time 2.188 (1.969) data 0.001 (0.130) loss 0.0001 (0.2784) lr 1.3090e-03 eta 1:52:14
epoch [6/10] batch [680/816] time 2.421 (1.972) data 0.000 (0.126) loss 0.0622 (0.2818) lr 1.3090e-03 eta 1:51:45
epoch [6/10] batch [700/816] time 2.169 (1.973) data 0.000 (0.123) loss 0.4133 (0.2835) lr 1.3090e-03 eta 1:51:10
epoch [6/10] batch [720/816] time 2.085 (1.974) data 0.000 (0.119) loss 0.5898 (0.2829) lr 1.3090e-03 eta 1:50:31
epoch [6/10] batch [740/816] time 2.082 (1.975) data 0.000 (0.116) loss 0.0111 (0.2821) lr 1.3090e-03 eta 1:49:58
epoch [6/10] batch [760/816] time 1.968 (1.976) data 0.001 (0.113) loss 0.0090 (0.2818) lr 1.3090e-03 eta 1:49:20
epoch [6/10] batch [780/816] time 2.028 (1.978) data 0.000 (0.110) loss 0.4680 (0.2786) lr 1.3090e-03 eta 1:48:46
epoch [6/10] batch [800/816] time 1.881 (1.978) data 0.001 (0.107) loss 0.0040 (0.2757) lr 1.3090e-03 eta 1:48:07
epoch [7/10] batch [20/816] time 1.704 (5.885) data 0.000 (4.317) loss 0.3179 (0.4193) lr 1.0000e-03 eta 5:18:11
epoch [7/10] batch [40/816] time 1.802 (3.806) data 0.000 (2.159) loss 0.0172 (0.3425) lr 1.0000e-03 eta 3:24:30
epoch [7/10] batch [60/816] time 1.663 (3.092) data 0.000 (1.439) loss 0.0759 (0.2829) lr 1.0000e-03 eta 2:45:07
epoch [7/10] batch [80/816] time 2.051 (2.770) data 0.000 (1.079) loss 2.0918 (0.3353) lr 1.0000e-03 eta 2:26:59
epoch [7/10] batch [100/816] time 1.838 (2.616) data 0.000 (0.864) loss 0.0009 (0.3009) lr 1.0000e-03 eta 2:17:56
epoch [7/10] batch [120/816] time 2.639 (2.511) data 0.001 (0.720) loss 0.0002 (0.3103) lr 1.0000e-03 eta 2:11:33
epoch [7/10] batch [140/816] time 2.031 (2.434) data 0.000 (0.617) loss 0.0000 (0.2876) lr 1.0000e-03 eta 2:06:42
epoch [7/10] batch [160/816] time 1.924 (2.378) data 0.000 (0.540) loss 0.0058 (0.2732) lr 1.0000e-03 eta 2:03:00
epoch [7/10] batch [180/816] time 1.975 (2.333) data 0.000 (0.480) loss 0.3550 (0.2558) lr 1.0000e-03 eta 1:59:55
epoch [7/10] batch [200/816] time 2.039 (2.300) data 0.001 (0.432) loss 1.8096 (0.2502) lr 1.0000e-03 eta 1:57:27
epoch [7/10] batch [220/816] time 1.996 (2.270) data 0.000 (0.393) loss 0.2142 (0.2444) lr 1.0000e-03 eta 1:55:08
epoch [7/10] batch [240/816] time 1.797 (2.247) data 0.001 (0.360) loss 0.0024 (0.2529) lr 1.0000e-03 eta 1:53:16
epoch [7/10] batch [260/816] time 1.655 (2.237) data 0.001 (0.332) loss 0.0007 (0.2487) lr 1.0000e-03 eta 1:52:01
epoch [7/10] batch [280/816] time 1.869 (2.228) data 0.000 (0.309) loss 0.0001 (0.2501) lr 1.0000e-03 eta 1:50:47
epoch [7/10] batch [300/816] time 2.370 (2.233) data 0.001 (0.288) loss 0.6069 (0.2485) lr 1.0000e-03 eta 1:50:19
epoch [7/10] batch [320/816] time 2.119 (2.229) data 0.000 (0.270) loss 0.9155 (0.2397) lr 1.0000e-03 eta 1:49:21
epoch [7/10] batch [340/816] time 1.474 (2.195) data 0.000 (0.254) loss 0.0386 (0.2375) lr 1.0000e-03 eta 1:46:58
epoch [7/10] batch [360/816] time 2.029 (2.187) data 0.000 (0.240) loss 0.0117 (0.2292) lr 1.0000e-03 eta 1:45:51
epoch [7/10] batch [380/816] time 1.812 (2.183) data 0.001 (0.228) loss 0.0017 (0.2290) lr 1.0000e-03 eta 1:44:56
epoch [7/10] batch [400/816] time 1.698 (2.159) data 0.001 (0.216) loss 0.0000 (0.2256) lr 1.0000e-03 eta 1:43:03
epoch [7/10] batch [420/816] time 1.896 (2.133) data 0.000 (0.206) loss 0.0005 (0.2320) lr 1.0000e-03 eta 1:41:07
epoch [7/10] batch [440/816] time 1.897 (2.125) data 0.000 (0.197) loss 0.2827 (0.2282) lr 1.0000e-03 eta 1:40:01
epoch [7/10] batch [460/816] time 1.798 (2.121) data 0.000 (0.188) loss 0.0071 (0.2295) lr 1.0000e-03 eta 1:39:08
epoch [7/10] batch [480/816] time 2.049 (2.116) data 0.000 (0.180) loss 0.0361 (0.2273) lr 1.0000e-03 eta 1:38:10
epoch [7/10] batch [500/816] time 1.826 (2.112) data 0.000 (0.173) loss 0.0003 (0.2292) lr 1.0000e-03 eta 1:37:17
epoch [7/10] batch [520/816] time 1.869 (2.108) data 0.001 (0.166) loss 2.7852 (0.2334) lr 1.0000e-03 eta 1:36:25
epoch [7/10] batch [540/816] time 2.019 (2.105) data 0.001 (0.160) loss 0.0287 (0.2329) lr 1.0000e-03 eta 1:35:32
epoch [7/10] batch [560/816] time 1.930 (2.101) data 0.001 (0.154) loss 0.0620 (0.2299) lr 1.0000e-03 eta 1:34:40
epoch [7/10] batch [580/816] time 2.011 (2.097) data 0.001 (0.149) loss 0.0002 (0.2272) lr 1.0000e-03 eta 1:33:47
epoch [7/10] batch [600/816] time 2.014 (2.093) data 0.000 (0.144) loss 0.3237 (0.2249) lr 1.0000e-03 eta 1:32:55
epoch [7/10] batch [620/816] time 2.005 (2.089) data 0.000 (0.140) loss 0.0003 (0.2265) lr 1.0000e-03 eta 1:32:02
epoch [7/10] batch [640/816] time 1.999 (2.085) data 0.000 (0.135) loss 0.0391 (0.2258) lr 1.0000e-03 eta 1:31:11
epoch [7/10] batch [660/816] time 2.289 (2.081) data 0.000 (0.131) loss 0.0006 (0.2275) lr 1.0000e-03 eta 1:30:17
epoch [7/10] batch [680/816] time 1.915 (2.076) data 0.001 (0.127) loss 1.3223 (0.2320) lr 1.0000e-03 eta 1:29:23
epoch [7/10] batch [700/816] time 1.885 (2.072) data 0.000 (0.124) loss 0.6118 (0.2359) lr 1.0000e-03 eta 1:28:33
epoch [7/10] batch [720/816] time 1.993 (2.071) data 0.000 (0.120) loss 0.0038 (0.2334) lr 1.0000e-03 eta 1:27:49
epoch [7/10] batch [740/816] time 2.741 (2.071) data 0.000 (0.117) loss 0.9878 (0.2336) lr 1.0000e-03 eta 1:27:07
epoch [7/10] batch [760/816] time 2.584 (2.069) data 0.000 (0.114) loss 0.0019 (0.2343) lr 1.0000e-03 eta 1:26:21
epoch [7/10] batch [780/816] time 3.181 (2.076) data 0.001 (0.111) loss 0.0000 (0.2326) lr 1.0000e-03 eta 1:25:57
epoch [7/10] batch [800/816] time 1.963 (2.086) data 0.000 (0.108) loss 1.5977 (0.2332) lr 1.0000e-03 eta 1:25:40
epoch [8/10] batch [20/816] time 1.972 (6.077) data 0.000 (4.292) loss 0.0213 (0.2080) lr 6.9098e-04 eta 4:05:55
epoch [8/10] batch [40/816] time 2.123 (4.021) data 0.000 (2.146) loss 0.0007 (0.2170) lr 6.9098e-04 eta 2:41:21
epoch [8/10] batch [60/816] time 1.739 (3.335) data 0.000 (1.431) loss 0.0169 (0.2349) lr 6.9098e-04 eta 2:12:43
epoch [8/10] batch [80/816] time 2.072 (2.990) data 0.000 (1.073) loss 0.0264 (0.2146) lr 6.9098e-04 eta 1:58:00
epoch [8/10] batch [100/816] time 1.318 (2.754) data 0.000 (0.859) loss 0.0006 (0.2138) lr 6.9098e-04 eta 1:47:46
epoch [8/10] batch [120/816] time 1.466 (2.547) data 0.001 (0.716) loss 0.0193 (0.2026) lr 6.9098e-04 eta 1:38:50
epoch [8/10] batch [140/816] time 1.884 (2.451) data 0.001 (0.614) loss 0.0000 (0.2026) lr 6.9098e-04 eta 1:34:17
epoch [8/10] batch [160/816] time 2.250 (2.387) data 0.000 (0.537) loss 0.0936 (0.2277) lr 6.9098e-04 eta 1:31:01
epoch [8/10] batch [180/816] time 1.759 (2.345) data 0.001 (0.477) loss 0.0000 (0.2216) lr 6.9098e-04 eta 1:28:39
epoch [8/10] batch [200/816] time 1.825 (2.302) data 0.000 (0.430) loss 0.0001 (0.2193) lr 6.9098e-04 eta 1:26:14
epoch [8/10] batch [220/816] time 1.910 (2.275) data 0.000 (0.391) loss 0.0003 (0.2172) lr 6.9098e-04 eta 1:24:27
epoch [8/10] batch [240/816] time 1.867 (2.255) data 0.000 (0.358) loss 0.1301 (0.2191) lr 6.9098e-04 eta 1:22:58
epoch [8/10] batch [260/816] time 1.791 (2.233) data 0.000 (0.330) loss 0.0642 (0.2144) lr 6.9098e-04 eta 1:21:26
epoch [8/10] batch [280/816] time 2.008 (2.216) data 0.000 (0.307) loss 0.0021 (0.2196) lr 6.9098e-04 eta 1:20:03
epoch [8/10] batch [300/816] time 1.965 (2.199) data 0.000 (0.286) loss 0.0517 (0.2090) lr 6.9098e-04 eta 1:18:42
epoch [8/10] batch [320/816] time 1.986 (2.185) data 0.001 (0.269) loss 0.0182 (0.2045) lr 6.9098e-04 eta 1:17:29
epoch [8/10] batch [340/816] time 1.994 (2.172) data 0.000 (0.253) loss 0.0002 (0.2045) lr 6.9098e-04 eta 1:16:18
epoch [8/10] batch [360/816] time 1.949 (2.161) data 0.000 (0.239) loss 0.0010 (0.2000) lr 6.9098e-04 eta 1:15:12
epoch [8/10] batch [380/816] time 2.216 (2.152) data 0.000 (0.226) loss 0.0365 (0.1991) lr 6.9098e-04 eta 1:14:09
epoch [8/10] batch [400/816] time 1.825 (2.142) data 0.001 (0.215) loss 0.1683 (0.1990) lr 6.9098e-04 eta 1:13:06
epoch [8/10] batch [420/816] time 2.665 (2.138) data 0.001 (0.205) loss 0.2822 (0.2055) lr 6.9098e-04 eta 1:12:15
epoch [8/10] batch [440/816] time 1.891 (2.124) data 0.001 (0.195) loss 0.0052 (0.2006) lr 6.9098e-04 eta 1:11:04
epoch [8/10] batch [460/816] time 2.098 (2.099) data 0.000 (0.187) loss 0.0099 (0.2005) lr 6.9098e-04 eta 1:09:32
epoch [8/10] batch [480/816] time 2.281 (2.096) data 0.000 (0.179) loss 0.2155 (0.1993) lr 6.9098e-04 eta 1:08:44
epoch [8/10] batch [500/816] time 1.756 (2.078) data 0.001 (0.172) loss 0.0412 (0.2036) lr 6.9098e-04 eta 1:07:28
epoch [8/10] batch [520/816] time 1.628 (2.056) data 0.000 (0.165) loss 0.1475 (0.2050) lr 6.9098e-04 eta 1:06:03
epoch [8/10] batch [540/816] time 2.283 (2.054) data 0.001 (0.159) loss 0.0449 (0.2031) lr 6.9098e-04 eta 1:05:19
epoch [8/10] batch [560/816] time 1.720 (2.052) data 0.000 (0.154) loss 0.3030 (0.2016) lr 6.9098e-04 eta 1:04:33
epoch [8/10] batch [580/816] time 1.752 (2.051) data 0.000 (0.148) loss 0.1051 (0.1970) lr 6.9098e-04 eta 1:03:50
epoch [8/10] batch [600/816] time 1.472 (2.046) data 0.001 (0.143) loss 0.0417 (0.1942) lr 6.9098e-04 eta 1:03:00
epoch [8/10] batch [620/816] time 1.474 (2.030) data 0.001 (0.139) loss 0.0027 (0.2005) lr 6.9098e-04 eta 1:01:50
epoch [8/10] batch [640/816] time 1.657 (2.026) data 0.000 (0.134) loss 0.4001 (0.2000) lr 6.9098e-04 eta 1:01:03
epoch [8/10] batch [660/816] time 1.986 (2.025) data 0.000 (0.130) loss 0.1069 (0.2017) lr 6.9098e-04 eta 1:00:20
epoch [8/10] batch [680/816] time 1.822 (2.025) data 0.000 (0.127) loss 0.0560 (0.2002) lr 6.9098e-04 eta 0:59:39
epoch [8/10] batch [700/816] time 1.912 (2.023) data 0.000 (0.123) loss 0.0002 (0.1979) lr 6.9098e-04 eta 0:58:56
epoch [8/10] batch [720/816] time 1.986 (2.022) data 0.001 (0.120) loss 0.0014 (0.1954) lr 6.9098e-04 eta 0:58:13
epoch [8/10] batch [740/816] time 1.963 (2.020) data 0.001 (0.116) loss 0.0000 (0.1962) lr 6.9098e-04 eta 0:57:29
epoch [8/10] batch [760/816] time 1.935 (2.019) data 0.001 (0.113) loss 0.0717 (0.2001) lr 6.9098e-04 eta 0:56:47
epoch [8/10] batch [780/816] time 1.963 (2.015) data 0.001 (0.110) loss 0.0003 (0.2043) lr 6.9098e-04 eta 0:56:01
epoch [8/10] batch [800/816] time 1.996 (2.012) data 0.000 (0.108) loss 0.0201 (0.2033) lr 6.9098e-04 eta 0:55:15
epoch [9/10] batch [20/816] time 1.393 (5.605) data 0.000 (4.146) loss 0.0193 (0.2660) lr 4.1221e-04 eta 2:30:34
epoch [9/10] batch [40/816] time 1.673 (3.666) data 0.000 (2.073) loss 0.0002 (0.1775) lr 4.1221e-04 eta 1:37:16
epoch [9/10] batch [60/816] time 1.894 (3.029) data 0.001 (1.382) loss 0.0916 (0.2232) lr 4.1221e-04 eta 1:19:22
epoch [9/10] batch [80/816] time 1.689 (2.751) data 0.000 (1.037) loss 2.2012 (0.2161) lr 4.1221e-04 eta 1:11:09
epoch [9/10] batch [100/816] time 2.101 (2.599) data 0.001 (0.829) loss 0.0060 (0.2017) lr 4.1221e-04 eta 1:06:20
epoch [9/10] batch [120/816] time 1.437 (2.419) data 0.001 (0.691) loss 0.0008 (0.2100) lr 4.1221e-04 eta 1:00:58
epoch [9/10] batch [140/816] time 1.834 (2.329) data 0.000 (0.592) loss 0.5767 (0.1968) lr 4.1221e-04 eta 0:57:54
epoch [9/10] batch [160/816] time 1.967 (2.282) data 0.000 (0.518) loss 0.0018 (0.2099) lr 4.1221e-04 eta 0:55:58
epoch [9/10] batch [180/816] time 1.888 (2.249) data 0.000 (0.461) loss 1.9326 (0.2226) lr 4.1221e-04 eta 0:54:25
epoch [9/10] batch [200/816] time 1.824 (2.220) data 0.000 (0.415) loss 0.0000 (0.2113) lr 4.1221e-04 eta 0:52:58
epoch [9/10] batch [220/816] time 1.966 (2.196) data 0.000 (0.377) loss 0.7158 (0.2256) lr 4.1221e-04 eta 0:51:40
epoch [9/10] batch [240/816] time 1.863 (2.177) data 0.001 (0.346) loss 0.2251 (0.2268) lr 4.1221e-04 eta 0:50:30
epoch [9/10] batch [260/816] time 1.889 (2.157) data 0.000 (0.319) loss 0.0117 (0.2188) lr 4.1221e-04 eta 0:49:19
epoch [9/10] batch [280/816] time 1.814 (2.141) data 0.000 (0.296) loss 0.0048 (0.2070) lr 4.1221e-04 eta 0:48:14
epoch [9/10] batch [300/816] time 1.877 (2.121) data 0.001 (0.277) loss 0.0586 (0.2001) lr 4.1221e-04 eta 0:47:04
epoch [9/10] batch [320/816] time 1.872 (2.105) data 0.000 (0.259) loss 0.0195 (0.2022) lr 4.1221e-04 eta 0:46:01
epoch [9/10] batch [340/816] time 1.895 (2.093) data 0.000 (0.244) loss 0.4011 (0.1990) lr 4.1221e-04 eta 0:45:04
epoch [9/10] batch [360/816] time 1.469 (2.073) data 0.000 (0.231) loss 0.0024 (0.1969) lr 4.1221e-04 eta 0:43:56
epoch [9/10] batch [380/816] time 1.458 (2.042) data 0.000 (0.218) loss 0.0006 (0.1917) lr 4.1221e-04 eta 0:42:36
epoch [9/10] batch [400/816] time 2.049 (2.030) data 0.000 (0.208) loss 0.0060 (0.1939) lr 4.1221e-04 eta 0:41:41
epoch [9/10] batch [420/816] time 2.058 (2.026) data 0.000 (0.198) loss 0.0009 (0.1915) lr 4.1221e-04 eta 0:40:55
epoch [9/10] batch [440/816] time 1.875 (2.023) data 0.000 (0.189) loss 0.0013 (0.1907) lr 4.1221e-04 eta 0:40:11
epoch [9/10] batch [460/816] time 1.980 (2.017) data 0.000 (0.181) loss 0.6050 (0.1917) lr 4.1221e-04 eta 0:39:24
epoch [9/10] batch [480/816] time 2.016 (2.013) data 0.000 (0.173) loss 0.0478 (0.1901) lr 4.1221e-04 eta 0:38:38
epoch [9/10] batch [500/816] time 2.646 (2.014) data 0.000 (0.166) loss 0.0327 (0.1862) lr 4.1221e-04 eta 0:37:59
epoch [9/10] batch [520/816] time 2.291 (2.013) data 0.001 (0.160) loss 0.0201 (0.1851) lr 4.1221e-04 eta 0:37:18
epoch [9/10] batch [540/816] time 1.978 (2.011) data 0.000 (0.154) loss 0.0192 (0.1818) lr 4.1221e-04 eta 0:36:36
epoch [9/10] batch [560/816] time 1.950 (2.010) data 0.000 (0.148) loss 0.2328 (0.1782) lr 4.1221e-04 eta 0:35:55
epoch [9/10] batch [580/816] time 2.120 (2.010) data 0.000 (0.143) loss 0.5132 (0.1749) lr 4.1221e-04 eta 0:35:14
epoch [9/10] batch [600/816] time 1.989 (2.009) data 0.001 (0.138) loss 1.1465 (0.1733) lr 4.1221e-04 eta 0:34:33
epoch [9/10] batch [620/816] time 1.904 (2.007) data 0.000 (0.134) loss 0.0043 (0.1700) lr 4.1221e-04 eta 0:33:51
epoch [9/10] batch [640/816] time 1.837 (2.004) data 0.001 (0.130) loss 0.0037 (0.1682) lr 4.1221e-04 eta 0:33:08
epoch [9/10] batch [660/816] time 1.462 (1.991) data 0.000 (0.126) loss 0.0257 (0.1657) lr 4.1221e-04 eta 0:32:14
epoch [9/10] batch [680/816] time 2.377 (1.979) data 0.000 (0.122) loss 0.0000 (0.1669) lr 4.1221e-04 eta 0:31:23
epoch [9/10] batch [700/816] time 1.877 (1.979) data 0.001 (0.119) loss 2.7949 (0.1692) lr 4.1221e-04 eta 0:30:44
epoch [9/10] batch [720/816] time 1.762 (1.978) data 0.001 (0.115) loss 0.5889 (0.1672) lr 4.1221e-04 eta 0:30:03
epoch [9/10] batch [740/816] time 2.260 (1.978) data 0.000 (0.112) loss 0.5991 (0.1660) lr 4.1221e-04 eta 0:29:24
epoch [9/10] batch [760/816] time 2.691 (1.979) data 0.000 (0.109) loss 0.0313 (0.1633) lr 4.1221e-04 eta 0:28:45
epoch [9/10] batch [780/816] time 1.809 (1.978) data 0.001 (0.107) loss 0.2749 (0.1635) lr 4.1221e-04 eta 0:28:05
epoch [9/10] batch [800/816] time 1.830 (1.978) data 0.000 (0.104) loss 0.0006 (0.1605) lr 4.1221e-04 eta 0:27:25
epoch [10/10] batch [20/816] time 1.925 (6.005) data 0.000 (4.246) loss 0.0686 (0.0818) lr 1.9098e-04 eta 1:19:40
epoch [10/10] batch [40/816] time 1.735 (3.887) data 0.001 (2.123) loss 0.0000 (0.0859) lr 1.9098e-04 eta 0:50:16
epoch [10/10] batch [60/816] time 1.526 (3.213) data 0.001 (1.416) loss 0.0006 (0.1135) lr 1.9098e-04 eta 0:40:29
epoch [10/10] batch [80/816] time 1.962 (2.886) data 0.000 (1.062) loss 0.0732 (0.1080) lr 1.9098e-04 eta 0:35:24
epoch [10/10] batch [100/816] time 1.834 (2.696) data 0.000 (0.849) loss 0.0578 (0.1263) lr 1.9098e-04 eta 0:32:10
epoch [10/10] batch [120/816] time 2.174 (2.564) data 0.001 (0.708) loss 0.0106 (0.1309) lr 1.9098e-04 eta 0:29:44
epoch [10/10] batch [140/816] time 1.751 (2.435) data 0.000 (0.607) loss 0.0002 (0.1292) lr 1.9098e-04 eta 0:27:26
epoch [10/10] batch [160/816] time 1.526 (2.319) data 0.001 (0.531) loss 2.2461 (0.1430) lr 1.9098e-04 eta 0:25:21
epoch [10/10] batch [180/816] time 2.418 (2.283) data 0.000 (0.472) loss 0.0637 (0.1499) lr 1.9098e-04 eta 0:24:11
epoch [10/10] batch [200/816] time 1.985 (2.255) data 0.001 (0.425) loss 0.0213 (0.1409) lr 1.9098e-04 eta 0:23:09
epoch [10/10] batch [220/816] time 2.365 (2.226) data 0.000 (0.386) loss 0.0347 (0.1331) lr 1.9098e-04 eta 0:22:06
epoch [10/10] batch [240/816] time 2.126 (2.204) data 0.000 (0.354) loss 0.0164 (0.1346) lr 1.9098e-04 eta 0:21:09
epoch [10/10] batch [260/816] time 1.816 (2.186) data 0.000 (0.327) loss 0.6436 (0.1357) lr 1.9098e-04 eta 0:20:15
epoch [10/10] batch [280/816] time 1.753 (2.175) data 0.001 (0.304) loss 0.4863 (0.1351) lr 1.9098e-04 eta 0:19:25
epoch [10/10] batch [300/816] time 2.159 (2.164) data 0.001 (0.283) loss 0.0111 (0.1344) lr 1.9098e-04 eta 0:18:36
epoch [10/10] batch [320/816] time 1.948 (2.150) data 0.000 (0.266) loss 0.0083 (0.1318) lr 1.9098e-04 eta 0:17:46
epoch [10/10] batch [340/816] time 1.925 (2.134) data 0.000 (0.250) loss 0.3494 (0.1291) lr 1.9098e-04 eta 0:16:55
epoch [10/10] batch [360/816] time 1.952 (2.123) data 0.001 (0.236) loss 0.0035 (0.1252) lr 1.9098e-04 eta 0:16:08
epoch [10/10] batch [380/816] time 1.968 (2.114) data 0.000 (0.224) loss 0.0076 (0.1231) lr 1.9098e-04 eta 0:15:21
epoch [10/10] batch [400/816] time 1.889 (2.108) data 0.000 (0.213) loss 0.0047 (0.1204) lr 1.9098e-04 eta 0:14:36
epoch [10/10] batch [420/816] time 1.881 (2.101) data 0.000 (0.203) loss 0.0006 (0.1206) lr 1.9098e-04 eta 0:13:51
epoch [10/10] batch [440/816] time 1.771 (2.091) data 0.000 (0.193) loss 0.0328 (0.1238) lr 1.9098e-04 eta 0:13:06
epoch [10/10] batch [460/816] time 1.486 (2.083) data 0.000 (0.185) loss 0.0320 (0.1221) lr 1.9098e-04 eta 0:12:21
epoch [10/10] batch [480/816] time 1.463 (2.059) data 0.001 (0.177) loss 0.9243 (0.1273) lr 1.9098e-04 eta 0:11:31
epoch [10/10] batch [500/816] time 1.817 (2.047) data 0.000 (0.170) loss 0.6616 (0.1287) lr 1.9098e-04 eta 0:10:46
epoch [10/10] batch [520/816] time 1.557 (2.045) data 0.000 (0.164) loss 0.0001 (0.1270) lr 1.9098e-04 eta 0:10:05
epoch [10/10] batch [540/816] time 1.464 (2.026) data 0.000 (0.158) loss 0.4783 (0.1259) lr 1.9098e-04 eta 0:09:19
epoch [10/10] batch [560/816] time 1.820 (2.013) data 0.000 (0.152) loss 0.0190 (0.1250) lr 1.9098e-04 eta 0:08:35
epoch [10/10] batch [580/816] time 1.784 (2.017) data 0.000 (0.147) loss 0.1686 (0.1257) lr 1.9098e-04 eta 0:07:55
epoch [10/10] batch [600/816] time 3.113 (2.018) data 0.000 (0.142) loss 0.0273 (0.1239) lr 1.9098e-04 eta 0:07:15
epoch [10/10] batch [620/816] time 1.867 (2.019) data 0.000 (0.137) loss 0.0000 (0.1227) lr 1.9098e-04 eta 0:06:35
epoch [10/10] batch [640/816] time 1.882 (2.020) data 0.000 (0.133) loss 0.0113 (0.1221) lr 1.9098e-04 eta 0:05:55
epoch [10/10] batch [660/816] time 1.967 (2.020) data 0.000 (0.129) loss 0.0015 (0.1237) lr 1.9098e-04 eta 0:05:15
epoch [10/10] batch [680/816] time 1.942 (2.019) data 0.001 (0.125) loss 0.3394 (0.1311) lr 1.9098e-04 eta 0:04:34
epoch [10/10] batch [700/816] time 1.898 (2.017) data 0.000 (0.122) loss 0.9395 (0.1308) lr 1.9098e-04 eta 0:03:54
epoch [10/10] batch [720/816] time 1.983 (2.016) data 0.000 (0.118) loss 0.0015 (0.1317) lr 1.9098e-04 eta 0:03:13
epoch [10/10] batch [740/816] time 1.976 (2.015) data 0.000 (0.115) loss 0.0024 (0.1321) lr 1.9098e-04 eta 0:02:33
epoch [10/10] batch [760/816] time 1.850 (2.013) data 0.000 (0.112) loss 0.0067 (0.1307) lr 1.9098e-04 eta 0:01:52
epoch [10/10] batch [780/816] time 1.843 (2.010) data 0.000 (0.109) loss 0.4497 (0.1317) lr 1.9098e-04 eta 0:01:12
epoch [10/10] batch [800/816] time 1.945 (2.007) data 0.000 (0.106) loss 0.0001 (0.1309) lr 1.9098e-04 eta 0:00:32
Checkpoint saved to output/base2new/train_base/ucf101/shots_16/CoCoOp/vit_b16_c16_ep10_batch1_ctxv1/seed2\prompt_learner\model.pth.tar-10
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 1,934
* correct: 1,618
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 82.5%
Elapsed: 4:47:58
