***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoCoOp/vit_b16_c16_ep10_batch1.yaml
dataset_config_file: configs/datasets/fgvc_aircraft.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/0506/base2new/train_base/fgvc_aircraft/shots_16/CoCoOp/vit_b16_c16_ep10_batch1/seed2
resume: 
root: ../DATA
seed: 2
source_domains: None
target_domains: None
trainer: CoCoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 1
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: FGVCAircraft
  NUM_LABELED: -1
  NUM_SHOTS: 16
  ROOT: ../DATA
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_flip',)
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 10
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/0506/base2new/train_base/fgvc_aircraft/shots_16/CoCoOp/vit_b16_c16_ep10_batch1/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoCoOp
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 2.2.2+cu118
Is debug build: False
CUDA used to build PyTorch: 11.8
ROCM used to build PyTorch: N/A

OS: Microsoft Windows 11 ¼ÒÍ¥ÖÐÎÄ°æ
GCC version: (x86_64-win32-seh-rev0, Built by MinGW-W64 project) 8.1.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: N/A

Python version: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)] (64-bit runtime)
Python platform: Windows-10-10.0.22631-SP0
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 2060
Nvidia driver version: 527.54
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture=9
CurrentClockSpeed=2592
DeviceID=CPU0
Family=198
L2CacheSize=1536
L2CacheSpeed=
Manufacturer=GenuineIntel
MaxClockSpeed=2592
Name=Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz
ProcessorType=3
Revision=

Versions of relevant libraries:
[pip3] flake8==3.7.9
[pip3] numpy==1.26.0
[pip3] torch==2.2.2+cu118
[pip3] torchaudio==2.2.2+cu118
[pip3] torchvision==0.17.2+cu118
[conda] blas                      1.0                         mkl  
[conda] mkl                       2023.1.0         h6b88ed4_46357  
[conda] mkl-service               2.4.0           py310h2bbff1b_1  
[conda] mkl_fft                   1.3.8           py310h2bbff1b_0  
[conda] mkl_random                1.2.4           py310h59b6b97_0  
[conda] numpy                     1.26.0          py310h055cbcc_0  
[conda] numpy-base                1.26.0          py310h65a83cf_0  
[conda] torch                     1.13.1+cu117             pypi_0    pypi
[conda] torchaudio                0.13.1+cu117             pypi_0    pypi
[conda] torchvision               0.14.1                   pypi_0    pypi
        Pillow (9.4.0)

Loading trainer: CoCoOp
Loading dataset: FGVCAircraft
Loading preprocessed few-shot data from C:\Jupyter\MyConda\Experiment\1_CoOp_\DATA\fgvc_aircraft\split_fewshot\shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
Building transform_train
+ resize to 224x224
+ random flip
+ to torch tensor of range [0, 1]
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
---------  ------------
Dataset    FGVCAircraft
# classes  50
# train_x  800
# val      200
# test     1,666
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Aid context: "X X X"
Number of aid context words (tokens): 3
Turning off gradients in both the image and the text encoder
Parameters to be updated: {'prompt_learner.meta_net.linear2.bias', 'prompt_learner.ctx', 'prompt_learner.meta_net.linear1.weight', 'prompt_learner.meta_net.linear1.bias', 'prompt_learner.meta_net.linear2.weight'}
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/0506/base2new/train_base/fgvc_aircraft/shots_16/CoCoOp/vit_b16_c16_ep10_batch1/seed2\tensorboard)
epoch [1/10] batch [20/800] time 1.850 (5.467) data 0.000 (3.455) loss 8.3594 (5.5788) lr 1.0000e-05 eta 12:07:04
epoch [1/10] batch [40/800] time 1.849 (3.698) data 0.000 (1.728) loss 5.2148 (4.7089) lr 1.0000e-05 eta 8:10:34
epoch [1/10] batch [60/800] time 2.078 (3.093) data 0.000 (1.152) loss 1.9053 (4.3940) lr 1.0000e-05 eta 6:49:19
epoch [1/10] batch [80/800] time 1.872 (2.793) data 0.000 (0.864) loss 4.7930 (4.1210) lr 1.0000e-05 eta 6:08:42
epoch [1/10] batch [100/800] time 1.850 (2.610) data 0.000 (0.691) loss 1.6240 (4.0920) lr 1.0000e-05 eta 5:43:39
epoch [1/10] batch [120/800] time 1.865 (2.487) data 0.000 (0.576) loss 4.8633 (4.0546) lr 1.0000e-05 eta 5:26:39
epoch [1/10] batch [140/800] time 1.973 (2.401) data 0.000 (0.494) loss 3.5898 (3.9845) lr 1.0000e-05 eta 5:14:35
epoch [1/10] batch [160/800] time 2.097 (2.340) data 0.000 (0.432) loss 3.9551 (3.9793) lr 1.0000e-05 eta 5:05:44
epoch [1/10] batch [180/800] time 1.974 (2.283) data 0.000 (0.384) loss 3.3633 (3.8759) lr 1.0000e-05 eta 4:57:30
epoch [1/10] batch [200/800] time 1.983 (2.255) data 0.000 (0.346) loss 3.0195 (3.7777) lr 1.0000e-05 eta 4:53:12
epoch [1/10] batch [220/800] time 1.258 (2.222) data 0.000 (0.314) loss 5.8672 (3.7233) lr 1.0000e-05 eta 4:48:08
epoch [1/10] batch [240/800] time 2.043 (2.197) data 0.000 (0.288) loss 3.0859 (3.6154) lr 1.0000e-05 eta 4:44:07
epoch [1/10] batch [260/800] time 1.949 (2.168) data 0.000 (0.266) loss 5.9570 (3.5494) lr 1.0000e-05 eta 4:39:42
epoch [1/10] batch [280/800] time 1.872 (2.151) data 0.000 (0.247) loss 2.1191 (3.4698) lr 1.0000e-05 eta 4:36:41
epoch [1/10] batch [300/800] time 2.057 (2.134) data 0.000 (0.231) loss 2.5703 (3.4022) lr 1.0000e-05 eta 4:33:51
epoch [1/10] batch [320/800] time 1.868 (2.114) data 0.000 (0.216) loss 2.2891 (3.3391) lr 1.0000e-05 eta 4:30:38
epoch [1/10] batch [340/800] time 1.978 (2.105) data 0.000 (0.203) loss 1.7500 (3.2845) lr 1.0000e-05 eta 4:28:42
epoch [1/10] batch [360/800] time 1.285 (2.096) data 0.000 (0.192) loss 2.4336 (3.2449) lr 1.0000e-05 eta 4:26:50
epoch [1/10] batch [380/800] time 1.875 (2.082) data 0.000 (0.182) loss 1.8633 (3.2105) lr 1.0000e-05 eta 4:24:28
epoch [1/10] batch [400/800] time 2.048 (2.073) data 0.000 (0.173) loss 1.7715 (3.1492) lr 1.0000e-05 eta 4:22:33
epoch [1/10] batch [420/800] time 1.918 (2.070) data 0.000 (0.165) loss 1.7627 (3.1198) lr 1.0000e-05 eta 4:21:30
epoch [1/10] batch [440/800] time 1.852 (2.060) data 0.000 (0.157) loss 2.1758 (3.1088) lr 1.0000e-05 eta 4:19:34
epoch [1/10] batch [460/800] time 1.262 (2.051) data 0.000 (0.150) loss 3.6680 (3.0595) lr 1.0000e-05 eta 4:17:41
epoch [1/10] batch [480/800] time 1.937 (2.049) data 0.000 (0.144) loss 0.0889 (3.0219) lr 1.0000e-05 eta 4:16:50
epoch [1/10] batch [500/800] time 1.981 (2.041) data 0.000 (0.138) loss 4.3359 (2.9876) lr 1.0000e-05 eta 4:15:08
epoch [1/10] batch [520/800] time 2.007 (2.038) data 0.000 (0.133) loss 0.5278 (2.9397) lr 1.0000e-05 eta 4:14:00
epoch [1/10] batch [540/800] time 1.989 (2.031) data 0.000 (0.128) loss 0.4219 (2.9045) lr 1.0000e-05 eta 4:12:32
epoch [1/10] batch [560/800] time 1.983 (2.023) data 0.000 (0.124) loss 0.9580 (2.8790) lr 1.0000e-05 eta 4:10:54
epoch [1/10] batch [580/800] time 2.088 (2.021) data 0.000 (0.119) loss 2.9336 (2.8489) lr 1.0000e-05 eta 4:09:55
epoch [1/10] batch [600/800] time 1.905 (2.018) data 0.000 (0.115) loss 0.9829 (2.8317) lr 1.0000e-05 eta 4:08:56
epoch [1/10] batch [620/800] time 1.976 (2.015) data 0.000 (0.112) loss 0.8506 (2.8106) lr 1.0000e-05 eta 4:07:48
epoch [1/10] batch [640/800] time 1.762 (2.011) data 0.000 (0.108) loss 1.7588 (2.7828) lr 1.0000e-05 eta 4:06:39
epoch [1/10] batch [660/800] time 2.013 (2.009) data 0.000 (0.105) loss 2.0137 (2.7671) lr 1.0000e-05 eta 4:05:45
epoch [1/10] batch [680/800] time 1.796 (2.006) data 0.000 (0.102) loss 0.9775 (2.7420) lr 1.0000e-05 eta 4:04:46
epoch [1/10] batch [700/800] time 2.003 (2.004) data 0.000 (0.099) loss 0.9927 (2.7163) lr 1.0000e-05 eta 4:03:50
epoch [1/10] batch [720/800] time 1.866 (2.003) data 0.000 (0.096) loss 0.1362 (2.7192) lr 1.0000e-05 eta 4:02:58
epoch [1/10] batch [740/800] time 1.909 (1.999) data 0.000 (0.094) loss 4.5977 (2.7170) lr 1.0000e-05 eta 4:01:50
epoch [1/10] batch [760/800] time 1.885 (1.998) data 0.000 (0.091) loss 3.1562 (2.7167) lr 1.0000e-05 eta 4:01:05
epoch [1/10] batch [780/800] time 1.854 (1.996) data 0.004 (0.089) loss 0.7280 (2.7161) lr 1.0000e-05 eta 4:00:12
epoch [1/10] batch [800/800] time 1.866 (1.994) data 0.000 (0.087) loss 2.3711 (2.7068) lr 2.0000e-03 eta 3:59:15
epoch [2/10] batch [20/800] time 1.867 (5.187) data 0.000 (3.413) loss 1.5723 (2.5438) lr 2.0000e-03 eta 10:20:39
epoch [2/10] batch [40/800] time 1.913 (3.510) data 0.000 (1.706) loss 1.2861 (2.5760) lr 2.0000e-03 eta 6:58:54
epoch [2/10] batch [60/800] time 1.677 (2.936) data 0.000 (1.138) loss 3.8594 (2.5261) lr 2.0000e-03 eta 5:49:22
epoch [2/10] batch [80/800] time 1.854 (2.694) data 0.000 (0.853) loss 1.7275 (2.4105) lr 2.0000e-03 eta 5:19:41
epoch [2/10] batch [100/800] time 2.180 (2.560) data 0.000 (0.683) loss 1.0889 (2.3431) lr 2.0000e-03 eta 5:02:56
epoch [2/10] batch [120/800] time 1.854 (2.442) data 0.000 (0.569) loss 0.1646 (2.2916) lr 2.0000e-03 eta 4:48:08
epoch [2/10] batch [140/800] time 1.846 (2.347) data 0.000 (0.488) loss 1.9141 (2.2842) lr 2.0000e-03 eta 4:36:08
epoch [2/10] batch [160/800] time 1.686 (2.294) data 0.000 (0.427) loss 1.9941 (2.2938) lr 2.0000e-03 eta 4:29:10
epoch [2/10] batch [180/800] time 2.124 (2.263) data 0.000 (0.379) loss 3.1523 (2.2949) lr 2.0000e-03 eta 4:24:44
epoch [2/10] batch [200/800] time 1.881 (2.230) data 0.000 (0.342) loss 4.6602 (2.3230) lr 2.0000e-03 eta 4:20:11
epoch [2/10] batch [220/800] time 1.877 (2.210) data 0.000 (0.311) loss 0.6616 (2.3029) lr 2.0000e-03 eta 4:17:03
epoch [2/10] batch [240/800] time 2.259 (2.198) data 0.000 (0.285) loss 2.5215 (2.2656) lr 2.0000e-03 eta 4:14:58
epoch [2/10] batch [260/800] time 2.012 (2.189) data 0.000 (0.263) loss 0.8672 (2.2252) lr 2.0000e-03 eta 4:13:08
epoch [2/10] batch [280/800] time 1.909 (2.171) data 0.000 (0.244) loss 3.6855 (2.2174) lr 2.0000e-03 eta 4:10:22
epoch [2/10] batch [300/800] time 2.553 (2.164) data 0.000 (0.228) loss 5.0469 (2.2307) lr 2.0000e-03 eta 4:08:49
epoch [2/10] batch [320/800] time 2.008 (2.160) data 0.000 (0.214) loss 0.3804 (2.1728) lr 2.0000e-03 eta 4:07:39
epoch [2/10] batch [340/800] time 1.310 (2.149) data 0.000 (0.201) loss 2.4551 (2.1838) lr 2.0000e-03 eta 4:05:40
epoch [2/10] batch [360/800] time 1.934 (2.133) data 0.004 (0.190) loss 2.8086 (2.1636) lr 2.0000e-03 eta 4:03:12
epoch [2/10] batch [380/800] time 1.987 (2.126) data 0.000 (0.180) loss 2.1543 (2.1639) lr 2.0000e-03 eta 4:01:37
epoch [2/10] batch [400/800] time 1.977 (2.112) data 0.000 (0.171) loss 1.5244 (2.1628) lr 2.0000e-03 eta 3:59:23
epoch [2/10] batch [420/800] time 1.996 (2.101) data 0.000 (0.163) loss 2.3398 (2.1587) lr 2.0000e-03 eta 3:57:25
epoch [2/10] batch [440/800] time 1.497 (2.090) data 0.000 (0.155) loss 0.3235 (2.1499) lr 2.0000e-03 eta 3:55:29
epoch [2/10] batch [460/800] time 2.176 (2.088) data 0.000 (0.149) loss 1.7705 (2.1707) lr 2.0000e-03 eta 3:54:34
epoch [2/10] batch [480/800] time 2.032 (2.086) data 0.000 (0.143) loss 6.6250 (2.1710) lr 2.0000e-03 eta 3:53:37
epoch [2/10] batch [500/800] time 2.040 (2.083) data 0.000 (0.137) loss 3.6230 (2.1897) lr 2.0000e-03 eta 3:52:36
epoch [2/10] batch [520/800] time 2.326 (2.082) data 0.000 (0.132) loss 4.2695 (2.2074) lr 2.0000e-03 eta 3:51:46
epoch [2/10] batch [540/800] time 1.279 (2.075) data 0.000 (0.127) loss 2.3945 (2.2162) lr 2.0000e-03 eta 3:50:16
epoch [2/10] batch [560/800] time 1.866 (2.068) data 0.000 (0.122) loss 1.5781 (2.1976) lr 2.0000e-03 eta 3:48:53
epoch [2/10] batch [580/800] time 1.882 (2.063) data 0.000 (0.118) loss 3.1973 (2.1870) lr 2.0000e-03 eta 3:47:39
epoch [2/10] batch [600/800] time 1.915 (2.058) data 0.004 (0.114) loss 1.5391 (2.1921) lr 2.0000e-03 eta 3:46:21
epoch [2/10] batch [620/800] time 2.061 (2.053) data 0.000 (0.110) loss 3.4590 (2.1886) lr 2.0000e-03 eta 3:45:06
epoch [2/10] batch [640/800] time 1.848 (2.055) data 0.001 (0.107) loss 0.1670 (2.1829) lr 2.0000e-03 eta 3:44:43
epoch [2/10] batch [660/800] time 3.334 (2.061) data 0.000 (0.104) loss 1.1641 (2.1748) lr 2.0000e-03 eta 3:44:41
epoch [2/10] batch [680/800] time 2.320 (2.070) data 0.000 (0.101) loss 0.7856 (2.1649) lr 2.0000e-03 eta 3:44:57
epoch [2/10] batch [700/800] time 2.625 (2.065) data 0.004 (0.098) loss 5.5820 (2.1763) lr 2.0000e-03 eta 3:43:42
epoch [2/10] batch [720/800] time 1.881 (2.060) data 0.000 (0.095) loss 0.6494 (2.1739) lr 2.0000e-03 eta 3:42:25
epoch [2/10] batch [740/800] time 2.406 (2.056) data 0.000 (0.093) loss 1.8506 (2.1647) lr 2.0000e-03 eta 3:41:18
epoch [2/10] batch [760/800] time 2.222 (2.054) data 0.000 (0.090) loss 2.8398 (2.1569) lr 2.0000e-03 eta 3:40:29
epoch [2/10] batch [780/800] time 1.849 (2.050) data 0.000 (0.088) loss 0.3462 (2.1514) lr 2.0000e-03 eta 3:39:22
epoch [2/10] batch [800/800] time 1.866 (2.045) data 0.000 (0.086) loss 2.2148 (2.1464) lr 1.9511e-03 eta 3:38:09
epoch [3/10] batch [20/800] time 1.846 (4.989) data 0.000 (3.201) loss 4.0469 (2.0394) lr 1.9511e-03 eta 8:50:28
epoch [3/10] batch [40/800] time 1.881 (3.447) data 0.004 (1.601) loss 0.7690 (2.1128) lr 1.9511e-03 eta 6:05:20
epoch [3/10] batch [60/800] time 1.851 (2.923) data 0.000 (1.067) loss 2.8242 (2.0981) lr 1.9511e-03 eta 5:08:52
epoch [3/10] batch [80/800] time 1.929 (2.656) data 0.000 (0.801) loss 3.4531 (2.1147) lr 1.9511e-03 eta 4:39:47
epoch [3/10] batch [100/800] time 1.946 (2.513) data 0.000 (0.641) loss 0.7129 (2.0817) lr 1.9511e-03 eta 4:23:49
epoch [3/10] batch [120/800] time 1.854 (2.388) data 0.000 (0.534) loss 2.2793 (2.0164) lr 1.9511e-03 eta 4:09:57
epoch [3/10] batch [140/800] time 1.850 (2.311) data 0.000 (0.458) loss 1.4102 (1.9678) lr 1.9511e-03 eta 4:01:08
epoch [3/10] batch [160/800] time 1.842 (2.254) data 0.000 (0.401) loss 1.4092 (1.9717) lr 1.9511e-03 eta 3:54:21
epoch [3/10] batch [180/800] time 1.262 (2.205) data 0.004 (0.356) loss 1.2793 (1.9682) lr 1.9511e-03 eta 3:48:35
epoch [3/10] batch [200/800] time 1.858 (2.162) data 0.000 (0.320) loss 2.3457 (1.9567) lr 1.9511e-03 eta 3:43:26
epoch [3/10] batch [220/800] time 1.598 (2.133) data 0.000 (0.291) loss 4.2383 (1.9791) lr 1.9511e-03 eta 3:39:43
epoch [3/10] batch [240/800] time 1.880 (2.114) data 0.000 (0.267) loss 2.0195 (2.0030) lr 1.9511e-03 eta 3:36:59
epoch [3/10] batch [260/800] time 1.875 (2.093) data 0.000 (0.247) loss 3.7754 (2.0389) lr 1.9511e-03 eta 3:34:08
epoch [3/10] batch [280/800] time 1.878 (2.074) data 0.000 (0.229) loss 0.7773 (1.9978) lr 1.9511e-03 eta 3:31:35
epoch [3/10] batch [300/800] time 1.880 (2.056) data 0.000 (0.214) loss 0.0044 (1.9815) lr 1.9511e-03 eta 3:29:03
epoch [3/10] batch [320/800] time 1.882 (2.043) data 0.000 (0.201) loss 0.0097 (1.9494) lr 1.9511e-03 eta 3:26:59
epoch [3/10] batch [340/800] time 1.881 (2.033) data 0.000 (0.189) loss 2.1719 (1.9587) lr 1.9511e-03 eta 3:25:19
epoch [3/10] batch [360/800] time 1.292 (2.021) data 0.000 (0.178) loss 1.4482 (1.9608) lr 1.9511e-03 eta 3:23:26
epoch [3/10] batch [380/800] time 1.874 (2.012) data 0.000 (0.169) loss 2.5352 (1.9676) lr 1.9511e-03 eta 3:21:53
epoch [3/10] batch [400/800] time 1.864 (2.005) data 0.000 (0.160) loss 1.5225 (1.9543) lr 1.9511e-03 eta 3:20:32
epoch [3/10] batch [420/800] time 1.871 (1.999) data 0.000 (0.153) loss 0.2263 (1.9708) lr 1.9511e-03 eta 3:19:15
epoch [3/10] batch [440/800] time 1.874 (1.990) data 0.000 (0.146) loss 0.7031 (1.9717) lr 1.9511e-03 eta 3:17:42
epoch [3/10] batch [460/800] time 1.877 (1.984) data 0.000 (0.140) loss 1.4561 (1.9690) lr 1.9511e-03 eta 3:16:23
epoch [3/10] batch [480/800] time 1.867 (1.978) data 0.000 (0.134) loss 2.3965 (1.9719) lr 1.9511e-03 eta 3:15:08
epoch [3/10] batch [500/800] time 1.892 (1.974) data 0.000 (0.128) loss 1.4795 (1.9574) lr 1.9511e-03 eta 3:14:06
epoch [3/10] batch [520/800] time 1.886 (1.969) data 0.000 (0.123) loss 2.4121 (1.9471) lr 1.9511e-03 eta 3:13:00
epoch [3/10] batch [540/800] time 1.874 (1.965) data 0.000 (0.119) loss 1.8496 (1.9520) lr 1.9511e-03 eta 3:11:52
epoch [3/10] batch [560/800] time 1.888 (1.960) data 0.000 (0.115) loss 1.6572 (1.9342) lr 1.9511e-03 eta 3:10:46
epoch [3/10] batch [580/800] time 1.881 (1.957) data 0.000 (0.111) loss 2.3926 (1.9370) lr 1.9511e-03 eta 3:09:50
epoch [3/10] batch [600/800] time 1.868 (1.954) data 0.000 (0.107) loss 2.3438 (1.9417) lr 1.9511e-03 eta 3:08:56
epoch [3/10] batch [620/800] time 1.860 (1.952) data 0.000 (0.104) loss 2.0801 (1.9507) lr 1.9511e-03 eta 3:08:02
epoch [3/10] batch [640/800] time 1.874 (1.948) data 0.000 (0.100) loss 6.5781 (1.9513) lr 1.9511e-03 eta 3:07:03
epoch [3/10] batch [660/800] time 1.870 (1.946) data 0.000 (0.097) loss 4.0820 (1.9672) lr 1.9511e-03 eta 3:06:12
epoch [3/10] batch [680/800] time 1.881 (1.944) data 0.000 (0.094) loss 0.9565 (1.9539) lr 1.9511e-03 eta 3:05:18
epoch [3/10] batch [700/800] time 1.875 (1.941) data 0.000 (0.092) loss 5.4141 (1.9583) lr 1.9511e-03 eta 3:04:22
epoch [3/10] batch [720/800] time 1.876 (1.939) data 0.000 (0.089) loss 0.1357 (1.9551) lr 1.9511e-03 eta 3:03:33
epoch [3/10] batch [740/800] time 1.879 (1.937) data 0.000 (0.087) loss 0.9482 (1.9569) lr 1.9511e-03 eta 3:02:45
epoch [3/10] batch [760/800] time 1.878 (1.935) data 0.000 (0.085) loss 0.5054 (1.9681) lr 1.9511e-03 eta 3:01:52
epoch [3/10] batch [780/800] time 1.862 (1.933) data 0.000 (0.082) loss 3.7812 (1.9722) lr 1.9511e-03 eta 3:01:05
epoch [3/10] batch [800/800] time 1.874 (1.931) data 0.000 (0.080) loss 2.4219 (1.9640) lr 1.8090e-03 eta 3:00:16
epoch [4/10] batch [20/800] time 1.878 (5.065) data 0.000 (3.203) loss 2.6387 (1.5857) lr 1.8090e-03 eta 7:51:03
epoch [4/10] batch [40/800] time 1.872 (3.451) data 0.000 (1.602) loss 2.8145 (1.5911) lr 1.8090e-03 eta 5:19:49
epoch [4/10] batch [60/800] time 1.876 (2.913) data 0.000 (1.068) loss 2.8574 (1.7679) lr 1.8090e-03 eta 4:28:58
epoch [4/10] batch [80/800] time 1.885 (2.654) data 0.004 (0.801) loss 2.0918 (1.7917) lr 1.8090e-03 eta 4:04:11
epoch [4/10] batch [100/800] time 1.875 (2.487) data 0.000 (0.641) loss 2.6855 (1.8638) lr 1.8090e-03 eta 3:47:57
epoch [4/10] batch [120/800] time 1.874 (2.379) data 0.000 (0.534) loss 0.0913 (1.8005) lr 1.8090e-03 eta 3:37:15
epoch [4/10] batch [140/800] time 1.870 (2.302) data 0.000 (0.458) loss 2.1523 (1.8197) lr 1.8090e-03 eta 3:29:26
epoch [4/10] batch [160/800] time 1.879 (2.248) data 0.000 (0.401) loss 1.1982 (1.8324) lr 1.8090e-03 eta 3:23:51
epoch [4/10] batch [180/800] time 1.885 (2.204) data 0.000 (0.356) loss 0.6860 (1.7988) lr 1.8090e-03 eta 3:19:04
epoch [4/10] batch [200/800] time 1.874 (2.171) data 0.000 (0.321) loss 1.1670 (1.8101) lr 1.8090e-03 eta 3:15:24
epoch [4/10] batch [220/800] time 1.882 (2.144) data 0.000 (0.291) loss 4.2852 (1.8190) lr 1.8090e-03 eta 3:12:17
epoch [4/10] batch [240/800] time 1.875 (2.119) data 0.000 (0.267) loss 1.0273 (1.8124) lr 1.8090e-03 eta 3:09:16
epoch [4/10] batch [260/800] time 1.878 (2.100) data 0.000 (0.247) loss 3.9746 (1.8359) lr 1.8090e-03 eta 3:06:54
epoch [4/10] batch [280/800] time 1.871 (2.083) data 0.000 (0.229) loss 0.8877 (1.8398) lr 1.8090e-03 eta 3:04:41
epoch [4/10] batch [300/800] time 1.883 (2.069) data 0.000 (0.214) loss 5.5781 (1.8621) lr 1.8090e-03 eta 3:02:47
epoch [4/10] batch [320/800] time 1.887 (2.057) data 0.000 (0.200) loss 3.1191 (1.8658) lr 1.8090e-03 eta 3:01:03
epoch [4/10] batch [340/800] time 1.881 (2.044) data 0.000 (0.189) loss 1.7334 (1.8656) lr 1.8090e-03 eta 2:59:13
epoch [4/10] batch [360/800] time 1.878 (2.035) data 0.000 (0.178) loss 0.5479 (1.8660) lr 1.8090e-03 eta 2:57:43
epoch [4/10] batch [380/800] time 1.875 (2.027) data 0.000 (0.169) loss 1.7451 (1.8544) lr 1.8090e-03 eta 2:56:20
epoch [4/10] batch [400/800] time 1.863 (2.019) data 0.000 (0.160) loss 0.4514 (1.8540) lr 1.8090e-03 eta 2:55:00
epoch [4/10] batch [420/800] time 1.881 (2.011) data 0.000 (0.153) loss 3.1309 (1.8471) lr 1.8090e-03 eta 2:53:35
epoch [4/10] batch [440/800] time 1.879 (2.005) data 0.000 (0.146) loss 1.1641 (1.8574) lr 1.8090e-03 eta 2:52:24
epoch [4/10] batch [460/800] time 1.887 (1.998) data 0.000 (0.139) loss 2.2988 (1.8648) lr 1.8090e-03 eta 2:51:11
epoch [4/10] batch [480/800] time 1.874 (1.992) data 0.000 (0.134) loss 3.4258 (1.8644) lr 1.8090e-03 eta 2:50:00
epoch [4/10] batch [500/800] time 1.887 (1.986) data 0.000 (0.128) loss 1.2822 (1.8790) lr 1.8090e-03 eta 2:48:49
epoch [4/10] batch [520/800] time 1.879 (1.981) data 0.000 (0.123) loss 2.6406 (1.8830) lr 1.8090e-03 eta 2:47:44
epoch [4/10] batch [540/800] time 1.873 (1.977) data 0.000 (0.119) loss 1.2354 (1.8855) lr 1.8090e-03 eta 2:46:41
epoch [4/10] batch [560/800] time 1.871 (1.973) data 0.000 (0.115) loss 0.5337 (1.8855) lr 1.8090e-03 eta 2:45:43
epoch [4/10] batch [580/800] time 1.874 (1.969) data 0.000 (0.111) loss 0.0836 (1.8701) lr 1.8090e-03 eta 2:44:43
epoch [4/10] batch [600/800] time 1.883 (1.966) data 0.004 (0.107) loss 3.6055 (1.8717) lr 1.8090e-03 eta 2:43:49
epoch [4/10] batch [620/800] time 1.860 (1.963) data 0.000 (0.104) loss 1.3818 (1.8734) lr 1.8090e-03 eta 2:42:56
epoch [4/10] batch [640/800] time 1.866 (1.959) data 0.000 (0.100) loss 0.9048 (1.8621) lr 1.8090e-03 eta 2:41:57
epoch [4/10] batch [660/800] time 1.704 (1.956) data 0.000 (0.097) loss 3.8164 (1.8608) lr 1.8090e-03 eta 2:41:00
epoch [4/10] batch [680/800] time 1.884 (1.952) data 0.000 (0.094) loss 0.7139 (1.8567) lr 1.8090e-03 eta 2:40:04
epoch [4/10] batch [700/800] time 1.871 (1.950) data 0.000 (0.092) loss 2.5430 (1.8678) lr 1.8090e-03 eta 2:39:15
epoch [4/10] batch [720/800] time 1.871 (1.947) data 0.000 (0.089) loss 2.6055 (1.8714) lr 1.8090e-03 eta 2:38:21
epoch [4/10] batch [740/800] time 1.865 (1.945) data 0.000 (0.087) loss 4.3164 (1.8852) lr 1.8090e-03 eta 2:37:32
epoch [4/10] batch [760/800] time 1.881 (1.943) data 0.000 (0.084) loss 2.7148 (1.8768) lr 1.8090e-03 eta 2:36:43
epoch [4/10] batch [780/800] time 1.870 (1.940) data 0.000 (0.082) loss 3.7637 (1.8799) lr 1.8090e-03 eta 2:35:51
epoch [4/10] batch [800/800] time 1.419 (1.938) data 0.004 (0.080) loss 5.0273 (1.8886) lr 1.5878e-03 eta 2:35:02
epoch [5/10] batch [20/800] time 1.886 (4.948) data 0.000 (3.218) loss 3.2617 (1.7433) lr 1.5878e-03 eta 6:34:10
epoch [5/10] batch [40/800] time 1.878 (3.383) data 0.000 (1.609) loss 2.1504 (1.8032) lr 1.5878e-03 eta 4:28:23
epoch [5/10] batch [60/800] time 1.874 (2.868) data 0.000 (1.073) loss 1.1240 (1.8297) lr 1.5878e-03 eta 3:46:32
epoch [5/10] batch [80/800] time 1.886 (2.621) data 0.004 (0.805) loss 1.6768 (1.6979) lr 1.5878e-03 eta 3:26:08
epoch [5/10] batch [100/800] time 1.872 (2.461) data 0.000 (0.644) loss 0.0369 (1.6705) lr 1.5878e-03 eta 3:12:46
epoch [5/10] batch [120/800] time 1.873 (2.357) data 0.000 (0.537) loss 1.5898 (1.6591) lr 1.5878e-03 eta 3:03:49
epoch [5/10] batch [140/800] time 1.884 (2.285) data 0.000 (0.460) loss 1.2500 (1.6755) lr 1.5878e-03 eta 2:57:29
epoch [5/10] batch [160/800] time 1.877 (2.234) data 0.000 (0.403) loss 1.4473 (1.6337) lr 1.5878e-03 eta 2:52:46
epoch [5/10] batch [180/800] time 1.873 (2.194) data 0.000 (0.358) loss 3.4512 (1.6348) lr 1.5878e-03 eta 2:48:58
epoch [5/10] batch [200/800] time 1.866 (2.159) data 0.000 (0.322) loss 4.7344 (1.6328) lr 1.5878e-03 eta 2:45:31
epoch [5/10] batch [220/800] time 1.875 (2.133) data 0.000 (0.293) loss 1.4932 (1.6056) lr 1.5878e-03 eta 2:42:50
epoch [5/10] batch [240/800] time 1.880 (2.112) data 0.000 (0.268) loss 2.3633 (1.6379) lr 1.5878e-03 eta 2:40:30
epoch [5/10] batch [260/800] time 1.875 (2.088) data 0.000 (0.248) loss 2.1797 (1.6889) lr 1.5878e-03 eta 2:37:58
epoch [5/10] batch [280/800] time 1.874 (2.069) data 0.000 (0.230) loss 0.6694 (1.7185) lr 1.5878e-03 eta 2:35:49
epoch [5/10] batch [300/800] time 1.863 (2.053) data 0.000 (0.215) loss 0.3704 (1.7000) lr 1.5878e-03 eta 2:33:59
epoch [5/10] batch [320/800] time 1.893 (2.041) data 0.000 (0.201) loss 1.6816 (1.7046) lr 1.5878e-03 eta 2:32:22
epoch [5/10] batch [340/800] time 1.875 (2.031) data 0.000 (0.190) loss 1.4180 (1.7150) lr 1.5878e-03 eta 2:30:58
epoch [5/10] batch [360/800] time 1.884 (2.021) data 0.000 (0.179) loss 1.3809 (1.7333) lr 1.5878e-03 eta 2:29:31
epoch [5/10] batch [380/800] time 1.891 (2.013) data 0.000 (0.170) loss 3.3301 (1.7457) lr 1.5878e-03 eta 2:28:17
epoch [5/10] batch [400/800] time 1.877 (2.005) data 0.000 (0.161) loss 2.0938 (1.7451) lr 1.5878e-03 eta 2:26:59
epoch [5/10] batch [420/800] time 1.876 (1.998) data 0.000 (0.154) loss 2.5977 (1.7652) lr 1.5878e-03 eta 2:25:53
epoch [5/10] batch [440/800] time 1.875 (1.991) data 0.000 (0.147) loss 0.7471 (1.7792) lr 1.5878e-03 eta 2:24:41
epoch [5/10] batch [460/800] time 1.879 (1.986) data 0.000 (0.140) loss 0.8188 (1.7934) lr 1.5878e-03 eta 2:23:39
epoch [5/10] batch [480/800] time 1.267 (1.979) data 0.000 (0.134) loss 0.0471 (1.8013) lr 1.5878e-03 eta 2:22:28
epoch [5/10] batch [500/800] time 1.881 (1.974) data 0.000 (0.129) loss 4.5156 (1.8106) lr 1.5878e-03 eta 2:21:29
epoch [5/10] batch [520/800] time 1.870 (1.971) data 0.000 (0.124) loss 2.5488 (1.7994) lr 1.5878e-03 eta 2:20:34
epoch [5/10] batch [540/800] time 1.877 (1.967) data 0.000 (0.119) loss 4.0781 (1.7937) lr 1.5878e-03 eta 2:19:40
epoch [5/10] batch [560/800] time 1.886 (1.964) data 0.000 (0.115) loss 0.9849 (1.7930) lr 1.5878e-03 eta 2:18:47
epoch [5/10] batch [580/800] time 1.888 (1.960) data 0.000 (0.111) loss 1.7422 (1.7975) lr 1.5878e-03 eta 2:17:49
epoch [5/10] batch [600/800] time 1.878 (1.957) data 0.000 (0.108) loss 2.2168 (1.7950) lr 1.5878e-03 eta 2:16:58
epoch [5/10] batch [620/800] time 1.859 (1.953) data 0.000 (0.104) loss 3.3105 (1.8074) lr 1.5878e-03 eta 2:16:03
epoch [5/10] batch [640/800] time 1.865 (1.949) data 0.000 (0.101) loss 1.2588 (1.8127) lr 1.5878e-03 eta 2:15:09
epoch [5/10] batch [660/800] time 1.867 (1.947) data 0.000 (0.098) loss 2.7266 (1.8024) lr 1.5878e-03 eta 2:14:21
epoch [5/10] batch [680/800] time 1.871 (1.944) data 0.000 (0.095) loss 2.0391 (1.8018) lr 1.5878e-03 eta 2:13:29
epoch [5/10] batch [700/800] time 1.870 (1.942) data 0.000 (0.092) loss 1.2363 (1.8121) lr 1.5878e-03 eta 2:12:43
epoch [5/10] batch [720/800] time 1.873 (1.939) data 0.000 (0.090) loss 2.2461 (1.8167) lr 1.5878e-03 eta 2:11:50
epoch [5/10] batch [740/800] time 1.876 (1.937) data 0.000 (0.087) loss 0.0039 (1.8305) lr 1.5878e-03 eta 2:11:04
epoch [5/10] batch [760/800] time 1.874 (1.936) data 0.000 (0.085) loss 2.5840 (1.8297) lr 1.5878e-03 eta 2:10:19
epoch [5/10] batch [780/800] time 1.870 (1.933) data 0.000 (0.083) loss 3.3594 (1.8253) lr 1.5878e-03 eta 2:09:31
epoch [5/10] batch [800/800] time 1.860 (1.931) data 0.000 (0.081) loss 2.3047 (1.8296) lr 1.3090e-03 eta 2:08:43
epoch [6/10] batch [20/800] time 1.869 (4.984) data 0.000 (3.186) loss 0.2561 (1.4975) lr 1.3090e-03 eta 5:30:37
epoch [6/10] batch [40/800] time 1.859 (3.430) data 0.000 (1.593) loss 2.0859 (1.8034) lr 1.3090e-03 eta 3:46:23
epoch [6/10] batch [60/800] time 1.868 (2.886) data 0.000 (1.062) loss 2.7051 (1.7222) lr 1.3090e-03 eta 3:09:32
epoch [6/10] batch [80/800] time 1.881 (2.634) data 0.000 (0.797) loss 2.0547 (1.6909) lr 1.3090e-03 eta 2:52:03
epoch [6/10] batch [100/800] time 1.883 (2.467) data 0.004 (0.637) loss 3.5273 (1.7014) lr 1.3090e-03 eta 2:40:19
epoch [6/10] batch [120/800] time 1.863 (2.368) data 0.000 (0.531) loss 0.5425 (1.6733) lr 1.3090e-03 eta 2:33:08
epoch [6/10] batch [140/800] time 1.875 (2.292) data 0.000 (0.455) loss 1.3877 (1.6647) lr 1.3090e-03 eta 2:27:28
epoch [6/10] batch [160/800] time 1.864 (2.235) data 0.000 (0.398) loss 1.0137 (1.6348) lr 1.3090e-03 eta 2:23:02
epoch [6/10] batch [180/800] time 1.878 (2.195) data 0.000 (0.354) loss 1.4180 (1.6459) lr 1.3090e-03 eta 2:19:46
epoch [6/10] batch [200/800] time 1.874 (2.156) data 0.000 (0.319) loss 1.1680 (1.6798) lr 1.3090e-03 eta 2:16:31
epoch [6/10] batch [220/800] time 1.869 (2.130) data 0.000 (0.290) loss 0.3689 (1.6597) lr 1.3090e-03 eta 2:14:12
epoch [6/10] batch [240/800] time 1.869 (2.106) data 0.000 (0.266) loss 1.9502 (1.7121) lr 1.3090e-03 eta 2:11:58
epoch [6/10] batch [260/800] time 1.875 (2.083) data 0.004 (0.245) loss 3.5547 (1.7124) lr 1.3090e-03 eta 2:09:48
epoch [6/10] batch [280/800] time 1.871 (2.065) data 0.000 (0.228) loss 1.1963 (1.7095) lr 1.3090e-03 eta 2:08:02
epoch [6/10] batch [300/800] time 1.883 (2.050) data 0.000 (0.213) loss 0.8940 (1.7028) lr 1.3090e-03 eta 2:06:24
epoch [6/10] batch [320/800] time 1.714 (2.037) data 0.000 (0.199) loss 0.9497 (1.6999) lr 1.3090e-03 eta 2:04:55
epoch [6/10] batch [340/800] time 1.870 (2.027) data 0.000 (0.188) loss 0.7769 (1.6924) lr 1.3090e-03 eta 2:03:40
epoch [6/10] batch [360/800] time 1.866 (2.019) data 0.000 (0.177) loss 2.2734 (1.6860) lr 1.3090e-03 eta 2:02:29
epoch [6/10] batch [380/800] time 1.864 (2.010) data 0.000 (0.168) loss 1.6484 (1.6893) lr 1.3090e-03 eta 2:01:14
epoch [6/10] batch [400/800] time 1.886 (2.003) data 0.000 (0.160) loss 1.7607 (1.6773) lr 1.3090e-03 eta 2:00:10
epoch [6/10] batch [420/800] time 1.877 (1.997) data 0.000 (0.152) loss 1.8379 (1.6772) lr 1.3090e-03 eta 1:59:08
epoch [6/10] batch [440/800] time 1.872 (1.991) data 0.004 (0.145) loss 2.3828 (1.6974) lr 1.3090e-03 eta 1:58:08
epoch [6/10] batch [460/800] time 1.882 (1.986) data 0.000 (0.139) loss 2.8438 (1.7082) lr 1.3090e-03 eta 1:57:11
epoch [6/10] batch [480/800] time 1.876 (1.978) data 0.000 (0.133) loss 1.6885 (1.7278) lr 1.3090e-03 eta 1:56:04
epoch [6/10] batch [500/800] time 1.726 (1.973) data 0.004 (0.128) loss 1.5010 (1.7486) lr 1.3090e-03 eta 1:55:04
epoch [6/10] batch [520/800] time 1.882 (1.968) data 0.000 (0.123) loss 0.9800 (1.7471) lr 1.3090e-03 eta 1:54:07
epoch [6/10] batch [540/800] time 1.868 (1.964) data 0.000 (0.118) loss 1.4307 (1.7551) lr 1.3090e-03 eta 1:53:13
epoch [6/10] batch [560/800] time 1.876 (1.960) data 0.000 (0.114) loss 2.1777 (1.7623) lr 1.3090e-03 eta 1:52:23
epoch [6/10] batch [580/800] time 1.725 (1.956) data 0.000 (0.110) loss 3.2012 (1.7697) lr 1.3090e-03 eta 1:51:30
epoch [6/10] batch [600/800] time 1.894 (1.954) data 0.000 (0.106) loss 1.5586 (1.7761) lr 1.3090e-03 eta 1:50:42
epoch [6/10] batch [620/800] time 1.874 (1.950) data 0.000 (0.103) loss 2.9766 (1.7759) lr 1.3090e-03 eta 1:49:51
epoch [6/10] batch [640/800] time 1.874 (1.947) data 0.000 (0.100) loss 1.0479 (1.7803) lr 1.3090e-03 eta 1:49:00
epoch [6/10] batch [660/800] time 1.280 (1.943) data 0.000 (0.097) loss 1.5762 (1.7695) lr 1.3090e-03 eta 1:48:09
epoch [6/10] batch [680/800] time 1.880 (1.941) data 0.000 (0.094) loss 0.7578 (1.7649) lr 1.3090e-03 eta 1:47:22
epoch [6/10] batch [700/800] time 1.885 (1.939) data 0.000 (0.091) loss 1.1768 (1.7691) lr 1.3090e-03 eta 1:46:38
epoch [6/10] batch [720/800] time 1.868 (1.937) data 0.000 (0.089) loss 1.5625 (1.7612) lr 1.3090e-03 eta 1:45:53
epoch [6/10] batch [740/800] time 1.884 (1.934) data 0.000 (0.086) loss 0.2343 (1.7658) lr 1.3090e-03 eta 1:45:06
epoch [6/10] batch [760/800] time 1.876 (1.933) data 0.000 (0.084) loss 2.7246 (1.7655) lr 1.3090e-03 eta 1:44:22
epoch [6/10] batch [780/800] time 1.872 (1.930) data 0.000 (0.082) loss 1.4248 (1.7666) lr 1.3090e-03 eta 1:43:36
epoch [6/10] batch [800/800] time 1.885 (1.929) data 0.000 (0.080) loss 2.2539 (1.7691) lr 1.0000e-03 eta 1:42:53
epoch [7/10] batch [20/800] time 1.887 (5.178) data 0.000 (3.362) loss 1.0908 (1.9745) lr 1.0000e-03 eta 4:34:27
epoch [7/10] batch [40/800] time 1.880 (3.528) data 0.000 (1.681) loss 0.7549 (1.6730) lr 1.0000e-03 eta 3:05:47
epoch [7/10] batch [60/800] time 1.882 (2.964) data 0.000 (1.121) loss 0.1298 (1.5683) lr 1.0000e-03 eta 2:35:06
epoch [7/10] batch [80/800] time 1.874 (2.692) data 0.000 (0.841) loss 2.4922 (1.5842) lr 1.0000e-03 eta 2:19:58
epoch [7/10] batch [100/800] time 1.874 (2.529) data 0.000 (0.673) loss 2.6660 (1.5911) lr 1.0000e-03 eta 2:10:40
epoch [7/10] batch [120/800] time 1.878 (2.413) data 0.000 (0.560) loss 0.6870 (1.5973) lr 1.0000e-03 eta 2:03:52
epoch [7/10] batch [140/800] time 1.886 (2.325) data 0.000 (0.480) loss 1.2373 (1.6316) lr 1.0000e-03 eta 1:58:35
epoch [7/10] batch [160/800] time 1.878 (2.267) data 0.000 (0.420) loss 0.7290 (1.6477) lr 1.0000e-03 eta 1:54:50
epoch [7/10] batch [180/800] time 1.894 (2.218) data 0.000 (0.374) loss 2.1250 (1.6638) lr 1.0000e-03 eta 1:51:36
epoch [7/10] batch [200/800] time 1.648 (2.160) data 0.000 (0.336) loss 1.9912 (1.6326) lr 1.0000e-03 eta 1:47:58
epoch [7/10] batch [220/800] time 1.892 (2.131) data 0.000 (0.306) loss 3.4141 (1.6367) lr 1.0000e-03 eta 1:45:49
epoch [7/10] batch [240/800] time 1.742 (2.106) data 0.004 (0.280) loss 3.9922 (1.6780) lr 1.0000e-03 eta 1:43:52
epoch [7/10] batch [260/800] time 1.873 (2.088) data 0.000 (0.259) loss 0.2040 (1.6472) lr 1.0000e-03 eta 1:42:17
epoch [7/10] batch [280/800] time 1.858 (2.072) data 0.000 (0.240) loss 2.5137 (1.6543) lr 1.0000e-03 eta 1:40:51
epoch [7/10] batch [300/800] time 1.870 (2.059) data 0.000 (0.224) loss 1.3125 (1.6718) lr 1.0000e-03 eta 1:39:31
epoch [7/10] batch [320/800] time 1.878 (2.046) data 0.000 (0.210) loss 2.1055 (1.6643) lr 1.0000e-03 eta 1:38:11
epoch [7/10] batch [340/800] time 1.871 (2.034) data 0.000 (0.198) loss 1.6445 (1.6633) lr 1.0000e-03 eta 1:36:57
epoch [7/10] batch [360/800] time 1.874 (2.024) data 0.000 (0.187) loss 1.0615 (1.6673) lr 1.0000e-03 eta 1:35:49
epoch [7/10] batch [380/800] time 1.878 (2.016) data 0.000 (0.177) loss 2.6758 (1.6667) lr 1.0000e-03 eta 1:34:43
epoch [7/10] batch [400/800] time 1.867 (2.002) data 0.000 (0.168) loss 1.8525 (1.6863) lr 1.0000e-03 eta 1:33:25
epoch [7/10] batch [420/800] time 1.291 (1.995) data 0.004 (0.160) loss 4.3672 (1.6935) lr 1.0000e-03 eta 1:32:25
epoch [7/10] batch [440/800] time 1.880 (1.989) data 0.000 (0.153) loss 2.2871 (1.7039) lr 1.0000e-03 eta 1:31:29
epoch [7/10] batch [460/800] time 1.871 (1.984) data 0.000 (0.146) loss 1.0791 (1.7324) lr 1.0000e-03 eta 1:30:36
epoch [7/10] batch [480/800] time 1.877 (1.978) data 0.000 (0.140) loss 1.4395 (1.7210) lr 1.0000e-03 eta 1:29:40
epoch [7/10] batch [500/800] time 1.867 (1.974) data 0.000 (0.135) loss 2.2598 (1.7155) lr 1.0000e-03 eta 1:28:49
epoch [7/10] batch [520/800] time 1.883 (1.970) data 0.000 (0.130) loss 0.7441 (1.7154) lr 1.0000e-03 eta 1:28:00
epoch [7/10] batch [540/800] time 1.870 (1.964) data 0.000 (0.125) loss 0.3987 (1.7166) lr 1.0000e-03 eta 1:27:04
epoch [7/10] batch [560/800] time 1.716 (1.958) data 0.000 (0.120) loss 2.8965 (1.7184) lr 1.0000e-03 eta 1:26:09
epoch [7/10] batch [580/800] time 1.871 (1.955) data 0.000 (0.116) loss 2.2637 (1.7182) lr 1.0000e-03 eta 1:25:22
epoch [7/10] batch [600/800] time 1.886 (1.951) data 0.004 (0.112) loss 0.4084 (1.7266) lr 1.0000e-03 eta 1:24:33
epoch [7/10] batch [620/800] time 1.883 (1.948) data 0.000 (0.109) loss 0.8774 (1.7243) lr 1.0000e-03 eta 1:23:45
epoch [7/10] batch [640/800] time 1.862 (1.946) data 0.000 (0.105) loss 0.1515 (1.7265) lr 1.0000e-03 eta 1:23:00
epoch [7/10] batch [660/800] time 1.880 (1.943) data 0.000 (0.102) loss 2.4902 (1.7144) lr 1.0000e-03 eta 1:22:16
epoch [7/10] batch [680/800] time 1.876 (1.940) data 0.000 (0.099) loss 2.0781 (1.7145) lr 1.0000e-03 eta 1:21:29
epoch [7/10] batch [700/800] time 1.882 (1.937) data 0.000 (0.096) loss 2.1738 (1.7274) lr 1.0000e-03 eta 1:20:43
epoch [7/10] batch [720/800] time 1.874 (1.936) data 0.000 (0.094) loss 3.4102 (1.7323) lr 1.0000e-03 eta 1:20:00
epoch [7/10] batch [740/800] time 1.870 (1.934) data 0.000 (0.091) loss 2.1895 (1.7305) lr 1.0000e-03 eta 1:19:17
epoch [7/10] batch [760/800] time 1.882 (1.932) data 0.000 (0.089) loss 1.6963 (1.7268) lr 1.0000e-03 eta 1:18:34
epoch [7/10] batch [780/800] time 1.279 (1.929) data 0.000 (0.087) loss 2.7734 (1.7293) lr 1.0000e-03 eta 1:17:47
epoch [7/10] batch [800/800] time 1.881 (1.927) data 0.004 (0.084) loss 0.1740 (1.7206) lr 6.9098e-04 eta 1:17:05
epoch [8/10] batch [20/800] time 1.870 (5.133) data 0.000 (3.364) loss 1.9150 (1.7671) lr 6.9098e-04 eta 3:23:37
epoch [8/10] batch [40/800] time 1.696 (3.465) data 0.000 (1.682) loss 2.0645 (1.8756) lr 6.9098e-04 eta 2:16:17
epoch [8/10] batch [60/800] time 1.695 (2.922) data 0.000 (1.122) loss 0.4788 (1.8228) lr 6.9098e-04 eta 1:53:57
epoch [8/10] batch [80/800] time 1.870 (2.661) data 0.000 (0.841) loss 3.4355 (1.8670) lr 6.9098e-04 eta 1:42:53
epoch [8/10] batch [100/800] time 1.866 (2.504) data 0.000 (0.673) loss 0.0960 (1.8198) lr 6.9098e-04 eta 1:35:58
epoch [8/10] batch [120/800] time 1.883 (2.392) data 0.000 (0.561) loss 0.5503 (1.7269) lr 6.9098e-04 eta 1:30:54
epoch [8/10] batch [140/800] time 1.873 (2.318) data 0.000 (0.481) loss 2.6035 (1.6943) lr 6.9098e-04 eta 1:27:19
epoch [8/10] batch [160/800] time 1.868 (2.258) data 0.000 (0.421) loss 2.8516 (1.6682) lr 6.9098e-04 eta 1:24:17
epoch [8/10] batch [180/800] time 1.884 (2.207) data 0.000 (0.374) loss 1.1387 (1.6878) lr 6.9098e-04 eta 1:21:39
epoch [8/10] batch [200/800] time 1.870 (2.170) data 0.000 (0.337) loss 1.2715 (1.6844) lr 6.9098e-04 eta 1:19:34
epoch [8/10] batch [220/800] time 1.894 (2.143) data 0.000 (0.306) loss 2.0820 (1.6534) lr 6.9098e-04 eta 1:17:52
epoch [8/10] batch [240/800] time 1.874 (2.118) data 0.000 (0.281) loss 0.7212 (1.6478) lr 6.9098e-04 eta 1:16:15
epoch [8/10] batch [260/800] time 1.869 (2.099) data 0.000 (0.259) loss 2.2422 (1.6473) lr 6.9098e-04 eta 1:14:52
epoch [8/10] batch [280/800] time 1.875 (2.081) data 0.000 (0.241) loss 1.1426 (1.6367) lr 6.9098e-04 eta 1:13:31
epoch [8/10] batch [300/800] time 1.872 (2.065) data 0.000 (0.225) loss 0.3577 (1.6202) lr 6.9098e-04 eta 1:12:16
epoch [8/10] batch [320/800] time 1.264 (2.047) data 0.000 (0.211) loss 0.1887 (1.6400) lr 6.9098e-04 eta 1:10:58
epoch [8/10] batch [340/800] time 1.890 (2.037) data 0.000 (0.198) loss 0.0743 (1.6311) lr 6.9098e-04 eta 1:09:55
epoch [8/10] batch [360/800] time 1.868 (2.028) data 0.000 (0.187) loss 0.0073 (1.6366) lr 6.9098e-04 eta 1:08:57
epoch [8/10] batch [380/800] time 1.883 (2.020) data 0.000 (0.177) loss 1.2188 (1.6407) lr 6.9098e-04 eta 1:08:00
epoch [8/10] batch [400/800] time 1.282 (2.011) data 0.000 (0.168) loss 2.8184 (1.6384) lr 6.9098e-04 eta 1:07:02
epoch [8/10] batch [420/800] time 1.871 (2.005) data 0.004 (0.160) loss 2.1582 (1.6408) lr 6.9098e-04 eta 1:06:08
epoch [8/10] batch [440/800] time 1.884 (1.999) data 0.000 (0.153) loss 1.3477 (1.6471) lr 6.9098e-04 eta 1:05:17
epoch [8/10] batch [460/800] time 1.879 (1.993) data 0.000 (0.147) loss 2.1367 (1.6246) lr 6.9098e-04 eta 1:04:27
epoch [8/10] batch [480/800] time 1.880 (1.989) data 0.000 (0.140) loss 2.6836 (1.6135) lr 6.9098e-04 eta 1:03:38
epoch [8/10] batch [500/800] time 1.876 (1.984) data 0.000 (0.135) loss 3.4922 (1.6120) lr 6.9098e-04 eta 1:02:49
epoch [8/10] batch [520/800] time 1.879 (1.980) data 0.000 (0.130) loss 2.7734 (1.6361) lr 6.9098e-04 eta 1:02:02
epoch [8/10] batch [540/800] time 1.881 (1.976) data 0.000 (0.125) loss 0.8022 (1.6402) lr 6.9098e-04 eta 1:01:15
epoch [8/10] batch [560/800] time 1.873 (1.973) data 0.000 (0.120) loss 1.5820 (1.6436) lr 6.9098e-04 eta 1:00:29
epoch [8/10] batch [580/800] time 1.873 (1.969) data 0.004 (0.116) loss 1.2109 (1.6473) lr 6.9098e-04 eta 0:59:44
epoch [8/10] batch [600/800] time 1.867 (1.966) data 0.000 (0.112) loss 0.0546 (1.6313) lr 6.9098e-04 eta 0:58:59
epoch [8/10] batch [620/800] time 1.883 (1.961) data 0.000 (0.109) loss 2.9082 (1.6318) lr 6.9098e-04 eta 0:58:10
epoch [8/10] batch [640/800] time 1.883 (1.957) data 0.000 (0.105) loss 2.4648 (1.6347) lr 6.9098e-04 eta 0:57:24
epoch [8/10] batch [660/800] time 1.875 (1.953) data 0.000 (0.102) loss 1.3203 (1.6249) lr 6.9098e-04 eta 0:56:39
epoch [8/10] batch [680/800] time 1.878 (1.951) data 0.000 (0.099) loss 2.9141 (1.6279) lr 6.9098e-04 eta 0:55:56
epoch [8/10] batch [700/800] time 1.871 (1.949) data 0.000 (0.096) loss 0.8965 (1.6319) lr 6.9098e-04 eta 0:55:13
epoch [8/10] batch [720/800] time 1.888 (1.946) data 0.000 (0.094) loss 2.7949 (1.6291) lr 6.9098e-04 eta 0:54:29
epoch [8/10] batch [740/800] time 1.870 (1.944) data 0.004 (0.091) loss 1.4121 (1.6311) lr 6.9098e-04 eta 0:53:47
epoch [8/10] batch [760/800] time 1.866 (1.942) data 0.000 (0.089) loss 1.0586 (1.6372) lr 6.9098e-04 eta 0:53:05
epoch [8/10] batch [780/800] time 1.876 (1.940) data 0.000 (0.087) loss 1.3457 (1.6436) lr 6.9098e-04 eta 0:52:22
epoch [8/10] batch [800/800] time 1.886 (1.936) data 0.000 (0.084) loss 3.6094 (1.6466) lr 4.1221e-04 eta 0:51:37
epoch [9/10] batch [20/800] time 1.880 (5.095) data 0.000 (3.268) loss 1.4238 (1.3248) lr 4.1221e-04 eta 2:14:10
epoch [9/10] batch [40/800] time 1.869 (3.466) data 0.000 (1.634) loss 1.6416 (1.5060) lr 4.1221e-04 eta 1:30:07
epoch [9/10] batch [60/800] time 1.872 (2.936) data 0.000 (1.089) loss 1.5459 (1.6678) lr 4.1221e-04 eta 1:15:21
epoch [9/10] batch [80/800] time 1.894 (2.671) data 0.000 (0.817) loss 0.5913 (1.5079) lr 4.1221e-04 eta 1:07:40
epoch [9/10] batch [100/800] time 1.872 (2.513) data 0.000 (0.654) loss 1.6680 (1.6104) lr 4.1221e-04 eta 1:02:49
epoch [9/10] batch [120/800] time 1.886 (2.407) data 0.000 (0.545) loss 3.1113 (1.6358) lr 4.1221e-04 eta 0:59:21
epoch [9/10] batch [140/800] time 1.882 (2.325) data 0.004 (0.467) loss 2.3516 (1.6629) lr 4.1221e-04 eta 0:56:34
epoch [9/10] batch [160/800] time 1.880 (2.264) data 0.000 (0.409) loss 3.0566 (1.6782) lr 4.1221e-04 eta 0:54:20
epoch [9/10] batch [180/800] time 1.873 (2.221) data 0.000 (0.363) loss 2.3848 (1.6804) lr 4.1221e-04 eta 0:52:34
epoch [9/10] batch [200/800] time 1.878 (2.175) data 0.000 (0.327) loss 2.1406 (1.6872) lr 4.1221e-04 eta 0:50:45
epoch [9/10] batch [220/800] time 1.868 (2.143) data 0.000 (0.297) loss 0.6221 (1.6796) lr 4.1221e-04 eta 0:49:16
epoch [9/10] batch [240/800] time 1.869 (2.114) data 0.004 (0.273) loss 2.0078 (1.6514) lr 4.1221e-04 eta 0:47:55
epoch [9/10] batch [260/800] time 1.859 (2.096) data 0.000 (0.252) loss 4.3516 (1.6523) lr 4.1221e-04 eta 0:46:48
epoch [9/10] batch [280/800] time 1.880 (2.080) data 0.000 (0.234) loss 3.1465 (1.6587) lr 4.1221e-04 eta 0:45:45
epoch [9/10] batch [300/800] time 1.882 (2.066) data 0.000 (0.218) loss 0.5742 (1.6652) lr 4.1221e-04 eta 0:44:45
epoch [9/10] batch [320/800] time 1.868 (2.054) data 0.000 (0.205) loss 0.5864 (1.6459) lr 4.1221e-04 eta 0:43:48
epoch [9/10] batch [340/800] time 1.865 (2.041) data 0.000 (0.192) loss 2.0293 (1.6340) lr 4.1221e-04 eta 0:42:51
epoch [9/10] batch [360/800] time 1.871 (2.032) data 0.000 (0.182) loss 2.1328 (1.6403) lr 4.1221e-04 eta 0:41:59
epoch [9/10] batch [380/800] time 1.868 (2.024) data 0.000 (0.172) loss 1.0361 (1.6459) lr 4.1221e-04 eta 0:41:09
epoch [9/10] batch [400/800] time 1.878 (2.017) data 0.004 (0.164) loss 0.8574 (1.6685) lr 4.1221e-04 eta 0:40:19
epoch [9/10] batch [420/800] time 1.885 (2.010) data 0.004 (0.156) loss 2.5273 (1.6669) lr 4.1221e-04 eta 0:39:31
epoch [9/10] batch [440/800] time 1.877 (2.004) data 0.000 (0.149) loss 2.0234 (1.6609) lr 4.1221e-04 eta 0:38:44
epoch [9/10] batch [460/800] time 1.863 (1.996) data 0.000 (0.142) loss 2.3965 (1.6574) lr 4.1221e-04 eta 0:37:55
epoch [9/10] batch [480/800] time 1.869 (1.991) data 0.000 (0.136) loss 0.7319 (1.6481) lr 4.1221e-04 eta 0:37:09
epoch [9/10] batch [500/800] time 1.877 (1.986) data 0.000 (0.131) loss 0.0040 (1.6367) lr 4.1221e-04 eta 0:36:24
epoch [9/10] batch [520/800] time 1.877 (1.982) data 0.000 (0.126) loss 0.0684 (1.6456) lr 4.1221e-04 eta 0:35:40
epoch [9/10] batch [540/800] time 1.880 (1.975) data 0.000 (0.121) loss 0.0570 (1.6332) lr 4.1221e-04 eta 0:34:53
epoch [9/10] batch [560/800] time 1.885 (1.972) data 0.000 (0.117) loss 0.2905 (1.6304) lr 4.1221e-04 eta 0:34:10
epoch [9/10] batch [580/800] time 1.875 (1.967) data 0.000 (0.113) loss 2.1230 (1.6295) lr 4.1221e-04 eta 0:33:26
epoch [9/10] batch [600/800] time 1.862 (1.964) data 0.000 (0.109) loss 2.0410 (1.6229) lr 4.1221e-04 eta 0:32:44
epoch [9/10] batch [620/800] time 1.877 (1.961) data 0.000 (0.106) loss 2.8555 (1.6343) lr 4.1221e-04 eta 0:32:01
epoch [9/10] batch [640/800] time 1.863 (1.957) data 0.000 (0.102) loss 0.9971 (1.6309) lr 4.1221e-04 eta 0:31:18
epoch [9/10] batch [660/800] time 1.883 (1.954) data 0.000 (0.099) loss 0.1498 (1.6209) lr 4.1221e-04 eta 0:30:36
epoch [9/10] batch [680/800] time 1.870 (1.952) data 0.000 (0.096) loss 0.0148 (1.6200) lr 4.1221e-04 eta 0:29:55
epoch [9/10] batch [700/800] time 1.426 (1.949) data 0.000 (0.094) loss 4.5977 (1.6239) lr 4.1221e-04 eta 0:29:13
epoch [9/10] batch [720/800] time 1.873 (1.947) data 0.000 (0.091) loss 2.2109 (1.6153) lr 4.1221e-04 eta 0:28:33
epoch [9/10] batch [740/800] time 1.881 (1.945) data 0.000 (0.089) loss 1.5820 (1.6115) lr 4.1221e-04 eta 0:27:52
epoch [9/10] batch [760/800] time 1.870 (1.941) data 0.000 (0.086) loss 1.0146 (1.6052) lr 4.1221e-04 eta 0:27:10
epoch [9/10] batch [780/800] time 1.882 (1.939) data 0.000 (0.084) loss 3.0645 (1.6077) lr 4.1221e-04 eta 0:26:30
epoch [9/10] batch [800/800] time 1.883 (1.938) data 0.000 (0.082) loss 1.6211 (1.6092) lr 1.9098e-04 eta 0:25:50
epoch [10/10] batch [20/800] time 1.878 (5.036) data 0.000 (3.235) loss 0.5049 (1.4947) lr 1.9098e-04 eta 1:05:27
epoch [10/10] batch [40/800] time 1.887 (3.431) data 0.000 (1.618) loss 1.1064 (1.5839) lr 1.9098e-04 eta 0:43:27
epoch [10/10] batch [60/800] time 1.881 (2.914) data 0.000 (1.079) loss 1.7959 (1.4208) lr 1.9098e-04 eta 0:35:56
epoch [10/10] batch [80/800] time 1.865 (2.654) data 0.000 (0.809) loss 0.1442 (1.4034) lr 1.9098e-04 eta 0:31:51
epoch [10/10] batch [100/800] time 1.882 (2.499) data 0.000 (0.647) loss 2.1875 (1.4819) lr 1.9098e-04 eta 0:29:09
epoch [10/10] batch [120/800] time 1.871 (2.395) data 0.000 (0.540) loss 1.0332 (1.4403) lr 1.9098e-04 eta 0:27:08
epoch [10/10] batch [140/800] time 1.874 (2.315) data 0.000 (0.463) loss 0.0029 (1.4631) lr 1.9098e-04 eta 0:25:28
epoch [10/10] batch [160/800] time 1.277 (2.257) data 0.000 (0.405) loss 1.5205 (1.4964) lr 1.9098e-04 eta 0:24:04
epoch [10/10] batch [180/800] time 1.876 (2.211) data 0.000 (0.360) loss 0.1646 (1.4975) lr 1.9098e-04 eta 0:22:51
epoch [10/10] batch [200/800] time 1.870 (2.178) data 0.000 (0.324) loss 0.6113 (1.5404) lr 1.9098e-04 eta 0:21:46
epoch [10/10] batch [220/800] time 1.876 (2.150) data 0.000 (0.294) loss 1.1475 (1.5390) lr 1.9098e-04 eta 0:20:47
epoch [10/10] batch [240/800] time 1.879 (2.127) data 0.000 (0.270) loss 2.4668 (1.5582) lr 1.9098e-04 eta 0:19:51
epoch [10/10] batch [260/800] time 1.870 (2.102) data 0.000 (0.249) loss 1.9551 (1.5625) lr 1.9098e-04 eta 0:18:55
epoch [10/10] batch [280/800] time 1.894 (2.086) data 0.000 (0.231) loss 2.2754 (1.6143) lr 1.9098e-04 eta 0:18:04
epoch [10/10] batch [300/800] time 1.901 (2.072) data 0.000 (0.216) loss 1.0840 (1.6142) lr 1.9098e-04 eta 0:17:16
epoch [10/10] batch [320/800] time 1.866 (2.060) data 0.000 (0.202) loss 0.7358 (1.6138) lr 1.9098e-04 eta 0:16:28
epoch [10/10] batch [340/800] time 1.882 (2.045) data 0.000 (0.191) loss 0.1793 (1.5845) lr 1.9098e-04 eta 0:15:40
epoch [10/10] batch [360/800] time 1.875 (2.033) data 0.000 (0.180) loss 2.2578 (1.5810) lr 1.9098e-04 eta 0:14:54
epoch [10/10] batch [380/800] time 1.887 (2.023) data 0.000 (0.171) loss 1.8291 (1.5726) lr 1.9098e-04 eta 0:14:09
epoch [10/10] batch [400/800] time 1.886 (2.014) data 0.000 (0.162) loss 2.7227 (1.5910) lr 1.9098e-04 eta 0:13:25
epoch [10/10] batch [420/800] time 1.871 (2.005) data 0.000 (0.154) loss 1.5596 (1.5801) lr 1.9098e-04 eta 0:12:42
epoch [10/10] batch [440/800] time 1.869 (1.998) data 0.004 (0.147) loss 2.7227 (1.5695) lr 1.9098e-04 eta 0:11:59
epoch [10/10] batch [460/800] time 1.878 (1.991) data 0.004 (0.141) loss 1.3428 (1.5760) lr 1.9098e-04 eta 0:11:16
epoch [10/10] batch [480/800] time 1.876 (1.986) data 0.000 (0.135) loss 1.6875 (1.5742) lr 1.9098e-04 eta 0:10:35
epoch [10/10] batch [500/800] time 1.868 (1.976) data 0.000 (0.130) loss 1.3525 (1.5780) lr 1.9098e-04 eta 0:09:52
epoch [10/10] batch [520/800] time 1.886 (1.973) data 0.000 (0.125) loss 1.4297 (1.5712) lr 1.9098e-04 eta 0:09:12
epoch [10/10] batch [540/800] time 1.873 (1.966) data 0.000 (0.120) loss 0.2228 (1.5626) lr 1.9098e-04 eta 0:08:31
epoch [10/10] batch [560/800] time 1.885 (1.962) data 0.000 (0.116) loss 2.1406 (1.5572) lr 1.9098e-04 eta 0:07:50
epoch [10/10] batch [580/800] time 1.876 (1.959) data 0.000 (0.112) loss 0.7808 (1.5537) lr 1.9098e-04 eta 0:07:10
epoch [10/10] batch [600/800] time 1.876 (1.955) data 0.000 (0.108) loss 0.6826 (1.5472) lr 1.9098e-04 eta 0:06:30
epoch [10/10] batch [620/800] time 1.880 (1.952) data 0.000 (0.105) loss 2.2383 (1.5495) lr 1.9098e-04 eta 0:05:51
epoch [10/10] batch [640/800] time 1.693 (1.947) data 0.000 (0.101) loss 2.1504 (1.5686) lr 1.9098e-04 eta 0:05:11
epoch [10/10] batch [660/800] time 1.293 (1.942) data 0.000 (0.098) loss 0.2517 (1.5781) lr 1.9098e-04 eta 0:04:31
epoch [10/10] batch [680/800] time 1.891 (1.939) data 0.000 (0.095) loss 0.0002 (1.5721) lr 1.9098e-04 eta 0:03:52
epoch [10/10] batch [700/800] time 1.876 (1.937) data 0.000 (0.093) loss 0.0000 (1.5615) lr 1.9098e-04 eta 0:03:13
epoch [10/10] batch [720/800] time 1.864 (1.935) data 0.000 (0.090) loss 1.2070 (1.5536) lr 1.9098e-04 eta 0:02:34
epoch [10/10] batch [740/800] time 1.872 (1.934) data 0.000 (0.088) loss 1.5264 (1.5648) lr 1.9098e-04 eta 0:01:56
epoch [10/10] batch [760/800] time 1.882 (1.932) data 0.000 (0.085) loss 1.7314 (1.5735) lr 1.9098e-04 eta 0:01:17
epoch [10/10] batch [780/800] time 1.878 (1.931) data 0.004 (0.083) loss 1.8740 (1.5691) lr 1.9098e-04 eta 0:00:38
epoch [10/10] batch [800/800] time 1.877 (1.929) data 0.000 (0.081) loss 0.9380 (1.5616) lr 4.8943e-05 eta 0:00:00
Checkpoint saved to output/0506/base2new/train_base/fgvc_aircraft/shots_16/CoCoOp/vit_b16_c16_ep10_batch1/seed2\prompt_learner\model.pth.tar-10
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 1,666
* correct: 625
* accuracy: 37.5%
* error: 62.5%
* macro_f1: 36.1%
Elapsed: 4:42:04
